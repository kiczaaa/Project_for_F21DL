{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libs\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stored data\n",
    "%store -r X_train\n",
    "%store -r X_cv\n",
    "%store -r y_train\n",
    "%store -r y_cv\n",
    "%store -r mmscaler\n",
    "%store -r pca\n",
    "%store -r X_train_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of total samples:  22564\n",
      "The shape of train set:  (18051, 1317)\n",
      "The shape of test set:  (4513, 12288)\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of total samples: \", X_train.shape[0] + X_cv.shape[0])\n",
    "print(\"The shape of train set: \", X_train_pca.shape)  # use scaled (normalized) and pca processed train data set\n",
    "print(\"The shape of test set: \", X_cv.shape) # use cv set as test set (train set will be divided into cv while training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to do\n",
    "1. Using Keras library (for the computer vision dataset) \n",
    "    - Measure the accracy on the training set. \n",
    "    - Then measure the accuacy using 10-fold cross-validation. Use the major metrics: Accruracy, TP rate, FP rate, Precision, Recall, F measure, the ROC area \n",
    "2. Experiment with various parameters that control the learning. (the learning rate, the number and size of layers, the number of iterations, batch size, epochs and momentum, and validation threshold)\n",
    "3. Experiement with three different train-test set split. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use Keras library to build an Image Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, 100)               131800    \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 10)                1010      \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 132,821\n",
      "Trainable params: 132,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build model \n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "        keras.layers.Dense(100, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(10, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer3\", activation=\"sigmoid\") # use sigmoid because our data sets is binary classification\n",
    "                                                               # units = 1 because we are using sigmoid in binary classification\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the input data: (None, 1317)\n",
      "The number of parameters of layer1:  131800\n",
      "The number of parameters of layer2:  1010\n",
      "The number of parameters of layer3:  11\n"
     ]
    }
   ],
   "source": [
    "# check the number of parameters of each layers, and the shape of input&output\n",
    "print(\"The shape of the input data:\", model.input.shape)\n",
    "print(\"The number of parameters of layer1: \", (model.input.shape[1]+1) * model.layers[0].units)\n",
    "print(\"The number of parameters of layer2: \", (model.layers[0].units+1) * model.layers[1].units)\n",
    "print(\"The number of parameters of layer3: \", (model.layers[1].units+1) * model.layers[2].units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of weights of layer1:  [1317, 100]\n",
      "The shape of weights of layer2:  [100, 10]\n",
      "The shape of weights of layer3:  [10, 1]\n"
     ]
    }
   ],
   "source": [
    "# check the shape of weights of each layer\n",
    "print(\"The shape of weights of layer1: \", [len(model.layers[0].get_weights()[0]), len(model.layers[0].get_weights()[0][0])])\n",
    "print(\"The shape of weights of layer2: \", [len(model.layers[1].get_weights()[0]), len(model.layers[1].get_weights()[0][0])])\n",
    "print(\"The shape of weights of layer3: \", [len(model.layers[2].get_weights()[0]), len(model.layers[2].get_weights()[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of biases of layer1:  100\n",
      "The shape of biases of layer2:  10\n",
      "The shape of biases of layer3:  1\n"
     ]
    }
   ],
   "source": [
    "# check the length of biases of each layer\n",
    "print(\"The shape of biases of layer1: \", len(model.layers[0].get_weights()[1]))\n",
    "print(\"The shape of biases of layer2: \", len(model.layers[1].get_weights()[1]))\n",
    "print(\"The shape of biases of layer3: \", len(model.layers[2].get_weights()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT0AAAGVCAIAAAADtrFJAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO2dTWwbx/n/Z23LCarCclxUjh3HSH9oXaBowSJpCxsNmloQmsbNMkAiWaZt2QkgCRTQgx0LaGGQMAy7PlGxDgbikrrpQErOJWQTXywB9sEkgqalAvQgI3WxipCWLFBwe/vnxfs/PNB0PbtcLal9m9X3c+LO7s4+8/KdnZkdzqMYhsEAAFKxLWwDAAAdA90CIB/QLQDyAd0CIB87zAfVavWdd94JyxQAQDuOHDny9ttv88PH3refffbZe++9F7hJclOr1Wq1WthW+MLa2hrqQxSo1WrVatUcssN60a1bt4KyJw4MDw+zmGbawsLCyMhILJMmF1THzGB8C4B8QLcAyAd0C4B8QLcAyAd0C4B8hKPbbDabzWZDeXQUiFnyFRPCqWazOT09HYpV0WF6elrXdSHQIdPcEM/3ra7r3WVHPAgl+YZhCP8tazably5d6u3tpdppbaqUxwnQWMYY03W9VqsVCoVkMimcajab2WyWrCqVSm7uojwXoHsHBwdHR0ebzab5emt2dYZhYn5+XgiRlHK5HFhChoaGhoaGgnmWS7xKvsv6YK1IhmG0Wi1VVavVKv0uFouMsUwmI1zWaDQYY41GY/PWdkomk8lkMlbjG40GmW0YBpmdy+U2vEtYF0HwdFWrVVVVW62WYINt1lmx1rEY6pZqzJbVrYfJ34xuc7mcoFK6rFgsWm/fpJ2bwVaBzhfYBhaLRU3T+GGj0RCSn06nzfp3iNyKtY6F0E9uNpulUol3M8yHlUpFUZRkMrm6ukqnKpUKnSoUCoqiTE5OPnjwgJm6WBSJ+TCXy1UqFR4YfAKdCT75wQ+nm83m1NTU0aNHhfBcLpdKpYSep4Cu66VSiYwvFArUvXTIJf7E6elpCl9aWtqM8YcPHzYbwxjjL1gHBgYGDh48yA+XlpaGhobMFwwPD09NTQm95e4xiziY9y29DfiD+CG1c5qmMcbS6bRh6v3z7lY6nWaMraysUP+KR0J3sceHDX4nhOj0fRt88qlr10XSun7fUkfd/P4x1t+rpIF6vS6Ec1RVzefzhmE0Gg1VVal76ZBL/Ep6ky8uLgrxd2o8R9M0snZlZcX9XQS3zRwbY6xcLncUDxGVfrJgrsOhcKper7P18Yb7u3yli36yLMnvWrdU3a2XGaZuPBeD+UpSnXlYyNa71g7ppVGo+ZT7dqpdXvGmkD0+vnW+i6jX69bhQKvVska1VXRrDtmCujWCTX7XurU1gIdQZ0FVVdKn+UrqUPBDquuqqlrjNB/yt7EZl2ncUIHUBlEXwOVdmUzGdqbNZUZZicT4Fmxx+vv76/V6pVIZGxsTPmzevHnTfNjX18cYo+G6A3SBrUg2SSKRGB0dZYxNTEy4vIVGsP39/Z4Y0A4pdUut8pYlBslPJBLlcrlSqeRyOXM4vTmFyRuX6aUZO885dOhQR9dbZ6T8QDLdUtkcO3YsbEPCQZbkkxqti4TM0EzS1atXzYEnT55kjD18+JAOKQbrv08F8vk8Y2xubo6u93aRFsVJQ2g33L17N5FItDvrZmraDeF8BzL/4IeUQbywzY0ufTnQdX1ubo7mGNl6M0xVme84MTk5yUzNdgQX2QWf/OC/A9E7yqxbIbHEiRMnhHr8yiuvqKp67do1uvL27dvpdHpgYMA5l1577TXG2NWrV3fv3q0oyt69e0nq9GVoeXm5nZ08HrOpyWRyenqaPjLpuk4fok+cOOF8F7G8vPzSSy/ZPosi/NnPftbOmM4wDwmCmZcSnu7msF6vU13M5/N80YmmaRRIc+vUftN8AM27tpse8JZO56WCT37w34Fo5okvYHCocmS5cC+9PxljxWKR0uucS4bpm006nebfnzKZTDqdFuIXzLZGRR+xiFwuZ7sMo11yHKoczY0LZ20zxIq1jilmU2hfElvjwoJWDkTKJAFf96kJN/ku64OtkfSqv3Dhgn/muSSZTJqlGBbZbHb37t1ChrgsX2sdk2x8C2RhbGzs7t27oe+YV6vVLl68GK4NjLHl5eXl5eWxsTGvIoy0boWh4FZD6uT39fXNzs5eu3bNYXjpN0tLS3v27DGvWwyFBw8e3Lx5c3Z2lj5reUKkdbt3717hx5ZCruRbV4P39/fPzc3duXMnLJMGBgY6/YrjB5VK5fLly8IX3U0unrfZhzU6RHlYGwCyJN/Bzr6+vigMccPFNgc2WbiRft8CAGyBbgGQD+gWAPmAbgGQD+gWAPmwmU+O4N4u0SfGmRbjpEmE8B8jG93SqlTgkuvXrzPGzp8/H7Yh3lOtVmdmZlAfQofqmBkb3R4/fjwQY2ICrRqNa6bNzMzENWkSYV39jvEtAPIB3QIgH9AtAPIB3QIgH9AtAPIB3YLNAj+azkTCj6bVWWAXT90QsyfIYJ4YTTzxiBmMW03r9kvwoxktP5q0izxjzOoX0CsET5DcHY5/T+waX/3xeeIRs+tI4Eczbn40XT6vO2w9Qfr6xM3gn2498Yi5mUjgR9P2AtvAgP1oeqDbRqNRLBZpt0tq2lVVpTQ0Go1yuUynaHPNdDpNDp2EF775UNhT100KW60W37yT9sI0b4TP84sHcvMoRFXVxcVFs8Hk/M7N9qXudctfO4yxfD7PveO4zAevMtP9tqyb3IeVstR8GeW2IF3hXttccqhj/IlCUbpkw3rF7LoJtkk2HxaLRcEnoOCyzM3TOb7oNhhHmM4ppGgbjYb56dR1ETwacndSts4XzWmp1+tWb4hW3OvW1kOk+3zwKjMD0C38aEbUj6bwPIdD4VTXniCdU0g7XFuvpDaYVyCzg8N2zhfpdvcDaZe67c5DpHM+++1WE340ifj40exat+YQD3VLaJrGe8IUQjWbO0HM5XJcw+2cL3Zay13qtjsPkc75bHSbmS6BH83I+tGMj27z+byqqisrK8KVVBVarRZ1LDeMsNNa7lK3nuSDV5npEp90a6y3p9QHDjGBbu611ijnu6wzUg53ubQ8Kv5vPfQESZ6sSqXSxMTEjRs3rPvl0rNu37597969s2fPCmd9cr5oZTMeIp2R0a0m/GhukqB1660nyFqtRu7PUqkUY+zgwYPWaxKJRDqdTqVShULBvHW9r84XrXTnIdKZyLrVhB/Ndme98qPZTT9ZWHchLIrgZ83fOWiY3mq1MpkM94/Gp0MN02dr6spSu0uT++ZHmM2gW2jmkK7XNI33aswDDLpSGKLwODmaptk+yBmX/WSaj+GDumKxyDvt7vPBk8wMZT653foKYQarXS451zHbojTWZyUd5pZtVxCpqsrnQSiThexyWHdkOyNFhDyfbCN9E8IF/HAzniCdn0ixma+nuWXhIwQNfa1ZKThf5NG2c77oJk/bYesh0n0+eJKZRoDfb+FH04y3fjS7nJdyj0vLfEWYkfIWX9c5CgScmZtcL2X9fBIK7ptgX8lkMh6ul9oS/wdaWFjY5EgSdAr8aJqRzI9muJ4g+V86VldXBwYGgjfAW+Ryqwk/mhz5/GiG6wmSppfz+fyVK1eCf7rnRNytJvxotkM+P5rGRvNYvjI+Pj4+Ph6iAd4SbmY64GAY/Ggy+NEEABDQLQDyAd0CIB/QLQDyYTMvtbCwELwd8rK2tsZimmm0xCeWSZOLtbW1AwcOPBZkXoQBz2sARBNhvZQS2a8LYJMoijI/Pw9verEE41sA5AO6BUA+oFsA5AO6BUA+oFsA5AO6BUA+oFsA5AO6BUA+oFsA5AO6BUA+oFsA5AO6BUA+oFsA5AO6BUA+oFsA5AO6BUA+oFsA5AO6BUA+oFsA5AO6BUA+oFsA5AO6BUA+oFsA5AO6BUA+oFsA5AO6BUA+oFsA5AO6BUA+oFsA5AO6BUA+oFsA5AO6BUA+oFsA5GNH2AYAzygUCv/5z3/MIe+///4//vEPfvjWW2/19/cHbhfwHsUwjLBtAN6QTqf/+Mc/PvHEE9ZTX3755VNPPfWvf/1rxw601HEA/eT4kEqlGGP/z47t27efPHkSoo0NeN/GB8MwnnnmmX/+85+2Z+/fv3/kyJGATQI+gfdtfFAU5dSpUzt37rSe2r9//+HDh4M3CfgEdBsrUqnUF198IQTu3Lnz7NmziqKEYhLwA/ST48b3vve9Tz/9VAj85JNPfvSjH4ViD/ADvG/jxunTp3t6eswh3/3udyHamAHdxo3Tp09/9dVX/LCnp+ett94K0R7gB+gnx5Af//jHn3zyCZWsoih///vfv/Od74RtFPASvG9jyJkzZ7Zv384YUxTlhRdegGjjB3QbQ1Kp1KNHjxhj27dvP3PmTNjmAO+BbmPIvn37fv7znyuK8ujRo+Hh4bDNAd4D3caT0dFRwzB++ctfPv3002HbAnzA8IH5+fmwkwVAJBgaGvJDYj4uNI+Beq9fv84YO3/+fNiGdMP169cnJiZ6e3ttz1ar1ZmZmRiUUZSh+uMHPur2+PHj/kUeDLdu3WLSJuTFF1/cv3+/wwUzMzOSJk0WqP74Aca3scVZtEBqoFsA5AO6BUA+oFsA5AO6BUA+QtNts9kslUrJZDIsA3wim81ms9mwrfCeZrM5PT0dthUhMz09ret62FYwFqJuL126lEqlKpVKMI/Tdb1WqxUKBdlbCl3Xg9+5otlsXrp0qbe3V1EURVGsDZPyOAGb51C4zWYzm82SVaVSyc1dlMMCdO/g4ODo6Giz2fQ7RRvjx2IO+pq/4WX+GWAlk8lkMplOnzg0NOTTepeuKZfLnmSayzIyDKPVaqmqWq1W6XexWGSMZTIZ4bJGo8EYazQam7etU9oVbqPRILMNwyCzc7nchndVq1WrTHi6qtWqqqqtVsuNYf7Vn62i2+6eGDXdkoQC1m0ulxNUStlYLBaFKwMuTevTrQp0vsA2sFgsaprGDxuNhpD8dDpt1r8D/tWfCM1L6bpeKBR4T4wGVLyjwgdXPHB1dZWtj7sURUkmk0tLSxRSqVSSyaSu65OTk0GONoVBu/mwUqmQkdxsMpIxRqmenJx88OABM/U5KRLzYS6Xo5EFD/F7ON1sNqempo4ePSqE53K5VCol9DwFdF0vlUpkaqFQoO6lQ57wJwoF2jXmLSxpXMpfsA4MDAwcPHiQHy4tLQ0NDZkvGB4enpqaCrm37Edj0N37Np1OM8YajYamaYyxdDptrHda6DdHVVXqtzQaDVVVqeFfXFxkjNXrdXojMcaq1Wq9Xjff22mSO20v+aOFQ2r4zeni+c/7n5T8lZUV6nDySOgufigkgTp77i3kuCwj6pab3z/G+nuVNFCv14Vwjqqq+XzeWC8m6l465InRpkBdpsihcDVNI2tXVlbc30UIdY/bXC6XNzRpS/STM5kMzyPzqVwuZ6469Xqd99Bo0GKOkCox3W4dhPitW+sjHA6FU/V6na0PwNzf1TUuy4iquxBIIVyEXAzmK0l15mEhW+9aO6SuXYG6oV3O8IaPPT6+db6LMFc2TqvVso3KypbQLaFpGgmVn6IKTS23YRi5XI5rmDfeZtrF7BDejiB1aw6Jjm5tH8dDqGvAuz/mK6n7wA+prquqao3TfNiuQN2woQKpDeIVyc1dmUzGdqbNpWFbRbf5fF5V1ZWVFeEUVYJWq0X9SYcYugtvB3TrrFtjvVWlPrBDwg3/U7fhvdZ65XyXdUbK/bOILTEvVSqVJiYmbty4cejQIeEU6fb27dv37t07e/ascJamc+IBpVQiEolEuVyuVCq8l0TQm1OYvHGZOp8K1FqvnLHOSEWHCOmW3MmZp/I4iUQinU6nUqlCoWCeJMzn84yxubk5mi2Uek0PVdZjx46FbchjkBqdFwnRTNLVq1fNgSdPnmSMPXz4kA4phg03u/K1QClOGkK74e7du4lEot1ZN1PTPuLHS9xNH4zPmvLxA7XQmqbx/ox5aEETG8LghEfC0TRNmI/lUEeO2c1XtaPTfo6QKH5IT+QG8NEgW5+qabVamUyGhn/G+riA5nv4MgAaIFAuNRoNmhcJfj653foKYQaLZq340LdYLJL9znliW6DG+tykw9yybeGqqspnQyiHhbxyqBK2M1LElp5PtrYdNFKimQCaWxY+P9DQV4iHT/Hz63m0XAbC49w3WJ3muxC/m0P+4Sqfz/Pao2kaBVLloBca1WxzLhn+65aExBcwOOehOcPpXnp/MsaKxSKlzjlPDLsCNda/NQjxc9oVLjU6RC6Xs12G0S457WakjPWW1M3KsBjqtlOEGalg8HW9lPvmww86Wi/lcnmQ37TTbcBkMhmsl3LLwsICtgIOhbGxsbt379ZqtXDNqNVqFy9eDNcGxtjy8vLy8vLY2Fi4ZkRdt/zPHKurqwMDA2Gb4xl8ojUSfy5xpK+vb3Z29tq1a8vLy2HZsLS0tGfPntBdbz948ODmzZuzs7N9fX3hWhJ13dL0cj6fv3LlSti2eMnevXuFH1Gmv79/bm7uzp07YRkwMDDQ6VccP6hUKpcvX+7v7w/bED/3YfWE8fHx8fHxsK3wHkM2N4h9fX0XLlwI24qQiU4ORP19CwCwAt0CIB/QLQDyAd0CIB8+zkstLCz4F3kwrK2tsVgkxAot+oll0qLD2tragQMHfInaj8Uc8PIGACGfH01Dtk8dVmiFln9e1UJkYWFhZGQkBmUUZfxb4YfxLQDyAd0CIB/QLQDyAd0CIB/QLQDyAd0CIB/QLegYqfff64joOM4UCE23VleF5ASoUqlEM6c8xxOPmMG71ZTXpyZjjHwyJZNJqwNX21MRcpwp4Mdijo72HGOm3fRokzS+CWDo+Lq/lCceMbuOpLs9wOT1qWkYRrFYpP3Zaa8y896gDqc6cpwpENt94az5a/YB5YdtHeFfvnviEXMzkXSnW3l9atLmqXxLR9oWkzZ2dThFuHecKbCF9oXr7+8/d+5cpVK5d+8eD7R1lunsjpGuJ/eNvLfmoY9GAVufke49YkrhVlNqn5r3799njO3fv58O9+3bxxj76KOPnE8RkXCcKeBHY7CZ962xvhu1s29FZ3eMwm7X9IgufDS6by9tfUa694jJiyMwt5pdvG+l9qkp+Bmja2hjV4dThPuNzgW2UD/ZGu7sLNP2FmYaXFG9d4jHAZf53p3PSIdThv9uNbvQrdQ+NR1CNrzYveNMgS2tW5fOMs2H1ILyPfKd43HAZb535zPSWbdG+4oVlm5tn8VDIu5T0332ugxxw9bSLZUrb1zbZZlDka+srPBS581kF1nvMt89kZzsujWi7VPTOoHHHne5ZHvKIUI3bKF5KcbYxx9/zBgT5j868q146NChcrlcr9fT6fTU1JR5kYAfPho34zPSGbncakbZp6ZgA81+Pf/8886nIkvkdNtsNmdmZlRV5d4JuvCtqCiKruuJROLdd9+t1+tTU1PdxeOS7nxGOhNBt5pS+9R8+eWXzTZ8/vnnPNDhlJmQHWcK+PESd9kHs3oxtF134ewss52LykwmQzOfmqZRV7mdj0YHXPZz2vmMNDrxiEmnAnOr6cl8skQ+NQ3DyOfz6XTadnGFwykD88mPPdgOq7NDwsFZJrNsiGOszydTAZunAW19NDrgPt9tfUYanXjEpHsDc6vZhW6l9qlJUNOjquri4qJwo8Mp944zBfzTrWL4sMNQbPYuCnJ/KVo4EVimdVdG1FONgruNZDJpdm/rK9lsdvfu3V2k2r/6E7nxLYgyW9CnZkQcZwpAt5FAFreaW82nZnQcZwpAt5FAIreaW8qnZnQcZwpE3Y/mFkGuuYCt41MzssnE+xYA+YBuAZAP6BYA+YBuAZAPH+el/HNqFBj0oTIGCbFCLkJjmbToUKvVfPpe5ct6qWq1+s4773geLeiIxcXFH/7wh9H/sBRvjhw58vbbb3serS+6BVFAUZT5+fnjx4+HbQjwHoxvAZAP6BYA+YBuAZAP6BYA+YBuAZAP6BYA+YBuAZAP6BYA+YBuAZAP6BYA+YBuAZAP6BYA+YBuAZAP6BYA+YBuAZAP6BYA+YBuAZAP6BYA+YBuAZAP6BYA+YBuAZAP6BYA+YBuAZAP6BYA+YBuAZAP6BYA+YBuAZAP6BYA+YBuAZAP6BYA+YBuAZAP6BYA+YBuAZAP+JuPD2fOnPnrX//KDz/77LNvfetb3/jGN+iwp6fnT3/60/79+0OyDnjJjrANAJ7x/e9/f25uzhyi6zr//YMf/ACijQ3oJ8eH06dPK4pie6qnp+fNN98M1hzgI+gnx4qf/OQnf/nLX6xlqijKw4cPn3vuuTCMAt6D922sOHPmzPbt24XAbdu2HT58GKKNE9BtrDhx4sSjR4+EwG3btp05cyYUe4BPQLexor+//6WXXhJeuYZhvP7662GZBPwAuo0bo6Oj5vHt9u3bBwcH+/v7QzQJeA50GzfeeOONHTv+93nPMIzTp0+HaA/wA+g2buzateuVV17h0t2xY0cymQzXJOA50G0MOX369Ndff80Y27Fjx2uvvbZr166wLQIeA93GkFdffZWWN3799denTp0K2xzgPdBtDHnyySffeOMNxlhvb++vf/3rsM0B3uP7+uS1tbX79+/7/RQgcODAAcbYT3/60/fffz9sW7Yczz777JEjR/x9huEz8/Pz/iYAgIgxNDTkt6wC+j+QIf8q6OHhYcbYrVu3wjbELX/4wx9+//vfW5c9WllYWBgZGYlBGUUBqid+g/FtbPnd737nRrRARqDb2GJefQFiBnQLgHxAtwDIB3QLgHxAtwDIRyR022w2S6VS/Ja/Z7PZbDYbthXe02w2p6enw7YiCKanp81760WHSOj20qVLqVSqUqkE87jV1dXJyUlFUSYnJ5eWloJ5qB/out5uIzj/aDably5d6u3tVRRFURRrw6Q8TsDm6bpeq9UKhYLta6BSqSSTyWQyaa1stqcGBwdHR0ebzaa/RneB3ws7aL3UhpcFY4xhGK1Wq1wu049iscgYo8MNGRoaCmAdTEeUy2VPMs1lGRmG0Wq1VFWtVquGKQMzmYxwWaPRYIw1Go3N29YpmUwmk8nYVqdisaiqaqvVarVa6XQ6n8+7OVWtVumUSwOCqSdbTreCSt0/N2q6JQkFrNtcLieolDKwWCwKVwZTmu2wFqumaYwxanEMw6jX64yxer3ufIpIp9O5XM7lo4OpJ5HoJ1vRdb1QKPCeGA2oeNeLD6544OrqKlsfdymKkkwmqQPcbDap/6Pr+uTkZDabpbpuJp1O+5EEYdBuPqxUKmQkN5uMZIxRqicnJx88eMBMfU6KxHyYy+WoR8dD/B5ON5vNqampo0ePCuG5XC6VSpVKJYd7dV0vlUpkaqFQoJ6nQ57wJwoF2jX05xa+8/u+ffsYYx999JHzKWJ4eHhqaipavWW/G4bu3rekpUajQW1hOp02DKNarfLfHFVVqT/WaDRUVaWGf3FxkTFWr9e5SqvVar1eF+5ttVrMt34yf7RwSO26OV28LHj/k5K/srJCHU4eCd3FD4VMoy6iews5LsuIuuWappkD6UbqmprfUUKEqqpS55OKiXqeDnlitClQlymy1m3KUuEaVVWdTxFkWKTGUxHVbSaT4eVnPpXL5cxVp16v8x4ajbXMEVIlptttxyeLi4vuhy5dlIeQKIdD4RR11ahv5v6urnFZRiROIZBCuAhXVlbM4QSpjg93qf2lgnNIXbsCdYM1ZxxCNryY2neXXeUtrVtC0zQSKj9FFZpPG+RyOa5hawe4Xalw+BSLG4LUrdG+VoWoW9vH8RDqGvDuj/lK4YVGMqAXmkPq2hWoG7zVbbu027Klx7eMsUKh8Nvf/lYovEQikU6nJyYmdF3Xdf3TTz89ePAgnaLBnpA8h/hLpZKqqocPH/YvCVuK/v7+er1eqVTGxsaEb543b940H/b19bH18nKg0wJ1xrYVoAbF4VRkiahuS6XSxMTEjRs3Dh06JJyiDL19+/a9e/fOnj0rnKXpnA1ZXl7+29/+Nj4+7om1PhHxqmMlkUiUy+VKpcJ7SQQJQ5jXcZk6lwW6IYINNPv1/PPPO5+KLBHVbSqVYozxd6kZeuWmUqlCoWB+W+bzecbY3NwcNfYOa3qazeadO3euXLlCh8vLy5OTk54nYTNQZT127FjYhjwGqdF5/RDNJF29etUcePLkScbYw4cP6ZBi2PD/5e4L1A0vv/yy2YbPP/+cBzqcMsM/C0cCvzvibsZOfNaUT11QE6hp2srKinDKWJ/YMH8cN0fC0TRNmI811mcphSvdTBV2Om4REsUPaRqMxnj8LP2mqZpWq5XJZPh8Jp9b5gln65OulJBGo0FTJsHPJ7dbXyHMYNGsFR/6FotFst85T2wL1Fifm3SYW+bxCDOO+Xw+nU7bLq5wOGVgPrmtEZZ2hOafMplMo9GguWXh84OqqnzqkqNpGtUYfj2PVpCBgDUqK52Wh5AoN4f8w1U+n+d1TtM0CqR6Qy80qtnmXDL81y0Jic/kCXkoXGz+jkL30vuTMVYsFil1znli2BWosf6tQYifYy1c81lqelRVXVxcFG50OEXNpcvlX1tIt51CjaK3cW6Ir+VhW/UDo6P1Uu5XDvlKO936QSaTwXopD1hYWAhm9y0gMDY2dvfu3VqtFq4ZtVrt4sWLwTxreXl5eXl5bGwsmMe5RCbdZrNZvqpxYGAgbHM8g89kRmslnR19fX2zs7PXrl1bXl4Oy4alpaU9e/YE8wHvwYMHN2/enJ2dpW9X0UEm3dL0cj6f51PB8WDv3r3CjyjT398/Nzd3586dsAwYGBiwfh30iUqlcvny5Qh6IZVpy7/x8fGIf3HtDkO2jYv7+vouXLgQthVBENlkyvS+BQAQ0C0A8gHdAiAf0C0A8hHQvFQMPrfSR8sYJMTK2toai2nSgqdWqwXwjQrvWwDkI6D3rUTuJ9shnR9N95AfzVgmLXjgRxMAYA90C4B8QLcAyAd0C4B8QLcAyAd0CzZLzNzzRdYHn5lI6FaxY3p6ulKpRD8HPcETz3pwz2elC/d80fXBZyISujUsW4QZhgX4/xMAAA9jSURBVDE4OFgoFKKfg55w7969iETSEbquj42NnT17ljZVo50cBekaj28fF7CFuVzugw8+mJiYsG7XXCqVCoXC3Nzc3Nzchx9+WCgUKDyRSFy8eNG6C3S08HsjHPd7F1ntMfuS8ce6DvBv3yBPPOttJpKu9wCLpXs+oiMffGawvxTr7+8/d+5cpVIxv0lsne45u3Wj68kNHO+qeejrTcDW95x7z3pwz8dCdc9HRNEHnxm/G4bNvG+N9b1wnX20Obt14z6EaF9itt5z69TXm/t21Nb3nHvPerxoAnPP1937Nq7u+YiO9kw2s+X2YW3XjpjDnZ3u2d7CTDvfUr13iMcBl+XRne85h1OG/+75utNtXN3zER354DMD3dqEu3S6Zz6klpXvte0cjwMuy6M733POujWHREe3to/jIfK653NO4IZAt4axXqi8ZW2XlQ7lvbKywoucN59dFInL8vBEcjHQrbHeTaA+cIips73XOofHLC7Ro6zbSM9LMcY+/vhjxpgw+dGRj7ZDhw6Vy2VyNj81NWVeIeCVrzczm/E95wzc87FA3PNJQaR122w2Z2ZmVFXlu5x34aNNURRd1xOJxLvvvluv16emprqLxyXd+Z5zBu75WIDu+cxEywefGb9f6C77YFYfajRRzAdIhLPTvXau7jKZDE17kgP7dvE4W+iy/9PO95zRiWc9OhWYez6v5pNj457PwHxyp/74OLlcjn8WN+PgdI+1cXVHVZk9Pj1o6+vNAfflYet7zujEsx7dG5h7vu50G2/3fB354DMTjG4Vw+elZ7QHit9PCYAg96mhhROBZVrXZUQ91Shs6p9MJkmEXpHNZnfv3t1F0oKpJ5Ee34KIE1f3fNH0wWcGuo0ccM/XEZ6754usDz4z0G3kgHu+jvDcPV9kffCZkckf3xZBurmAmLnnkyIteN8CIB/QLQDyAd0CIB/QLQDyAd0CIB8BzScHv5GfT8QmIVZinLSAGRoa8vsRvq9zXFtbo718QMCMjIycO3fuyJEjYRuy5Xj22Wf9znbfdQvCQlGU+fn548ePh20I8B6MbwGQD+gWAPmAbgGQD+gWAPmAbgGQD+gWAPmAbgGQD+gWAPmAbgGQD+gWAPmAbgGQD+gWAPmAbgGQD+gWAPmAbgGQD+gWAPmAbgGQD+gWAPmAbgGQD+gWAPmAbgGQD+gWAPmAbgGQD+gWAPmAbgGQD+gWAPmAbgGQD+gWAPmAbgGQD+gWAPmAbgGQD+gWAPnYEbYBwDM0Tfv666/NIY1G4+HDh/xw//79Tz75ZOB2Ae+Bv/n48Jvf/ObDDz9sd7anp6fRaDz11FNBmgR8Av3k+HDixIl2p7Zt2/arX/0Koo0N0G18eP3119t1gw3DGB0dDdge4B/QbXzo7e199dVXe3p6rKeeeOKJV199NXiTgE9At7Hi1KlTX331lRDY09Pz+uuv9/b2hmIS8APoNlYcO3bsm9/8phD45Zdfnjp1KhR7gE9At7Fi586dw8PDO3fuNAfu2rVrcHAwLJOAH0C3cePkyZNffPEFP+zp6UmlUoKSgezg+23cePTo0dNPP/3vf/+bh9y9e/cXv/hFiCYBz8H7Nm5s27bt1KlTfFb529/+9osvvhiuScBzoNsYkkqlvvzyS8bYzp0733zzzW3bUMpxA/3kGGIYxnPPPbe6usoY+/Of//zCCy+EbRHwGLTEMURRlDNnzjDG/u///g+ijSVB/x/onXfeqVarAT90C/Lf//6XMfbkk08ODw+HbcuW4NatW0E+Luj3bbVardVqAT/UD9577721tbWwrWjLrl27du/e/eyzz3Zxb61Wi0cZBcPa2tp7770X8END+P/t4cOHA26c/EBRlPPnzx8/fjxsQ9py586d7pZb0Cs6BmUUDAsLCyMjIwE/FOPb2II1UjEGugVAPqBbAOQDugVAPqBbAOQjirptNpulUimZTIZtiMdks9lsNhu2Fd7TbDanp6fDtsIzpqendV0P24oNiKJuL126lEqlKpVKMI9rNpvZbFZRFEVRSqVSMA/1A13XFUUJ+KHNZvPSpUu9vb2UgdaGSXmcgM3Tdb1WqxUKBdvXQKVSSSaTyWTSXNkGBwdHR0ebzWaAZnaOESxDQ0NDQ0MbXhaYbY1Go1qt0u9iscgYy+Vybm5kjM3Pz/tpWseUy2VPMs1lGRmG0Wq1VFWlDGy1WpSBmUxGuKzRaDDGGo3G5m3rlEwmk8lkbKtTsVhUVbXVarVarXQ6nc/n+alqtUqn3Dxifn4+eB1tdd1y0Xb63KjpliQUsG5zuZygUsrAYrEoXBl8zRaeLhigaRpjjJd+vV5njNXrdX5BOp122YKHotso9pOt6LpeKBR4T4wGVLzrxQdXPJD+CsMvSyaTS0tLFEJdI13XJycns9ns4cOHzU9hjPHm2VuEQbv5sFKpkJHcbDKSMUapnpycfPDgATP1OSkS82Eul6POHg/xezjdbDanpqaOHj0qhOdyuVQq5Tzi0HW9VCqRqYVCgTqlDnnCnygUaNfcv3+fMbZ//3463LdvH2Pso48+4hcMDw9PTU1Ft7cccDvR3fs2nU4zxhqNBjWT6XTaMAz6fwL95qiqSv2xRqOhqio1/IuLi4yxer1ObyTGWLVardfr5ns1TSPFrqysuEkI6/B9yx8tHFKTb04XLxre/6Tkr6ysUIeTR0J38UMh06iL6N5Cjssyom65pmnmQDKActL8+hJqmqqq1C+lYqJOqUOeGG0K1GWKrFWdslS4RlVVfkhPL5fLG0aOfvL/sFZBXn7mU7lczlx16vU676HRWMscIVViul0YunABMD/Ht0KiHA6FU9SLI8Pc39U1LsuIxCkEUggXIW8EzVeS6vhwl9pfKjiH1LUrUDdYc2bDkFar5bIyQLf/w7YKappGQuWnqELzGYVcLsc1zBtvM+1i5rFRXTRPUThYGJhuzSHR0a3t43gIdQ1498d8pfCuI4XQu84hde0K1A1d6LZdAq1At//DmmX5fF5V1ZWVFeEUVQI+K+gQg3M4YY3fwULo1kG3xnqrSn1gh4Qb/qfOeq91Do9ZxlxR1q0c81KlUmliYuLGjRuHDh0STpFub9++fe/evbNnzwpnaTrHPdb4owOlVCISiUS5XK5UKryXRJBmhCkfl6nrtEDbIdhAs1/PP/+8J5EHgBy6TaVSjLGDBw9aTyUSiXQ6nUqlCoWCeXI4n88zxubm5miW2OWaHrqYhlLRgSrrsWPHwjbkMUiNzkuLaCbp6tWr5sCTJ08yxrhjXophw305uivQdrz88stmGz7//HMeaManjwseEPD73U0fjM+a8qkLah01TeP9WPNHfJrYEAalPBKOpmnCfCzFzEfFrVbL/Rws67CfLCSKH9IMGfUk+Vn6TVM1ZBWf6uRzyzzhbL2DR7nUaDRoNiX4+eR26yuEGSyateJD32KxSPY754ltgRrrc5MOc8s8HmEyMp/Pp9Np23UXBuaTBdzUCWuzQiOlTCbTaDRobln4/EBDXyEe/mmHX8+j5TKgykfkcjlhGYazkR3pVkiUm0P+4Sqfz/M6p2kaBVKVohca1WxzLhn+65aExHNMEJVwsfkTC91L709qnih1znli2BWosf6tQYifwyyYz1Lpq6q6uLgo3Ehtops1XtBtlwgzUsHQqW47jTz4qsDpaL2Uy89mftNOt12TyWSwXspfFhYWsGthKIyNjd29ezf0TeRqtdrFixc9jHB5eXl5eXlsbMzDOL1FYt3yP/Gsrq4ODAyEbY5n8EnO6C6yW6evr292dvbatWvLy8th2bC0tLRnzx7zlOQmefDgwc2bN2dnZ/v6+ryK03Mk1i1NL+fz+StXroRti5fs3btX+BFl+vv75+bm7ty5E5YBAwMD3n69q1Qqly9f7u/v9zBOzwlhH1avGB8fHx8fD9sK7zFk8/zS19d34cKFsK3wDCnSIvH7FoAtC3QLgHxAtwDIB3QLgHxAtwBISMDrPIaGhsJOMQDeE7COwvHHd/78+eCf6y0jIyPnzp07cuRI2IZ4z/Xr1xljMSijYKhWqzMzMwE/NATdHjhwIMruJ10yMjJy5MiRGCTECnnQjGXSfCJ43WJ8C4B8QLcAyAd0C4B8QLcAyAd0C4B8QLfAS2T0qSmF40yBKOpWsWN6erpSqUiXv13giTtM+NS00s6nphyOMx8niro1LFv7GYYxODhYKBSky98uuHfvXkQi6Qhd18fGxs6ePUubJNL2q4J0jcf3fAzYwlwu98EHH0xMTAiulROJxMWLF8fGxiR6K0RRt4wxvtsA3yskkUjMzs4yxuTK304hz4NRiKRTZmdnE4kE7RfT19d34sQJxtjVq1cFx3xUsqHsJnHlypV2W6McPnz4mWeeoQomBRHVrS39/f3nzp2rVCrml4mts0xnd4x0Pblv5L01D300mrF1GOneHSZ8ajL/fWoSUXecKRDwemj3e3zamkd7WDv7VnR2xyjscs7WO2+d+mhk7vZhtXUY6d4dJi+mIH1qdrFXrtQ+NQn3G50LYP/kx2iXv+ZwZ2eZtrcw02bWVPUd4nE2b0Pdducw0uGUEYhPzS50K7VPTcK940wB6PYx3OjWpbNM8yG9r/ge+c7xOJu3oW67cxjprFtzSHR0a/s4HhJxn5puTjkA3T6GbSZSufLGtV1GOxT5ysoKL3XeuHZRYG5064nkYqBbI9o+Nd2ccgD+Cjbm448/ZowJ8x8d+VY8dOhQuVyu1+vpdHpqasq8SMArH42czTiMdAY+NZkP5SURMum22WzOzMyoqsq9E3ThW1FRFF3XE4nEu+++W6/Xp6amuovHDd05jHQGPjWZb+XFouw4UyDg97vLPpjV9yFNFPMxEuHsLLOdi8pMJkMzn5qmUVe5nY9GB5iLfnI7h5FGJ+4w6VSQPjU9mU+Wy6emgflkZzr1o8lp5+TSwVkma+Oikmoze3zy0NZHo7ORbr4D2TqMNDpxh0n3BulTswvdxsCnpnvHmQKh6FYxgl1uRl0g2glFahRFmZ+fD2AzF1o4EWQxdVdG1FONgpOOZDJpdmvskmw2u3v37i7sX1hYGBkZCVhHMo1vQZSR2qdm9B1nCkC3kQY+NTuiO5+aUjjOFIBuIw18anZEdz41pXCcKSCxH82tQMCjps0jo09N6QxmeN8CICPQLQDyAd0CIB/QLQDyEcK81Nra2sLCQvDP9Ry+tDBmrK2tMcbiUUYBEE41CHh9FvxoglgSsI6CXucIANg8GN8CIB/QLQDyAd0CIB/QLQDy8f8BrU3KGT35a8AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot the model\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the loss function and the optimizer\n",
    "# reference for choosing loss function: \n",
    "# https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_cv = np.array(y_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure accuracy on train set and test(cv) set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "508/508 [==============================] - 3s 5ms/step - loss: 0.5562 - accuracy: 0.7282 - val_loss: 0.5154 - val_accuracy: 0.7536\n",
      "Epoch 2/30\n",
      "508/508 [==============================] - 2s 4ms/step - loss: 0.4807 - accuracy: 0.7831 - val_loss: 0.4782 - val_accuracy: 0.7835\n",
      "Epoch 3/30\n",
      "508/508 [==============================] - 2s 3ms/step - loss: 0.4539 - accuracy: 0.7968 - val_loss: 0.4639 - val_accuracy: 0.7885\n",
      "Epoch 4/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.4394 - accuracy: 0.8037 - val_loss: 0.4558 - val_accuracy: 0.7924\n",
      "Epoch 5/30\n",
      "508/508 [==============================] - 2s 3ms/step - loss: 0.4293 - accuracy: 0.8090 - val_loss: 0.4513 - val_accuracy: 0.7962\n",
      "Epoch 6/30\n",
      "508/508 [==============================] - 2s 3ms/step - loss: 0.4216 - accuracy: 0.8147 - val_loss: 0.4516 - val_accuracy: 0.7962\n",
      "Epoch 7/30\n",
      "508/508 [==============================] - 2s 3ms/step - loss: 0.4155 - accuracy: 0.8177 - val_loss: 0.4502 - val_accuracy: 0.7979\n",
      "Epoch 8/30\n",
      "508/508 [==============================] - 2s 4ms/step - loss: 0.4095 - accuracy: 0.8215 - val_loss: 0.4470 - val_accuracy: 0.7996\n",
      "Epoch 9/30\n",
      "508/508 [==============================] - 2s 3ms/step - loss: 0.4049 - accuracy: 0.8254 - val_loss: 0.4462 - val_accuracy: 0.7979\n",
      "Epoch 10/30\n",
      "508/508 [==============================] - 2s 3ms/step - loss: 0.4002 - accuracy: 0.8275 - val_loss: 0.4467 - val_accuracy: 0.7979\n",
      "Epoch 11/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3950 - accuracy: 0.8303 - val_loss: 0.4486 - val_accuracy: 0.7940\n",
      "Epoch 12/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3901 - accuracy: 0.8358 - val_loss: 0.4462 - val_accuracy: 0.7996\n",
      "Epoch 13/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3854 - accuracy: 0.8377 - val_loss: 0.4455 - val_accuracy: 0.7996\n",
      "Epoch 14/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3803 - accuracy: 0.8416 - val_loss: 0.4430 - val_accuracy: 0.7990\n",
      "Epoch 15/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3752 - accuracy: 0.8434 - val_loss: 0.4479 - val_accuracy: 0.8001\n",
      "Epoch 16/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3702 - accuracy: 0.8470 - val_loss: 0.4454 - val_accuracy: 0.7984\n",
      "Epoch 17/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3651 - accuracy: 0.8481 - val_loss: 0.4483 - val_accuracy: 0.7929\n",
      "Epoch 18/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3597 - accuracy: 0.8537 - val_loss: 0.4502 - val_accuracy: 0.7918\n",
      "Epoch 19/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3539 - accuracy: 0.8550 - val_loss: 0.4465 - val_accuracy: 0.8023\n",
      "Epoch 20/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3478 - accuracy: 0.8577 - val_loss: 0.4481 - val_accuracy: 0.7918\n",
      "Epoch 21/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3422 - accuracy: 0.8611 - val_loss: 0.4523 - val_accuracy: 0.7929\n",
      "Epoch 22/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3360 - accuracy: 0.8652 - val_loss: 0.4505 - val_accuracy: 0.7957\n",
      "Epoch 23/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3300 - accuracy: 0.8665 - val_loss: 0.4568 - val_accuracy: 0.7913\n",
      "Epoch 24/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8716 - val_loss: 0.4561 - val_accuracy: 0.7907\n",
      "Epoch 25/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3169 - accuracy: 0.8761 - val_loss: 0.4633 - val_accuracy: 0.7946\n",
      "Epoch 26/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3105 - accuracy: 0.8782 - val_loss: 0.4614 - val_accuracy: 0.7879\n",
      "Epoch 27/30\n",
      "508/508 [==============================] - 2s 3ms/step - loss: 0.3040 - accuracy: 0.8820 - val_loss: 0.4630 - val_accuracy: 0.7907\n",
      "Epoch 28/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.2966 - accuracy: 0.8862 - val_loss: 0.4729 - val_accuracy: 0.7962\n",
      "Epoch 29/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.2897 - accuracy: 0.8885 - val_loss: 0.4854 - val_accuracy: 0.7885\n",
      "Epoch 30/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.2840 - accuracy: 0.8929 - val_loss: 0.4962 - val_accuracy: 0.7852\n"
     ]
    }
   ],
   "source": [
    "# fit\n",
    "history = model.fit(X_train_pca, y_train, epochs=30, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the history\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the validation data:  (4513, 1317)\n",
      "Number of features of the train set and validation set is same?:  True\n"
     ]
    }
   ],
   "source": [
    "## measure accuracy on test set\n",
    "# set validation data\n",
    "X_cv_scaled = mmscaler.transform(X_cv)\n",
    "X_cv_pca = pca.transform(X_cv_scaled)\n",
    "print(\"The shape of the validation data: \", X_cv_pca.shape)\n",
    "print(\"Number of features of the train set and validation set is same?: \", X_train_pca.shape[1] == X_cv_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45149680972099304, 0.8105472922325134]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_cv_pca, y_cv) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure accuracy using 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for creating new model\n",
    "def create_model():\n",
    "    # build model\n",
    "    model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "        keras.layers.Dense(100, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(10, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer3\", activation=\"sigmoid\") \n",
    "    ])\n",
    "    # compile\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "508/508 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7417\n",
      "Epoch 2/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4719 - accuracy: 0.7853\n",
      "Epoch 3/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4512 - accuracy: 0.7982\n",
      "Epoch 4/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4389 - accuracy: 0.8046\n",
      "Epoch 5/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4306 - accuracy: 0.8112\n",
      "Epoch 6/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4239 - accuracy: 0.8151\n",
      "Epoch 7/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4175 - accuracy: 0.8182\n",
      "Epoch 8/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4123 - accuracy: 0.8218\n",
      "Epoch 9/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4069 - accuracy: 0.8251\n",
      "Epoch 10/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4021 - accuracy: 0.8281\n",
      "Epoch 11/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3979 - accuracy: 0.8303\n",
      "Epoch 12/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3924 - accuracy: 0.8349\n",
      "Epoch 13/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3869 - accuracy: 0.8381\n",
      "Epoch 14/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3818 - accuracy: 0.8408\n",
      "Epoch 15/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3767 - accuracy: 0.8446\n",
      "Epoch 16/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3710 - accuracy: 0.8472\n",
      "Epoch 17/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3647 - accuracy: 0.8510\n",
      "Epoch 18/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3588 - accuracy: 0.8535\n",
      "Epoch 19/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8582\n",
      "Epoch 20/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8622\n",
      "Epoch 21/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3395 - accuracy: 0.8646\n",
      "Epoch 22/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3320 - accuracy: 0.8656\n",
      "Epoch 23/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3250 - accuracy: 0.8710\n",
      "Epoch 24/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3194 - accuracy: 0.8752\n",
      "Epoch 25/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3111 - accuracy: 0.8800\n",
      "Epoch 26/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3039 - accuracy: 0.8821\n",
      "Epoch 27/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2980 - accuracy: 0.8864\n",
      "Epoch 28/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2910 - accuracy: 0.8890\n",
      "Epoch 29/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2826 - accuracy: 0.8946\n",
      "Epoch 30/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2762 - accuracy: 0.8968\n",
      "57/57 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "508/508 [==============================] - 2s 2ms/step - loss: 0.5588 - accuracy: 0.7157\n",
      "Epoch 2/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4757 - accuracy: 0.7846\n",
      "Epoch 3/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4529 - accuracy: 0.7967\n",
      "Epoch 4/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4402 - accuracy: 0.8040\n",
      "Epoch 5/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4315 - accuracy: 0.8078\n",
      "Epoch 6/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4244 - accuracy: 0.8134\n",
      "Epoch 7/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4184 - accuracy: 0.8184\n",
      "Epoch 8/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4130 - accuracy: 0.8204\n",
      "Epoch 9/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4085 - accuracy: 0.8219\n",
      "Epoch 10/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4031 - accuracy: 0.8248\n",
      "Epoch 11/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3984 - accuracy: 0.8289\n",
      "Epoch 12/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3935 - accuracy: 0.8317\n",
      "Epoch 13/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3884 - accuracy: 0.8357\n",
      "Epoch 14/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3833 - accuracy: 0.8376\n",
      "Epoch 15/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3781 - accuracy: 0.8417\n",
      "Epoch 16/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3727 - accuracy: 0.8445\n",
      "Epoch 17/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3677 - accuracy: 0.8477\n",
      "Epoch 18/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3616 - accuracy: 0.8504\n",
      "Epoch 19/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3562 - accuracy: 0.8549\n",
      "Epoch 20/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3506 - accuracy: 0.8569\n",
      "Epoch 21/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3436 - accuracy: 0.8618\n",
      "Epoch 22/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3383 - accuracy: 0.8637\n",
      "Epoch 23/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3311 - accuracy: 0.8690\n",
      "Epoch 24/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3248 - accuracy: 0.8732\n",
      "Epoch 25/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3181 - accuracy: 0.8771\n",
      "Epoch 26/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3110 - accuracy: 0.8790\n",
      "Epoch 27/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3049 - accuracy: 0.8809\n",
      "Epoch 28/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2979 - accuracy: 0.8864\n",
      "Epoch 29/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.2913 - accuracy: 0.8886\n",
      "Epoch 30/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.2833 - accuracy: 0.8928\n",
      "57/57 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "508/508 [==============================] - 2s 2ms/step - loss: 0.5484 - accuracy: 0.7305\n",
      "Epoch 2/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4745 - accuracy: 0.7861\n",
      "Epoch 3/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4502 - accuracy: 0.7991\n",
      "Epoch 4/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4361 - accuracy: 0.8064\n",
      "Epoch 5/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4264 - accuracy: 0.8148\n",
      "Epoch 6/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4187 - accuracy: 0.8197\n",
      "Epoch 7/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4125 - accuracy: 0.8219\n",
      "Epoch 8/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4064 - accuracy: 0.8255\n",
      "Epoch 9/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4009 - accuracy: 0.8286\n",
      "Epoch 10/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3956 - accuracy: 0.8332\n",
      "Epoch 11/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3896 - accuracy: 0.8368\n",
      "Epoch 12/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3844 - accuracy: 0.8401\n",
      "Epoch 13/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3788 - accuracy: 0.8427\n",
      "Epoch 14/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3730 - accuracy: 0.8483\n",
      "Epoch 15/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3676 - accuracy: 0.8519\n",
      "Epoch 16/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3619 - accuracy: 0.8545\n",
      "Epoch 17/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3565 - accuracy: 0.8589\n",
      "Epoch 18/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3501 - accuracy: 0.8622\n",
      "Epoch 19/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3432 - accuracy: 0.8642\n",
      "Epoch 20/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3377 - accuracy: 0.8691\n",
      "Epoch 21/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3313 - accuracy: 0.8710\n",
      "Epoch 22/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3252 - accuracy: 0.8765\n",
      "Epoch 23/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3184 - accuracy: 0.8768\n",
      "Epoch 24/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3127 - accuracy: 0.8790\n",
      "Epoch 25/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3058 - accuracy: 0.8848\n",
      "Epoch 26/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2986 - accuracy: 0.8890\n",
      "Epoch 27/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2910 - accuracy: 0.8910\n",
      "Epoch 28/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2862 - accuracy: 0.8949\n",
      "Epoch 29/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2784 - accuracy: 0.8991\n",
      "Epoch 30/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2719 - accuracy: 0.9001\n",
      "57/57 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "508/508 [==============================] - 2s 2ms/step - loss: 0.5481 - accuracy: 0.7276\n",
      "Epoch 2/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4758 - accuracy: 0.7854\n",
      "Epoch 3/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4512 - accuracy: 0.8015\n",
      "Epoch 4/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4377 - accuracy: 0.8057\n",
      "Epoch 5/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4285 - accuracy: 0.8126\n",
      "Epoch 6/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4213 - accuracy: 0.8163\n",
      "Epoch 7/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4149 - accuracy: 0.8217\n",
      "Epoch 8/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4093 - accuracy: 0.8253\n",
      "Epoch 9/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4042 - accuracy: 0.8283\n",
      "Epoch 10/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3996 - accuracy: 0.8315\n",
      "Epoch 11/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3947 - accuracy: 0.8343\n",
      "Epoch 12/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3894 - accuracy: 0.8384\n",
      "Epoch 13/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3846 - accuracy: 0.8408\n",
      "Epoch 14/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3796 - accuracy: 0.8430\n",
      "Epoch 15/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3750 - accuracy: 0.8465\n",
      "Epoch 16/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3694 - accuracy: 0.8483\n",
      "Epoch 17/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3642 - accuracy: 0.8502\n",
      "Epoch 18/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3590 - accuracy: 0.8532\n",
      "Epoch 19/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3528 - accuracy: 0.8563\n",
      "Epoch 20/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3470 - accuracy: 0.8608\n",
      "Epoch 21/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3420 - accuracy: 0.8618\n",
      "Epoch 22/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3362 - accuracy: 0.8661\n",
      "Epoch 23/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3302 - accuracy: 0.8686\n",
      "Epoch 24/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3237 - accuracy: 0.8712\n",
      "Epoch 25/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3179 - accuracy: 0.8775\n",
      "Epoch 26/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3122 - accuracy: 0.8777\n",
      "Epoch 27/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3064 - accuracy: 0.8827\n",
      "Epoch 28/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2988 - accuracy: 0.8858\n",
      "Epoch 29/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2938 - accuracy: 0.8875\n",
      "Epoch 30/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2864 - accuracy: 0.8928\n",
      "57/57 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "508/508 [==============================] - 2s 2ms/step - loss: 0.5695 - accuracy: 0.7148\n",
      "Epoch 2/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4946 - accuracy: 0.7738\n",
      "Epoch 3/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4652 - accuracy: 0.7909\n",
      "Epoch 4/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4493 - accuracy: 0.8000\n",
      "Epoch 5/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4404 - accuracy: 0.8038\n",
      "Epoch 6/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4325 - accuracy: 0.8090\n",
      "Epoch 7/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4264 - accuracy: 0.8128\n",
      "Epoch 8/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4208 - accuracy: 0.8155\n",
      "Epoch 9/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4163 - accuracy: 0.8188\n",
      "Epoch 10/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4116 - accuracy: 0.8213\n",
      "Epoch 11/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4068 - accuracy: 0.8230\n",
      "Epoch 12/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4018 - accuracy: 0.8274\n",
      "Epoch 13/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3976 - accuracy: 0.8291\n",
      "Epoch 14/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3931 - accuracy: 0.8307\n",
      "Epoch 15/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3886 - accuracy: 0.8347\n",
      "Epoch 16/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3833 - accuracy: 0.8375\n",
      "Epoch 17/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3787 - accuracy: 0.8409\n",
      "Epoch 18/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3740 - accuracy: 0.8437\n",
      "Epoch 19/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3681 - accuracy: 0.8462\n",
      "Epoch 20/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3636 - accuracy: 0.8510\n",
      "Epoch 21/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3582 - accuracy: 0.8539\n",
      "Epoch 22/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3531 - accuracy: 0.8569\n",
      "Epoch 23/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3475 - accuracy: 0.8595\n",
      "Epoch 24/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3415 - accuracy: 0.8615\n",
      "Epoch 25/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3357 - accuracy: 0.8656\n",
      "Epoch 26/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3294 - accuracy: 0.8706\n",
      "Epoch 27/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3228 - accuracy: 0.8724\n",
      "Epoch 28/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3161 - accuracy: 0.8777\n",
      "Epoch 29/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3103 - accuracy: 0.8794\n",
      "Epoch 30/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3044 - accuracy: 0.8828\n",
      "57/57 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "508/508 [==============================] - 2s 2ms/step - loss: 0.5503 - accuracy: 0.7284\n",
      "Epoch 2/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4782 - accuracy: 0.7837\n",
      "Epoch 3/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4523 - accuracy: 0.7973\n",
      "Epoch 4/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4386 - accuracy: 0.8035\n",
      "Epoch 5/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4292 - accuracy: 0.8083\n",
      "Epoch 6/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.4220 - accuracy: 0.8124\n",
      "Epoch 7/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4167 - accuracy: 0.8168\n",
      "Epoch 8/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4114 - accuracy: 0.8200\n",
      "Epoch 9/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.4061 - accuracy: 0.8241\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4012 - accuracy: 0.8267\n",
      "Epoch 11/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3965 - accuracy: 0.8295\n",
      "Epoch 12/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3918 - accuracy: 0.8326\n",
      "Epoch 13/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3873 - accuracy: 0.8345\n",
      "Epoch 14/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3820 - accuracy: 0.8389\n",
      "Epoch 15/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3769 - accuracy: 0.8406\n",
      "Epoch 16/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3713 - accuracy: 0.8442\n",
      "Epoch 17/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3663 - accuracy: 0.8485\n",
      "Epoch 18/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3611 - accuracy: 0.8504\n",
      "Epoch 19/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3547 - accuracy: 0.8546\n",
      "Epoch 20/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3488 - accuracy: 0.8565\n",
      "Epoch 21/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3431 - accuracy: 0.8611\n",
      "Epoch 22/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3376 - accuracy: 0.8647\n",
      "Epoch 23/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.8696\n",
      "Epoch 24/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8715\n",
      "Epoch 25/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3182 - accuracy: 0.8755\n",
      "Epoch 26/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3113 - accuracy: 0.8814\n",
      "Epoch 27/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3051 - accuracy: 0.8829\n",
      "Epoch 28/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2995 - accuracy: 0.8849\n",
      "Epoch 29/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.2912 - accuracy: 0.8917\n",
      "Epoch 30/30\n",
      "508/508 [==============================] - 2s 3ms/step - loss: 0.2846 - accuracy: 0.8927\n",
      "57/57 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "508/508 [==============================] - 2s 3ms/step - loss: 0.5450 - accuracy: 0.7331\n",
      "Epoch 2/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.4787 - accuracy: 0.7838\n",
      "Epoch 3/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.4545 - accuracy: 0.7975\n",
      "Epoch 4/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.4409 - accuracy: 0.8048\n",
      "Epoch 5/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4316 - accuracy: 0.8117\n",
      "Epoch 6/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4237 - accuracy: 0.8168\n",
      "Epoch 7/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4177 - accuracy: 0.8185\n",
      "Epoch 8/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4121 - accuracy: 0.8231\n",
      "Epoch 9/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4072 - accuracy: 0.8259\n",
      "Epoch 10/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4026 - accuracy: 0.8278\n",
      "Epoch 11/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3974 - accuracy: 0.8307\n",
      "Epoch 12/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3927 - accuracy: 0.8342\n",
      "Epoch 13/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3877 - accuracy: 0.8368\n",
      "Epoch 14/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3828 - accuracy: 0.8395\n",
      "Epoch 15/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3781 - accuracy: 0.8419\n",
      "Epoch 16/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3725 - accuracy: 0.8449\n",
      "Epoch 17/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3672 - accuracy: 0.8496\n",
      "Epoch 18/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3616 - accuracy: 0.8535\n",
      "Epoch 19/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3556 - accuracy: 0.8533\n",
      "Epoch 20/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3508 - accuracy: 0.8578\n",
      "Epoch 21/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3441 - accuracy: 0.8628\n",
      "Epoch 22/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.8662\n",
      "Epoch 23/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.8698\n",
      "Epoch 24/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3254 - accuracy: 0.8725\n",
      "Epoch 25/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3191 - accuracy: 0.8745\n",
      "Epoch 26/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3124 - accuracy: 0.8756\n",
      "Epoch 27/30\n",
      "508/508 [==============================] - 2s 3ms/step - loss: 0.3058 - accuracy: 0.8820\n",
      "Epoch 28/30\n",
      "508/508 [==============================] - 2s 3ms/step - loss: 0.2992 - accuracy: 0.8861\n",
      "Epoch 29/30\n",
      "508/508 [==============================] - 2s 3ms/step - loss: 0.2918 - accuracy: 0.8890\n",
      "Epoch 30/30\n",
      "508/508 [==============================] - 2s 3ms/step - loss: 0.2858 - accuracy: 0.8894\n",
      "57/57 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "508/508 [==============================] - 2s 2ms/step - loss: 0.5315 - accuracy: 0.7412\n",
      "Epoch 2/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.4707 - accuracy: 0.7854\n",
      "Epoch 3/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4503 - accuracy: 0.7981\n",
      "Epoch 4/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.4388 - accuracy: 0.8064\n",
      "Epoch 5/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4300 - accuracy: 0.8100\n",
      "Epoch 6/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4234 - accuracy: 0.8151\n",
      "Epoch 7/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.4178 - accuracy: 0.8187\n",
      "Epoch 8/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4127 - accuracy: 0.8217\n",
      "Epoch 9/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4079 - accuracy: 0.8241\n",
      "Epoch 10/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.4031 - accuracy: 0.8276\n",
      "Epoch 11/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3981 - accuracy: 0.8309\n",
      "Epoch 12/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3939 - accuracy: 0.8334\n",
      "Epoch 13/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3893 - accuracy: 0.8367\n",
      "Epoch 14/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3841 - accuracy: 0.8403\n",
      "Epoch 15/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3798 - accuracy: 0.8416\n",
      "Epoch 16/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3748 - accuracy: 0.8447\n",
      "Epoch 17/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3691 - accuracy: 0.8481\n",
      "Epoch 18/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3639 - accuracy: 0.8504\n",
      "Epoch 19/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3588 - accuracy: 0.8545\n",
      "Epoch 20/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3525 - accuracy: 0.8568\n",
      "Epoch 21/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.8608\n",
      "Epoch 22/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3421 - accuracy: 0.8637\n",
      "Epoch 23/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3356 - accuracy: 0.8662\n",
      "Epoch 24/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3299 - accuracy: 0.8712\n",
      "Epoch 25/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3235 - accuracy: 0.8750\n",
      "Epoch 26/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3182 - accuracy: 0.8764\n",
      "Epoch 27/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3115 - accuracy: 0.8803\n",
      "Epoch 28/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3065 - accuracy: 0.8834\n",
      "Epoch 29/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.2977 - accuracy: 0.8901\n",
      "Epoch 30/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2922 - accuracy: 0.8924\n",
      "57/57 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "508/508 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7398\n",
      "Epoch 2/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4671 - accuracy: 0.7859\n",
      "Epoch 3/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4466 - accuracy: 0.7993\n",
      "Epoch 4/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4345 - accuracy: 0.8063\n",
      "Epoch 5/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4257 - accuracy: 0.8099\n",
      "Epoch 6/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4192 - accuracy: 0.8141\n",
      "Epoch 7/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4129 - accuracy: 0.8168\n",
      "Epoch 8/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4079 - accuracy: 0.8210\n",
      "Epoch 9/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4027 - accuracy: 0.8244\n",
      "Epoch 10/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3973 - accuracy: 0.8276\n",
      "Epoch 11/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3929 - accuracy: 0.8311\n",
      "Epoch 12/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3877 - accuracy: 0.8349\n",
      "Epoch 13/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3826 - accuracy: 0.8370\n",
      "Epoch 14/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3772 - accuracy: 0.8386\n",
      "Epoch 15/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3718 - accuracy: 0.8445\n",
      "Epoch 16/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3660 - accuracy: 0.8472\n",
      "Epoch 17/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3603 - accuracy: 0.8488\n",
      "Epoch 18/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3543 - accuracy: 0.8514\n",
      "Epoch 19/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3485 - accuracy: 0.8570\n",
      "Epoch 20/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3417 - accuracy: 0.8595\n",
      "Epoch 21/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3354 - accuracy: 0.8648\n",
      "Epoch 22/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3292 - accuracy: 0.8693\n",
      "Epoch 23/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3222 - accuracy: 0.8707\n",
      "Epoch 24/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3160 - accuracy: 0.8778\n",
      "Epoch 25/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3081 - accuracy: 0.8808\n",
      "Epoch 26/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3027 - accuracy: 0.8826\n",
      "Epoch 27/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2958 - accuracy: 0.8867\n",
      "Epoch 28/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.2877 - accuracy: 0.8917\n",
      "Epoch 29/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2809 - accuracy: 0.8946\n",
      "Epoch 30/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.2739 - accuracy: 0.8983\n",
      "57/57 [==============================] - 0s 1ms/step\n",
      "Epoch 1/30\n",
      "508/508 [==============================] - 2s 2ms/step - loss: 0.5954 - accuracy: 0.6872\n",
      "Epoch 2/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.5068 - accuracy: 0.7692\n",
      "Epoch 3/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4691 - accuracy: 0.7894\n",
      "Epoch 4/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4505 - accuracy: 0.8005\n",
      "Epoch 5/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4387 - accuracy: 0.8060\n",
      "Epoch 6/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4303 - accuracy: 0.8115\n",
      "Epoch 7/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4231 - accuracy: 0.8169\n",
      "Epoch 8/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4174 - accuracy: 0.8180\n",
      "Epoch 9/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4121 - accuracy: 0.8217\n",
      "Epoch 10/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4073 - accuracy: 0.8241\n",
      "Epoch 11/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.4025 - accuracy: 0.8267\n",
      "Epoch 12/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3978 - accuracy: 0.8294\n",
      "Epoch 13/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3929 - accuracy: 0.8326\n",
      "Epoch 14/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3882 - accuracy: 0.8370\n",
      "Epoch 15/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3831 - accuracy: 0.8395\n",
      "Epoch 16/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3779 - accuracy: 0.8426\n",
      "Epoch 17/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3731 - accuracy: 0.8456\n",
      "Epoch 18/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3680 - accuracy: 0.8463\n",
      "Epoch 19/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3618 - accuracy: 0.8501\n",
      "Epoch 20/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3562 - accuracy: 0.8552\n",
      "Epoch 21/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3507 - accuracy: 0.8574\n",
      "Epoch 22/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3446 - accuracy: 0.8639\n",
      "Epoch 23/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3385 - accuracy: 0.8653\n",
      "Epoch 24/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3319 - accuracy: 0.8677\n",
      "Epoch 25/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3270 - accuracy: 0.8722\n",
      "Epoch 26/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3195 - accuracy: 0.8755\n",
      "Epoch 27/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3132 - accuracy: 0.8808\n",
      "Epoch 28/30\n",
      "508/508 [==============================] - 1s 2ms/step - loss: 0.3063 - accuracy: 0.8839\n",
      "Epoch 29/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.3004 - accuracy: 0.8844\n",
      "Epoch 30/30\n",
      "508/508 [==============================] - 1s 3ms/step - loss: 0.2946 - accuracy: 0.8879\n",
      "57/57 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under RoC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1fold</th>\n",
       "      <td>0.799003</td>\n",
       "      <td>604.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.751244</td>\n",
       "      <td>0.837325</td>\n",
       "      <td>0.787484</td>\n",
       "      <td>0.751244</td>\n",
       "      <td>0.797495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2fold</th>\n",
       "      <td>0.814958</td>\n",
       "      <td>592.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.736318</td>\n",
       "      <td>0.878122</td>\n",
       "      <td>0.829132</td>\n",
       "      <td>0.736318</td>\n",
       "      <td>0.817407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3fold</th>\n",
       "      <td>0.802216</td>\n",
       "      <td>587.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.730100</td>\n",
       "      <td>0.860140</td>\n",
       "      <td>0.807428</td>\n",
       "      <td>0.730100</td>\n",
       "      <td>0.803065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4fold</th>\n",
       "      <td>0.788366</td>\n",
       "      <td>620.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.771144</td>\n",
       "      <td>0.802198</td>\n",
       "      <td>0.757946</td>\n",
       "      <td>0.771144</td>\n",
       "      <td>0.785761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5fold</th>\n",
       "      <td>0.814958</td>\n",
       "      <td>641.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.797264</td>\n",
       "      <td>0.829171</td>\n",
       "      <td>0.789409</td>\n",
       "      <td>0.797264</td>\n",
       "      <td>0.812630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6fold</th>\n",
       "      <td>0.792244</td>\n",
       "      <td>592.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.736318</td>\n",
       "      <td>0.837163</td>\n",
       "      <td>0.784106</td>\n",
       "      <td>0.736318</td>\n",
       "      <td>0.791101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7fold</th>\n",
       "      <td>0.783380</td>\n",
       "      <td>598.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0.743781</td>\n",
       "      <td>0.815185</td>\n",
       "      <td>0.763729</td>\n",
       "      <td>0.743781</td>\n",
       "      <td>0.781082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8fold</th>\n",
       "      <td>0.801108</td>\n",
       "      <td>589.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0.732587</td>\n",
       "      <td>0.856144</td>\n",
       "      <td>0.803547</td>\n",
       "      <td>0.732587</td>\n",
       "      <td>0.801494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9fold</th>\n",
       "      <td>0.811080</td>\n",
       "      <td>624.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.839161</td>\n",
       "      <td>0.794904</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.809217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10fold</th>\n",
       "      <td>0.793352</td>\n",
       "      <td>607.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>825.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.755915</td>\n",
       "      <td>0.823353</td>\n",
       "      <td>0.774235</td>\n",
       "      <td>0.755915</td>\n",
       "      <td>0.791133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy     TP     FP     TN     FN  Sensitivity  Specificity  \\\n",
       "1fold   0.799003  604.0  163.0  839.0  200.0     0.751244     0.837325   \n",
       "2fold   0.814958  592.0  122.0  879.0  212.0     0.736318     0.878122   \n",
       "3fold   0.802216  587.0  140.0  861.0  217.0     0.730100     0.860140   \n",
       "4fold   0.788366  620.0  198.0  803.0  184.0     0.771144     0.802198   \n",
       "5fold   0.814958  641.0  171.0  830.0  163.0     0.797264     0.829171   \n",
       "6fold   0.792244  592.0  163.0  838.0  212.0     0.736318     0.837163   \n",
       "7fold   0.783380  598.0  185.0  816.0  206.0     0.743781     0.815185   \n",
       "8fold   0.801108  589.0  144.0  857.0  215.0     0.732587     0.856144   \n",
       "9fold   0.811080  624.0  161.0  840.0  180.0     0.776119     0.839161   \n",
       "10fold  0.793352  607.0  177.0  825.0  196.0     0.755915     0.823353   \n",
       "\n",
       "        Precision    Recall  Area Under RoC Curve  \n",
       "1fold    0.787484  0.751244              0.797495  \n",
       "2fold    0.829132  0.736318              0.817407  \n",
       "3fold    0.807428  0.730100              0.803065  \n",
       "4fold    0.757946  0.771144              0.785761  \n",
       "5fold    0.789409  0.797264              0.812630  \n",
       "6fold    0.784106  0.736318              0.791101  \n",
       "7fold    0.763729  0.743781              0.781082  \n",
       "8fold    0.803547  0.732587              0.801494  \n",
       "9fold    0.794904  0.776119              0.809217  \n",
       "10fold   0.774235  0.755915              0.791133  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implement 10-fold cross-validation manually and evaluate it using major matics \n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# make data from for evaluation \n",
    "columns = ['Accuracy', 'TP', 'FP', 'TN', 'FN', 'Sensitivity', 'Specificity', 'Precision', 'Recall', 'Area Under RoC Curve']\n",
    "tenFold_evaluation = pd.DataFrame(columns = columns)\n",
    "tenFold_evaluation\n",
    "\n",
    "# split data into 10 groups\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "strtfdKFold = StratifiedKFold(n_splits=10)\n",
    "kfold = strtfdKFold.split(X_train, y_train)\n",
    "\n",
    "\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    # create model\n",
    "    model = create_model()\n",
    "    \n",
    "    # fit and predict\n",
    "    history = model.fit(X_train_pca[train], y_train[train], epochs=30)\n",
    "    pred = model.predict(X_train_pca[test]).reshape(-1) >= 0.5\n",
    "    \n",
    "    # evaluate\n",
    "    accuracy = sum(pred==y_train[test]) / len(pred)\n",
    "    cm = confusion_matrix(y_train[test], pred)\n",
    "    tp, fp, tn, fn = cm[1,1], cm[0,1], cm[0,0], cm[1,0]\n",
    "    sensitivity = tp / (tp+fn)\n",
    "    specificity = tn / (tn+fp)\n",
    "    precision = precision_score(y_train[test], pred)\n",
    "    recall = recall_score(y_train[test], pred)\n",
    "    auc = roc_auc_score(pred, y_train[test])\n",
    "    \n",
    "    index = str(k+1) + \"fold\"\n",
    "    tenFold_evaluation.loc[index] = [accuracy, tp, fp, tn, fn, sensitivity, specificity, precision, recall, auc]\n",
    "\n",
    "tenFold_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under RoC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1fold</th>\n",
       "      <td>0.799003</td>\n",
       "      <td>604.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.751244</td>\n",
       "      <td>0.837325</td>\n",
       "      <td>0.787484</td>\n",
       "      <td>0.751244</td>\n",
       "      <td>0.797495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2fold</th>\n",
       "      <td>0.814958</td>\n",
       "      <td>592.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.736318</td>\n",
       "      <td>0.878122</td>\n",
       "      <td>0.829132</td>\n",
       "      <td>0.736318</td>\n",
       "      <td>0.817407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3fold</th>\n",
       "      <td>0.802216</td>\n",
       "      <td>587.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.730100</td>\n",
       "      <td>0.860140</td>\n",
       "      <td>0.807428</td>\n",
       "      <td>0.730100</td>\n",
       "      <td>0.803065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4fold</th>\n",
       "      <td>0.788366</td>\n",
       "      <td>620.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.771144</td>\n",
       "      <td>0.802198</td>\n",
       "      <td>0.757946</td>\n",
       "      <td>0.771144</td>\n",
       "      <td>0.785761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5fold</th>\n",
       "      <td>0.814958</td>\n",
       "      <td>641.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.797264</td>\n",
       "      <td>0.829171</td>\n",
       "      <td>0.789409</td>\n",
       "      <td>0.797264</td>\n",
       "      <td>0.812630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6fold</th>\n",
       "      <td>0.792244</td>\n",
       "      <td>592.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.736318</td>\n",
       "      <td>0.837163</td>\n",
       "      <td>0.784106</td>\n",
       "      <td>0.736318</td>\n",
       "      <td>0.791101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7fold</th>\n",
       "      <td>0.783380</td>\n",
       "      <td>598.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0.743781</td>\n",
       "      <td>0.815185</td>\n",
       "      <td>0.763729</td>\n",
       "      <td>0.743781</td>\n",
       "      <td>0.781082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8fold</th>\n",
       "      <td>0.801108</td>\n",
       "      <td>589.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0.732587</td>\n",
       "      <td>0.856144</td>\n",
       "      <td>0.803547</td>\n",
       "      <td>0.732587</td>\n",
       "      <td>0.801494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9fold</th>\n",
       "      <td>0.811080</td>\n",
       "      <td>624.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.839161</td>\n",
       "      <td>0.794904</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.809217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10fold</th>\n",
       "      <td>0.793352</td>\n",
       "      <td>607.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>825.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.755915</td>\n",
       "      <td>0.823353</td>\n",
       "      <td>0.774235</td>\n",
       "      <td>0.755915</td>\n",
       "      <td>0.791133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy     TP     FP     TN     FN  Sensitivity  Specificity  \\\n",
       "1fold   0.799003  604.0  163.0  839.0  200.0     0.751244     0.837325   \n",
       "2fold   0.814958  592.0  122.0  879.0  212.0     0.736318     0.878122   \n",
       "3fold   0.802216  587.0  140.0  861.0  217.0     0.730100     0.860140   \n",
       "4fold   0.788366  620.0  198.0  803.0  184.0     0.771144     0.802198   \n",
       "5fold   0.814958  641.0  171.0  830.0  163.0     0.797264     0.829171   \n",
       "6fold   0.792244  592.0  163.0  838.0  212.0     0.736318     0.837163   \n",
       "7fold   0.783380  598.0  185.0  816.0  206.0     0.743781     0.815185   \n",
       "8fold   0.801108  589.0  144.0  857.0  215.0     0.732587     0.856144   \n",
       "9fold   0.811080  624.0  161.0  840.0  180.0     0.776119     0.839161   \n",
       "10fold  0.793352  607.0  177.0  825.0  196.0     0.755915     0.823353   \n",
       "\n",
       "        Precision    Recall  Area Under RoC Curve  \n",
       "1fold    0.787484  0.751244              0.797495  \n",
       "2fold    0.829132  0.736318              0.817407  \n",
       "3fold    0.807428  0.730100              0.803065  \n",
       "4fold    0.757946  0.771144              0.785761  \n",
       "5fold    0.789409  0.797264              0.812630  \n",
       "6fold    0.784106  0.736318              0.791101  \n",
       "7fold    0.763729  0.743781              0.781082  \n",
       "8fold    0.803547  0.732587              0.801494  \n",
       "9fold    0.794904  0.776119              0.809217  \n",
       "10fold   0.774235  0.755915              0.791133  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tenFold_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Experiment with various parameters that control the learning\n",
    "For example, the learning rate, the number and size of layers, the number of iterations, batch size, epochs and momentum, and validation threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16245, 1317)\n",
      "(1806, 1317)\n"
     ]
    }
   ],
   "source": [
    "# for faster testing, split train data set into train - cv set again (rather than using 10-fold cross validation)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_temp, X_test_temp, y_train_temp, y_test_temp = train_test_split(X_train_pca, y_train, test_size=0.1, random_state=42)\n",
    "print(X_train_temp.shape)\n",
    "print(X_test_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under RoC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Accuracy, TP, FP, TN, FN, Sensitivity, Specificity, Precision, Recall, Area Under RoC Curve]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make data from for evaluation \n",
    "columns = ['Accuracy', 'TP', 'FP', 'TN', 'FN', 'Sensitivity', 'Specificity', 'Precision', 'Recall', 'Area Under RoC Curve']\n",
    "architecture_evaluation = pd.DataFrame(columns = columns)\n",
    "architecture_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a fitted model, predict on new data and record the result of evaluation \n",
    "def evaluate_model(model, description):    \n",
    "    # predict\n",
    "    pred = model.predict(X_test_temp).reshape(-1) >= 0.5    \n",
    "    # evaluate\n",
    "    accuracy = sum(pred==y_test_temp) / len(pred)\n",
    "    cm = confusion_matrix(y_test_temp, pred)\n",
    "    tp, fp, tn, fn = cm[1,1], cm[0,1], cm[0,0], cm[1,0]\n",
    "    sensitivity = tp / (tp+fn)\n",
    "    specificity = tn / (tn+fp)\n",
    "    precision = precision_score(y_test_temp, pred)\n",
    "    recall = recall_score(y_test_temp, pred)\n",
    "    auc = roc_auc_score(pred, y_test_temp)\n",
    "    \n",
    "    index = description\n",
    "    architecture_evaluation.loc[index] = [accuracy, tp, fp, tn, fn, sensitivity, specificity, precision, recall, auc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment with the number and size of layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.6049 - accuracy: 0.6806 - val_loss: 0.5616 - val_accuracy: 0.7280\n",
      "Epoch 2/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.5219 - accuracy: 0.7538 - val_loss: 0.5040 - val_accuracy: 0.7649\n",
      "Epoch 3/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.4806 - accuracy: 0.7795 - val_loss: 0.4742 - val_accuracy: 0.7717\n",
      "Epoch 4/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.4589 - accuracy: 0.7918 - val_loss: 0.4581 - val_accuracy: 0.7797\n",
      "Epoch 5/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.4450 - accuracy: 0.8017 - val_loss: 0.4490 - val_accuracy: 0.7902\n",
      "Epoch 6/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.4354 - accuracy: 0.8068 - val_loss: 0.4405 - val_accuracy: 0.7957\n",
      "Epoch 7/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.4276 - accuracy: 0.8109 - val_loss: 0.4394 - val_accuracy: 0.7871\n",
      "Epoch 8/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.4214 - accuracy: 0.8146 - val_loss: 0.4332 - val_accuracy: 0.7988\n",
      "Epoch 9/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.4159 - accuracy: 0.8181 - val_loss: 0.4305 - val_accuracy: 0.8074\n",
      "Epoch 10/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.4115 - accuracy: 0.8208 - val_loss: 0.4299 - val_accuracy: 0.8055\n",
      "Epoch 11/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.4070 - accuracy: 0.8228 - val_loss: 0.4276 - val_accuracy: 0.8055\n",
      "Epoch 12/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.4022 - accuracy: 0.8271 - val_loss: 0.4267 - val_accuracy: 0.8018\n",
      "Epoch 13/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3980 - accuracy: 0.8291 - val_loss: 0.4279 - val_accuracy: 0.8068\n",
      "Epoch 14/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3934 - accuracy: 0.8326 - val_loss: 0.4294 - val_accuracy: 0.8031\n",
      "Epoch 15/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3889 - accuracy: 0.8334 - val_loss: 0.4272 - val_accuracy: 0.8031\n",
      "Epoch 16/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3841 - accuracy: 0.8368 - val_loss: 0.4277 - val_accuracy: 0.8031\n",
      "Epoch 17/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3796 - accuracy: 0.8381 - val_loss: 0.4294 - val_accuracy: 0.8055\n",
      "Epoch 18/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3747 - accuracy: 0.8441 - val_loss: 0.4266 - val_accuracy: 0.8092\n",
      "Epoch 19/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3701 - accuracy: 0.8460 - val_loss: 0.4284 - val_accuracy: 0.8043\n",
      "Epoch 20/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3645 - accuracy: 0.8479 - val_loss: 0.4254 - val_accuracy: 0.8074\n",
      "Epoch 21/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3593 - accuracy: 0.8525 - val_loss: 0.4286 - val_accuracy: 0.8049\n",
      "Epoch 22/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3540 - accuracy: 0.8540 - val_loss: 0.4321 - val_accuracy: 0.8000\n",
      "Epoch 23/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.8590 - val_loss: 0.4368 - val_accuracy: 0.7982\n",
      "Epoch 24/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3418 - accuracy: 0.8620 - val_loss: 0.4310 - val_accuracy: 0.8018\n",
      "Epoch 25/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3368 - accuracy: 0.8648 - val_loss: 0.4350 - val_accuracy: 0.7994\n",
      "Epoch 26/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3294 - accuracy: 0.8689 - val_loss: 0.4392 - val_accuracy: 0.7938\n",
      "Epoch 27/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3242 - accuracy: 0.8713 - val_loss: 0.4335 - val_accuracy: 0.7994\n",
      "Epoch 28/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3176 - accuracy: 0.8742 - val_loss: 0.4381 - val_accuracy: 0.7951\n",
      "Epoch 29/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3111 - accuracy: 0.8783 - val_loss: 0.4518 - val_accuracy: 0.7926\n",
      "Epoch 30/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3053 - accuracy: 0.8800 - val_loss: 0.4481 - val_accuracy: 0.7895\n",
      "57/57 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under RoC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layer1 100, Layer2 10, Layer3 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>578.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.888105</td>\n",
       "      <td>0.838897</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.813808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Accuracy     TP     FP     TN     FN  \\\n",
       "Layer1 100, Layer2 10, Layer3 1  0.807863  578.0  111.0  881.0  236.0   \n",
       "\n",
       "                                 Sensitivity  Specificity  Precision  \\\n",
       "Layer1 100, Layer2 10, Layer3 1     0.710074     0.888105   0.838897   \n",
       "\n",
       "                                   Recall  Area Under RoC Curve  \n",
       "Layer1 100, Layer2 10, Layer3 1  0.710074              0.813808  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model with different size of layer (layer1 - 100, layer2 - 10, layer3 - 1)\n",
    "model1 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "    keras.layers.Dense(100, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(10, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer3\", activation=\"sigmoid\") \n",
    "])\n",
    "# complie\n",
    "model1.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "# fit\n",
    "history1 = model1.fit(X_train_temp, y_train_temp, epochs=30, validation_split=0.1)\n",
    "\n",
    "# evaluate\n",
    "description = \"Layer1 100, Layer2 10, Layer3 1\"\n",
    "evaluate_model(model1, description)\n",
    "architecture_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.5326 - accuracy: 0.7341 - val_loss: 0.4753 - val_accuracy: 0.7723\n",
      "Epoch 2/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.4624 - accuracy: 0.7897 - val_loss: 0.4491 - val_accuracy: 0.7951\n",
      "Epoch 3/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.4440 - accuracy: 0.8021 - val_loss: 0.4386 - val_accuracy: 0.7969\n",
      "Epoch 4/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.4326 - accuracy: 0.8088 - val_loss: 0.4305 - val_accuracy: 0.8098\n",
      "Epoch 5/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.4245 - accuracy: 0.8129 - val_loss: 0.4261 - val_accuracy: 0.8031\n",
      "Epoch 6/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.4176 - accuracy: 0.8178 - val_loss: 0.4223 - val_accuracy: 0.8117\n",
      "Epoch 7/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.4116 - accuracy: 0.8223 - val_loss: 0.4202 - val_accuracy: 0.8098\n",
      "Epoch 8/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.4058 - accuracy: 0.8253 - val_loss: 0.4174 - val_accuracy: 0.8129\n",
      "Epoch 9/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.4006 - accuracy: 0.8265 - val_loss: 0.4163 - val_accuracy: 0.8129\n",
      "Epoch 10/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3948 - accuracy: 0.8306 - val_loss: 0.4134 - val_accuracy: 0.8172\n",
      "Epoch 11/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3894 - accuracy: 0.8356 - val_loss: 0.4124 - val_accuracy: 0.8178\n",
      "Epoch 12/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3840 - accuracy: 0.8384 - val_loss: 0.4156 - val_accuracy: 0.8111\n",
      "Epoch 13/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3783 - accuracy: 0.8405 - val_loss: 0.4130 - val_accuracy: 0.8135\n",
      "Epoch 14/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3725 - accuracy: 0.8441 - val_loss: 0.4151 - val_accuracy: 0.8062\n",
      "Epoch 15/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3665 - accuracy: 0.8465 - val_loss: 0.4131 - val_accuracy: 0.8123\n",
      "Epoch 16/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.3600 - accuracy: 0.8476 - val_loss: 0.4151 - val_accuracy: 0.8129\n",
      "Epoch 17/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3540 - accuracy: 0.8547 - val_loss: 0.4102 - val_accuracy: 0.8160\n",
      "Epoch 18/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3473 - accuracy: 0.8573 - val_loss: 0.4187 - val_accuracy: 0.8135\n",
      "Epoch 19/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3398 - accuracy: 0.8637 - val_loss: 0.4158 - val_accuracy: 0.8098\n",
      "Epoch 20/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.3322 - accuracy: 0.8673 - val_loss: 0.4184 - val_accuracy: 0.8166\n",
      "Epoch 21/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.3251 - accuracy: 0.8684 - val_loss: 0.4199 - val_accuracy: 0.8111\n",
      "Epoch 22/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.3176 - accuracy: 0.8739 - val_loss: 0.4186 - val_accuracy: 0.8154\n",
      "Epoch 23/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3098 - accuracy: 0.8776 - val_loss: 0.4171 - val_accuracy: 0.8135\n",
      "Epoch 24/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.3014 - accuracy: 0.8828 - val_loss: 0.4196 - val_accuracy: 0.8123\n",
      "Epoch 25/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.2933 - accuracy: 0.8872 - val_loss: 0.4327 - val_accuracy: 0.8043\n",
      "Epoch 26/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.2860 - accuracy: 0.8908 - val_loss: 0.4339 - val_accuracy: 0.8135\n",
      "Epoch 27/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.2770 - accuracy: 0.8966 - val_loss: 0.4280 - val_accuracy: 0.8111\n",
      "Epoch 28/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.2690 - accuracy: 0.9021 - val_loss: 0.4369 - val_accuracy: 0.8080\n",
      "Epoch 29/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.2615 - accuracy: 0.9036 - val_loss: 0.4442 - val_accuracy: 0.8086\n",
      "Epoch 30/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.2523 - accuracy: 0.9083 - val_loss: 0.4454 - val_accuracy: 0.8092\n",
      "57/57 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under RoC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layer1 100, Layer2 10, Layer3 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>578.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.888105</td>\n",
       "      <td>0.838897</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.813808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 200, Layer2 20, Layer3 1</th>\n",
       "      <td>0.807309</td>\n",
       "      <td>631.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.833669</td>\n",
       "      <td>0.792714</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.805763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Accuracy     TP     FP     TN     FN  \\\n",
       "Layer1 100, Layer2 10, Layer3 1  0.807863  578.0  111.0  881.0  236.0   \n",
       "Layer1 200, Layer2 20, Layer3 1  0.807309  631.0  165.0  827.0  183.0   \n",
       "\n",
       "                                 Sensitivity  Specificity  Precision  \\\n",
       "Layer1 100, Layer2 10, Layer3 1     0.710074     0.888105   0.838897   \n",
       "Layer1 200, Layer2 20, Layer3 1     0.775184     0.833669   0.792714   \n",
       "\n",
       "                                   Recall  Area Under RoC Curve  \n",
       "Layer1 100, Layer2 10, Layer3 1  0.710074              0.813808  \n",
       "Layer1 200, Layer2 20, Layer3 1  0.775184              0.805763  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model with different size of layer (layer1 - 200, layer2 - 20, layer3 - 1)\n",
    "model2 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "    keras.layers.Dense(200, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(20, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer3\", activation=\"sigmoid\") \n",
    "])\n",
    "# complie\n",
    "model2.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "# fit\n",
    "history2 = model2.fit(X_train_temp, y_train_temp, epochs=30, validation_split=0.1)\n",
    "\n",
    "# evaluate\n",
    "description = \"Layer1 200, Layer2 20, Layer3 1\"\n",
    "evaluate_model(model2, description)\n",
    "architecture_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.5473 - accuracy: 0.7218 - val_loss: 0.4967 - val_accuracy: 0.7637\n",
      "Epoch 2/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4709 - accuracy: 0.7840 - val_loss: 0.4604 - val_accuracy: 0.7809\n",
      "Epoch 3/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4482 - accuracy: 0.7962 - val_loss: 0.4473 - val_accuracy: 0.7920\n",
      "Epoch 4/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4364 - accuracy: 0.8045 - val_loss: 0.4412 - val_accuracy: 0.7963\n",
      "Epoch 5/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4281 - accuracy: 0.8092 - val_loss: 0.4344 - val_accuracy: 0.8025\n",
      "Epoch 6/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4211 - accuracy: 0.8150 - val_loss: 0.4353 - val_accuracy: 0.8006\n",
      "Epoch 7/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4149 - accuracy: 0.8193 - val_loss: 0.4278 - val_accuracy: 0.8086\n",
      "Epoch 8/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4089 - accuracy: 0.8207 - val_loss: 0.4277 - val_accuracy: 0.8068\n",
      "Epoch 9/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4026 - accuracy: 0.8254 - val_loss: 0.4285 - val_accuracy: 0.8080\n",
      "Epoch 10/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3978 - accuracy: 0.8267 - val_loss: 0.4245 - val_accuracy: 0.8068\n",
      "Epoch 11/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3916 - accuracy: 0.8309 - val_loss: 0.4203 - val_accuracy: 0.8111\n",
      "Epoch 12/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3861 - accuracy: 0.8341 - val_loss: 0.4191 - val_accuracy: 0.8148\n",
      "Epoch 13/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3799 - accuracy: 0.8376 - val_loss: 0.4179 - val_accuracy: 0.8123\n",
      "Epoch 14/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3735 - accuracy: 0.8406 - val_loss: 0.4170 - val_accuracy: 0.8086\n",
      "Epoch 15/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3673 - accuracy: 0.8440 - val_loss: 0.4189 - val_accuracy: 0.8105\n",
      "Epoch 16/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3608 - accuracy: 0.8488 - val_loss: 0.4183 - val_accuracy: 0.8092\n",
      "Epoch 17/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3546 - accuracy: 0.8518 - val_loss: 0.4208 - val_accuracy: 0.8105\n",
      "Epoch 18/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3471 - accuracy: 0.8575 - val_loss: 0.4176 - val_accuracy: 0.8166\n",
      "Epoch 19/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3392 - accuracy: 0.8594 - val_loss: 0.4220 - val_accuracy: 0.8092\n",
      "Epoch 20/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3319 - accuracy: 0.8646 - val_loss: 0.4275 - val_accuracy: 0.8074\n",
      "Epoch 21/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3244 - accuracy: 0.8687 - val_loss: 0.4196 - val_accuracy: 0.8049\n",
      "Epoch 22/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3159 - accuracy: 0.8735 - val_loss: 0.4214 - val_accuracy: 0.8074\n",
      "Epoch 23/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3074 - accuracy: 0.8777 - val_loss: 0.4314 - val_accuracy: 0.8049\n",
      "Epoch 24/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.2995 - accuracy: 0.8799 - val_loss: 0.4309 - val_accuracy: 0.8055\n",
      "Epoch 25/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.2898 - accuracy: 0.8872 - val_loss: 0.4310 - val_accuracy: 0.8055\n",
      "Epoch 26/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.2816 - accuracy: 0.8889 - val_loss: 0.4327 - val_accuracy: 0.8092\n",
      "Epoch 27/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.2728 - accuracy: 0.8947 - val_loss: 0.4450 - val_accuracy: 0.8049\n",
      "Epoch 28/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.2632 - accuracy: 0.8984 - val_loss: 0.4489 - val_accuracy: 0.8043\n",
      "Epoch 29/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.2547 - accuracy: 0.9043 - val_loss: 0.4386 - val_accuracy: 0.8043\n",
      "Epoch 30/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.2455 - accuracy: 0.9100 - val_loss: 0.4506 - val_accuracy: 0.8037\n",
      "57/57 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under RoC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layer1 100, Layer2 10, Layer3 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>578.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.888105</td>\n",
       "      <td>0.838897</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.813808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 200, Layer2 20, Layer3 1</th>\n",
       "      <td>0.807309</td>\n",
       "      <td>631.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.833669</td>\n",
       "      <td>0.792714</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.805763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 300, Layer2 30, Layer3 1</th>\n",
       "      <td>0.800664</td>\n",
       "      <td>640.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.774818</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.798634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Accuracy     TP     FP     TN     FN  \\\n",
       "Layer1 100, Layer2 10, Layer3 1  0.807863  578.0  111.0  881.0  236.0   \n",
       "Layer1 200, Layer2 20, Layer3 1  0.807309  631.0  165.0  827.0  183.0   \n",
       "Layer1 300, Layer2 30, Layer3 1  0.800664  640.0  186.0  806.0  174.0   \n",
       "\n",
       "                                 Sensitivity  Specificity  Precision  \\\n",
       "Layer1 100, Layer2 10, Layer3 1     0.710074     0.888105   0.838897   \n",
       "Layer1 200, Layer2 20, Layer3 1     0.775184     0.833669   0.792714   \n",
       "Layer1 300, Layer2 30, Layer3 1     0.786241     0.812500   0.774818   \n",
       "\n",
       "                                   Recall  Area Under RoC Curve  \n",
       "Layer1 100, Layer2 10, Layer3 1  0.710074              0.813808  \n",
       "Layer1 200, Layer2 20, Layer3 1  0.775184              0.805763  \n",
       "Layer1 300, Layer2 30, Layer3 1  0.786241              0.798634  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model with different size of layer (layer1 - 300, layer2 - 30, layer3 - 1)\n",
    "model3 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "    keras.layers.Dense(300, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(30, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer3\", activation=\"sigmoid\") \n",
    "])\n",
    "# complie\n",
    "model3.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "# fit\n",
    "history3 = model3.fit(X_train_temp, y_train_temp, epochs=30, validation_split=0.1)\n",
    "\n",
    "# evaluate\n",
    "description = \"Layer1 300, Layer2 30, Layer3 1\"\n",
    "evaluate_model(model3, description)\n",
    "architecture_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.5327 - accuracy: 0.7325 - val_loss: 0.4909 - val_accuracy: 0.7557\n",
      "Epoch 2/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4689 - accuracy: 0.7826 - val_loss: 0.4627 - val_accuracy: 0.7840\n",
      "Epoch 3/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4496 - accuracy: 0.7960 - val_loss: 0.4505 - val_accuracy: 0.7963\n",
      "Epoch 4/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4376 - accuracy: 0.8051 - val_loss: 0.4463 - val_accuracy: 0.7914\n",
      "Epoch 5/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4295 - accuracy: 0.8098 - val_loss: 0.4372 - val_accuracy: 0.7994\n",
      "Epoch 6/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4220 - accuracy: 0.8153 - val_loss: 0.4356 - val_accuracy: 0.8037\n",
      "Epoch 7/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4157 - accuracy: 0.8195 - val_loss: 0.4309 - val_accuracy: 0.8012\n",
      "Epoch 8/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4102 - accuracy: 0.8235 - val_loss: 0.4288 - val_accuracy: 0.8018\n",
      "Epoch 9/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4039 - accuracy: 0.8260 - val_loss: 0.4311 - val_accuracy: 0.8018\n",
      "Epoch 10/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3985 - accuracy: 0.8267 - val_loss: 0.4242 - val_accuracy: 0.8018\n",
      "Epoch 11/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3927 - accuracy: 0.8319 - val_loss: 0.4245 - val_accuracy: 0.8049\n",
      "Epoch 12/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3869 - accuracy: 0.8364 - val_loss: 0.4210 - val_accuracy: 0.8043\n",
      "Epoch 13/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3804 - accuracy: 0.8379 - val_loss: 0.4227 - val_accuracy: 0.8031\n",
      "Epoch 14/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3747 - accuracy: 0.8411 - val_loss: 0.4234 - val_accuracy: 0.8080\n",
      "Epoch 15/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3680 - accuracy: 0.8457 - val_loss: 0.4271 - val_accuracy: 0.8037\n",
      "Epoch 16/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3607 - accuracy: 0.8502 - val_loss: 0.4296 - val_accuracy: 0.7988\n",
      "Epoch 17/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3542 - accuracy: 0.8536 - val_loss: 0.4230 - val_accuracy: 0.7994\n",
      "Epoch 18/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3464 - accuracy: 0.8594 - val_loss: 0.4240 - val_accuracy: 0.8062\n",
      "Epoch 19/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3379 - accuracy: 0.8641 - val_loss: 0.4241 - val_accuracy: 0.8000\n",
      "Epoch 20/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3309 - accuracy: 0.8657 - val_loss: 0.4240 - val_accuracy: 0.8031\n",
      "Epoch 21/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3223 - accuracy: 0.8700 - val_loss: 0.4271 - val_accuracy: 0.8086\n",
      "Epoch 22/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3137 - accuracy: 0.8754 - val_loss: 0.4239 - val_accuracy: 0.8012\n",
      "Epoch 23/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3044 - accuracy: 0.8806 - val_loss: 0.4354 - val_accuracy: 0.8018\n",
      "Epoch 24/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.2943 - accuracy: 0.8872 - val_loss: 0.4279 - val_accuracy: 0.8012\n",
      "Epoch 25/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.2865 - accuracy: 0.8899 - val_loss: 0.4290 - val_accuracy: 0.7994\n",
      "Epoch 26/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.2782 - accuracy: 0.8958 - val_loss: 0.4417 - val_accuracy: 0.7994\n",
      "Epoch 27/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.2683 - accuracy: 0.9013 - val_loss: 0.4487 - val_accuracy: 0.8049\n",
      "Epoch 28/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.2585 - accuracy: 0.9059 - val_loss: 0.4569 - val_accuracy: 0.7982\n",
      "Epoch 29/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.2490 - accuracy: 0.9091 - val_loss: 0.4470 - val_accuracy: 0.8043\n",
      "Epoch 30/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.2383 - accuracy: 0.9152 - val_loss: 0.4558 - val_accuracy: 0.7975\n",
      "57/57 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under RoC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layer1 100, Layer2 10, Layer3 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>578.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.888105</td>\n",
       "      <td>0.838897</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.813808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 200, Layer2 20, Layer3 1</th>\n",
       "      <td>0.807309</td>\n",
       "      <td>631.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.833669</td>\n",
       "      <td>0.792714</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.805763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 300, Layer2 30, Layer3 1</th>\n",
       "      <td>0.800664</td>\n",
       "      <td>640.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.774818</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.798634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>635.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.819556</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.799827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Accuracy     TP     FP     TN     FN  \\\n",
       "Layer1 100, Layer2 10, Layer3 1  0.807863  578.0  111.0  881.0  236.0   \n",
       "Layer1 200, Layer2 20, Layer3 1  0.807309  631.0  165.0  827.0  183.0   \n",
       "Layer1 300, Layer2 30, Layer3 1  0.800664  640.0  186.0  806.0  174.0   \n",
       "Layer1 400, Layer2 40, Layer3 1  0.801772  635.0  179.0  813.0  179.0   \n",
       "\n",
       "                                 Sensitivity  Specificity  Precision  \\\n",
       "Layer1 100, Layer2 10, Layer3 1     0.710074     0.888105   0.838897   \n",
       "Layer1 200, Layer2 20, Layer3 1     0.775184     0.833669   0.792714   \n",
       "Layer1 300, Layer2 30, Layer3 1     0.786241     0.812500   0.774818   \n",
       "Layer1 400, Layer2 40, Layer3 1     0.780098     0.819556   0.780098   \n",
       "\n",
       "                                   Recall  Area Under RoC Curve  \n",
       "Layer1 100, Layer2 10, Layer3 1  0.710074              0.813808  \n",
       "Layer1 200, Layer2 20, Layer3 1  0.775184              0.805763  \n",
       "Layer1 300, Layer2 30, Layer3 1  0.786241              0.798634  \n",
       "Layer1 400, Layer2 40, Layer3 1  0.780098              0.799827  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model with different size of layer (layer1 - 400, layer2 - 40, layer3 - 1)\n",
    "model4 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "    keras.layers.Dense(400, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(40, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer3\", activation=\"sigmoid\") \n",
    "])\n",
    "# complie\n",
    "model4.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "# fit\n",
    "history4 = model4.fit(X_train_temp, y_train_temp, epochs=30, validation_split=0.1)\n",
    "\n",
    "# evaluate\n",
    "description = \"Layer1 400, Layer2 40, Layer3 1\"\n",
    "evaluate_model(model4, description)\n",
    "architecture_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.5105 - accuracy: 0.7461 - val_loss: 0.4719 - val_accuracy: 0.7754\n",
      "Epoch 2/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.4552 - accuracy: 0.7910 - val_loss: 0.4537 - val_accuracy: 0.7846\n",
      "Epoch 3/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.4395 - accuracy: 0.8023 - val_loss: 0.4442 - val_accuracy: 0.7951\n",
      "Epoch 4/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4290 - accuracy: 0.8094 - val_loss: 0.4386 - val_accuracy: 0.7957\n",
      "Epoch 5/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4209 - accuracy: 0.8147 - val_loss: 0.4341 - val_accuracy: 0.8018\n",
      "Epoch 6/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4140 - accuracy: 0.8173 - val_loss: 0.4306 - val_accuracy: 0.8049\n",
      "Epoch 7/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4073 - accuracy: 0.8240 - val_loss: 0.4297 - val_accuracy: 0.8062\n",
      "Epoch 8/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4006 - accuracy: 0.8258 - val_loss: 0.4382 - val_accuracy: 0.7982\n",
      "Epoch 9/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3944 - accuracy: 0.8300 - val_loss: 0.4253 - val_accuracy: 0.8055\n",
      "Epoch 10/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3878 - accuracy: 0.8329 - val_loss: 0.4218 - val_accuracy: 0.8049\n",
      "Epoch 11/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3814 - accuracy: 0.8369 - val_loss: 0.4222 - val_accuracy: 0.8031\n",
      "Epoch 12/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3744 - accuracy: 0.8404 - val_loss: 0.4242 - val_accuracy: 0.8055\n",
      "Epoch 13/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3667 - accuracy: 0.8446 - val_loss: 0.4217 - val_accuracy: 0.8055\n",
      "Epoch 14/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3599 - accuracy: 0.8482 - val_loss: 0.4228 - val_accuracy: 0.8068\n",
      "Epoch 15/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3523 - accuracy: 0.8521 - val_loss: 0.4200 - val_accuracy: 0.8111\n",
      "Epoch 16/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3447 - accuracy: 0.8577 - val_loss: 0.4205 - val_accuracy: 0.8037\n",
      "Epoch 17/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3362 - accuracy: 0.8620 - val_loss: 0.4196 - val_accuracy: 0.8098\n",
      "Epoch 18/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3270 - accuracy: 0.8667 - val_loss: 0.4233 - val_accuracy: 0.8092\n",
      "Epoch 19/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3186 - accuracy: 0.8727 - val_loss: 0.4215 - val_accuracy: 0.8105\n",
      "Epoch 20/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3079 - accuracy: 0.8780 - val_loss: 0.4235 - val_accuracy: 0.8111\n",
      "Epoch 21/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3000 - accuracy: 0.8824 - val_loss: 0.4403 - val_accuracy: 0.7969\n",
      "Epoch 22/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.2904 - accuracy: 0.8884 - val_loss: 0.4308 - val_accuracy: 0.8025\n",
      "Epoch 23/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.2808 - accuracy: 0.8913 - val_loss: 0.4295 - val_accuracy: 0.8049\n",
      "Epoch 24/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.2712 - accuracy: 0.8960 - val_loss: 0.4391 - val_accuracy: 0.8055\n",
      "Epoch 25/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.2618 - accuracy: 0.9016 - val_loss: 0.4397 - val_accuracy: 0.7963\n",
      "Epoch 26/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.2518 - accuracy: 0.9049 - val_loss: 0.4496 - val_accuracy: 0.8006\n",
      "Epoch 27/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.2419 - accuracy: 0.9106 - val_loss: 0.4486 - val_accuracy: 0.8006\n",
      "Epoch 28/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.2329 - accuracy: 0.9164 - val_loss: 0.4668 - val_accuracy: 0.7957\n",
      "Epoch 29/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.2210 - accuracy: 0.9209 - val_loss: 0.4578 - val_accuracy: 0.7969\n",
      "Epoch 30/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.2146 - accuracy: 0.9222 - val_loss: 0.5064 - val_accuracy: 0.7982\n",
      "57/57 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under RoC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layer1 100, Layer2 10, Layer3 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>578.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.888105</td>\n",
       "      <td>0.838897</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.813808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 200, Layer2 20, Layer3 1</th>\n",
       "      <td>0.807309</td>\n",
       "      <td>631.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.833669</td>\n",
       "      <td>0.792714</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.805763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 300, Layer2 30, Layer3 1</th>\n",
       "      <td>0.800664</td>\n",
       "      <td>640.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.774818</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.798634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>635.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.819556</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.799827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 500, Layer2 50, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>587.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.867944</td>\n",
       "      <td>0.817549</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.804455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Accuracy     TP     FP     TN     FN  \\\n",
       "Layer1 100, Layer2 10, Layer3 1  0.807863  578.0  111.0  881.0  236.0   \n",
       "Layer1 200, Layer2 20, Layer3 1  0.807309  631.0  165.0  827.0  183.0   \n",
       "Layer1 300, Layer2 30, Layer3 1  0.800664  640.0  186.0  806.0  174.0   \n",
       "Layer1 400, Layer2 40, Layer3 1  0.801772  635.0  179.0  813.0  179.0   \n",
       "Layer1 500, Layer2 50, Layer3 1  0.801772  587.0  131.0  861.0  227.0   \n",
       "\n",
       "                                 Sensitivity  Specificity  Precision  \\\n",
       "Layer1 100, Layer2 10, Layer3 1     0.710074     0.888105   0.838897   \n",
       "Layer1 200, Layer2 20, Layer3 1     0.775184     0.833669   0.792714   \n",
       "Layer1 300, Layer2 30, Layer3 1     0.786241     0.812500   0.774818   \n",
       "Layer1 400, Layer2 40, Layer3 1     0.780098     0.819556   0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1     0.721130     0.867944   0.817549   \n",
       "\n",
       "                                   Recall  Area Under RoC Curve  \n",
       "Layer1 100, Layer2 10, Layer3 1  0.710074              0.813808  \n",
       "Layer1 200, Layer2 20, Layer3 1  0.775184              0.805763  \n",
       "Layer1 300, Layer2 30, Layer3 1  0.786241              0.798634  \n",
       "Layer1 400, Layer2 40, Layer3 1  0.780098              0.799827  \n",
       "Layer1 500, Layer2 50, Layer3 1  0.721130              0.804455  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model with different size of layer (layer1 - 500, layer2 - 50, layer3 - 1)\n",
    "model5 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "    keras.layers.Dense(500, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(50, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer3\", activation=\"sigmoid\") \n",
    "])\n",
    "# complie\n",
    "model5.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "# fit\n",
    "history5 = model5.fit(X_train_temp, y_train_temp, epochs=30, validation_split=0.1)\n",
    "\n",
    "# evaluate\n",
    "description = \"Layer1 500, Layer2 50, Layer3 1\"\n",
    "evaluate_model(model5, description)\n",
    "architecture_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.5531 - accuracy: 0.7216 - val_loss: 0.5026 - val_accuracy: 0.7612\n",
      "Epoch 2/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.4827 - accuracy: 0.7818 - val_loss: 0.4706 - val_accuracy: 0.7889\n",
      "Epoch 3/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.4606 - accuracy: 0.7931 - val_loss: 0.4550 - val_accuracy: 0.7945\n",
      "Epoch 4/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.4473 - accuracy: 0.8022 - val_loss: 0.4460 - val_accuracy: 0.7975\n",
      "Epoch 5/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.4383 - accuracy: 0.8071 - val_loss: 0.4399 - val_accuracy: 0.8000\n",
      "Epoch 6/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.4309 - accuracy: 0.8120 - val_loss: 0.4391 - val_accuracy: 0.7975\n",
      "Epoch 7/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.4250 - accuracy: 0.8153 - val_loss: 0.4351 - val_accuracy: 0.7994\n",
      "Epoch 8/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.4197 - accuracy: 0.8196 - val_loss: 0.4337 - val_accuracy: 0.8049\n",
      "Epoch 9/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.4145 - accuracy: 0.8218 - val_loss: 0.4342 - val_accuracy: 0.8055\n",
      "Epoch 10/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.4100 - accuracy: 0.8243 - val_loss: 0.4306 - val_accuracy: 0.8055\n",
      "Epoch 11/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.4051 - accuracy: 0.8278 - val_loss: 0.4288 - val_accuracy: 0.8105\n",
      "Epoch 12/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.4008 - accuracy: 0.8306 - val_loss: 0.4277 - val_accuracy: 0.8098\n",
      "Epoch 13/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3960 - accuracy: 0.8330 - val_loss: 0.4266 - val_accuracy: 0.8074\n",
      "Epoch 14/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3909 - accuracy: 0.8360 - val_loss: 0.4251 - val_accuracy: 0.8111\n",
      "Epoch 15/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3867 - accuracy: 0.8384 - val_loss: 0.4239 - val_accuracy: 0.8111\n",
      "Epoch 16/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3819 - accuracy: 0.8421 - val_loss: 0.4270 - val_accuracy: 0.8117\n",
      "Epoch 17/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3769 - accuracy: 0.8436 - val_loss: 0.4302 - val_accuracy: 0.8111\n",
      "Epoch 18/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3726 - accuracy: 0.8459 - val_loss: 0.4248 - val_accuracy: 0.8154\n",
      "Epoch 19/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3673 - accuracy: 0.8500 - val_loss: 0.4329 - val_accuracy: 0.8018\n",
      "Epoch 20/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3630 - accuracy: 0.8520 - val_loss: 0.4249 - val_accuracy: 0.8092\n",
      "Epoch 21/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3585 - accuracy: 0.8541 - val_loss: 0.4263 - val_accuracy: 0.8068\n",
      "Epoch 22/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3533 - accuracy: 0.8566 - val_loss: 0.4285 - val_accuracy: 0.8074\n",
      "Epoch 23/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3482 - accuracy: 0.8605 - val_loss: 0.4299 - val_accuracy: 0.8025\n",
      "Epoch 24/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3429 - accuracy: 0.8631 - val_loss: 0.4315 - val_accuracy: 0.8080\n",
      "Epoch 25/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3379 - accuracy: 0.8663 - val_loss: 0.4309 - val_accuracy: 0.8129\n",
      "Epoch 26/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3328 - accuracy: 0.8685 - val_loss: 0.4278 - val_accuracy: 0.8086\n",
      "Epoch 27/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3268 - accuracy: 0.8724 - val_loss: 0.4319 - val_accuracy: 0.8111\n",
      "Epoch 28/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3215 - accuracy: 0.8746 - val_loss: 0.4346 - val_accuracy: 0.8068\n",
      "Epoch 29/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3165 - accuracy: 0.8778 - val_loss: 0.4304 - val_accuracy: 0.8129\n",
      "Epoch 30/30\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3107 - accuracy: 0.8791 - val_loss: 0.4325 - val_accuracy: 0.8154\n",
      "57/57 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under RoC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layer1 100, Layer2 10, Layer3 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>578.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.888105</td>\n",
       "      <td>0.838897</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.813808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 200, Layer2 20, Layer3 1</th>\n",
       "      <td>0.807309</td>\n",
       "      <td>631.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.833669</td>\n",
       "      <td>0.792714</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.805763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 300, Layer2 30, Layer3 1</th>\n",
       "      <td>0.800664</td>\n",
       "      <td>640.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.774818</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.798634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>635.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.819556</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.799827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 500, Layer2 50, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>587.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.867944</td>\n",
       "      <td>0.817549</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.804455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 50, Layer2 5, Layer3 1</th>\n",
       "      <td>0.806202</td>\n",
       "      <td>617.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.845766</td>\n",
       "      <td>0.801299</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.805572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Accuracy     TP     FP     TN     FN  \\\n",
       "Layer1 100, Layer2 10, Layer3 1  0.807863  578.0  111.0  881.0  236.0   \n",
       "Layer1 200, Layer2 20, Layer3 1  0.807309  631.0  165.0  827.0  183.0   \n",
       "Layer1 300, Layer2 30, Layer3 1  0.800664  640.0  186.0  806.0  174.0   \n",
       "Layer1 400, Layer2 40, Layer3 1  0.801772  635.0  179.0  813.0  179.0   \n",
       "Layer1 500, Layer2 50, Layer3 1  0.801772  587.0  131.0  861.0  227.0   \n",
       "Layer1 50, Layer2 5, Layer3 1    0.806202  617.0  153.0  839.0  197.0   \n",
       "\n",
       "                                 Sensitivity  Specificity  Precision  \\\n",
       "Layer1 100, Layer2 10, Layer3 1     0.710074     0.888105   0.838897   \n",
       "Layer1 200, Layer2 20, Layer3 1     0.775184     0.833669   0.792714   \n",
       "Layer1 300, Layer2 30, Layer3 1     0.786241     0.812500   0.774818   \n",
       "Layer1 400, Layer2 40, Layer3 1     0.780098     0.819556   0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1     0.721130     0.867944   0.817549   \n",
       "Layer1 50, Layer2 5, Layer3 1       0.757985     0.845766   0.801299   \n",
       "\n",
       "                                   Recall  Area Under RoC Curve  \n",
       "Layer1 100, Layer2 10, Layer3 1  0.710074              0.813808  \n",
       "Layer1 200, Layer2 20, Layer3 1  0.775184              0.805763  \n",
       "Layer1 300, Layer2 30, Layer3 1  0.786241              0.798634  \n",
       "Layer1 400, Layer2 40, Layer3 1  0.780098              0.799827  \n",
       "Layer1 500, Layer2 50, Layer3 1  0.721130              0.804455  \n",
       "Layer1 50, Layer2 5, Layer3 1    0.757985              0.805572  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model with different size of layer (layer1 - 50, layer2 - 5, layer3 - 1)\n",
    "model6 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "    keras.layers.Dense(50, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(5, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer3\", activation=\"sigmoid\") \n",
    "])\n",
    "# complie\n",
    "model6.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "# fit\n",
    "history6 = model6.fit(X_train_temp, y_train_temp, epochs=30, validation_split=0.1)\n",
    "\n",
    "# evaluate\n",
    "description = \"Layer1 50, Layer2 5, Layer3 1\"\n",
    "evaluate_model(model6, description)\n",
    "architecture_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment with number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "457/457 [==============================] - 3s 5ms/step - loss: 0.6244 - accuracy: 0.6833 - val_loss: 0.5964 - val_accuracy: 0.6954\n",
      "Epoch 2/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.5690 - accuracy: 0.7289 - val_loss: 0.5500 - val_accuracy: 0.7440\n",
      "Epoch 3/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.5246 - accuracy: 0.7639 - val_loss: 0.5105 - val_accuracy: 0.7711\n",
      "Epoch 4/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4921 - accuracy: 0.7843 - val_loss: 0.4843 - val_accuracy: 0.7778\n",
      "Epoch 5/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4709 - accuracy: 0.7940 - val_loss: 0.4676 - val_accuracy: 0.7883\n",
      "Epoch 6/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4567 - accuracy: 0.8013 - val_loss: 0.4562 - val_accuracy: 0.7932\n",
      "Epoch 7/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4465 - accuracy: 0.8049 - val_loss: 0.4496 - val_accuracy: 0.7938\n",
      "Epoch 8/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4381 - accuracy: 0.8096 - val_loss: 0.4419 - val_accuracy: 0.8043\n",
      "Epoch 9/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4309 - accuracy: 0.8144 - val_loss: 0.4365 - val_accuracy: 0.8105\n",
      "Epoch 10/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4250 - accuracy: 0.8180 - val_loss: 0.4324 - val_accuracy: 0.8117\n",
      "Epoch 11/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4195 - accuracy: 0.8218 - val_loss: 0.4306 - val_accuracy: 0.8111\n",
      "Epoch 12/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4143 - accuracy: 0.8250 - val_loss: 0.4276 - val_accuracy: 0.8086\n",
      "Epoch 13/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4096 - accuracy: 0.8263 - val_loss: 0.4254 - val_accuracy: 0.8092\n",
      "Epoch 14/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4052 - accuracy: 0.8302 - val_loss: 0.4245 - val_accuracy: 0.8123\n",
      "Epoch 15/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4006 - accuracy: 0.8324 - val_loss: 0.4236 - val_accuracy: 0.8172\n",
      "Epoch 16/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3961 - accuracy: 0.8369 - val_loss: 0.4264 - val_accuracy: 0.8111\n",
      "Epoch 17/30\n",
      "457/457 [==============================] - 3s 7ms/step - loss: 0.3911 - accuracy: 0.8410 - val_loss: 0.4213 - val_accuracy: 0.8135\n",
      "Epoch 18/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3858 - accuracy: 0.8430 - val_loss: 0.4208 - val_accuracy: 0.8172\n",
      "Epoch 19/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3808 - accuracy: 0.8474 - val_loss: 0.4244 - val_accuracy: 0.8111\n",
      "Epoch 20/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3750 - accuracy: 0.8512 - val_loss: 0.4211 - val_accuracy: 0.8166\n",
      "Epoch 21/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3696 - accuracy: 0.8513 - val_loss: 0.4202 - val_accuracy: 0.8123\n",
      "Epoch 22/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3626 - accuracy: 0.8582 - val_loss: 0.4193 - val_accuracy: 0.8098\n",
      "Epoch 23/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3566 - accuracy: 0.8630 - val_loss: 0.4271 - val_accuracy: 0.8105\n",
      "Epoch 24/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3490 - accuracy: 0.8689 - val_loss: 0.4315 - val_accuracy: 0.8068\n",
      "Epoch 25/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3420 - accuracy: 0.8702 - val_loss: 0.4239 - val_accuracy: 0.8080\n",
      "Epoch 26/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3349 - accuracy: 0.8747 - val_loss: 0.4243 - val_accuracy: 0.8123\n",
      "Epoch 27/30\n",
      "457/457 [==============================] - 3s 7ms/step - loss: 0.3266 - accuracy: 0.8791 - val_loss: 0.4355 - val_accuracy: 0.8031\n",
      "Epoch 28/30\n",
      "457/457 [==============================] - 3s 7ms/step - loss: 0.3187 - accuracy: 0.8854 - val_loss: 0.4274 - val_accuracy: 0.8098\n",
      "Epoch 29/30\n",
      "457/457 [==============================] - 4s 8ms/step - loss: 0.3098 - accuracy: 0.8913 - val_loss: 0.4340 - val_accuracy: 0.8068\n",
      "Epoch 30/30\n",
      "457/457 [==============================] - 3s 7ms/step - loss: 0.3014 - accuracy: 0.8910 - val_loss: 0.4324 - val_accuracy: 0.8098\n",
      "57/57 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under RoC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layer1 100, Layer2 10, Layer3 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>578.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.888105</td>\n",
       "      <td>0.838897</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.813808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 200, Layer2 20, Layer3 1</th>\n",
       "      <td>0.807309</td>\n",
       "      <td>631.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.833669</td>\n",
       "      <td>0.792714</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.805763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 300, Layer2 30, Layer3 1</th>\n",
       "      <td>0.800664</td>\n",
       "      <td>640.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.774818</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.798634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>635.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.819556</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.799827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 500, Layer2 50, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>587.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.867944</td>\n",
       "      <td>0.817549</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.804455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 50, Layer2 5, Layer3 1</th>\n",
       "      <td>0.806202</td>\n",
       "      <td>617.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.845766</td>\n",
       "      <td>0.801299</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.805572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 4, Layer4 1</th>\n",
       "      <td>0.810078</td>\n",
       "      <td>617.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.852823</td>\n",
       "      <td>0.808650</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.809886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Accuracy     TP     FP     TN  \\\n",
       "Layer1 100, Layer2 10, Layer3 1            0.807863  578.0  111.0  881.0   \n",
       "Layer1 200, Layer2 20, Layer3 1            0.807309  631.0  165.0  827.0   \n",
       "Layer1 300, Layer2 30, Layer3 1            0.800664  640.0  186.0  806.0   \n",
       "Layer1 400, Layer2 40, Layer3 1            0.801772  635.0  179.0  813.0   \n",
       "Layer1 500, Layer2 50, Layer3 1            0.801772  587.0  131.0  861.0   \n",
       "Layer1 50, Layer2 5, Layer3 1              0.806202  617.0  153.0  839.0   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1  0.810078  617.0  146.0  846.0   \n",
       "\n",
       "                                              FN  Sensitivity  Specificity  \\\n",
       "Layer1 100, Layer2 10, Layer3 1            236.0     0.710074     0.888105   \n",
       "Layer1 200, Layer2 20, Layer3 1            183.0     0.775184     0.833669   \n",
       "Layer1 300, Layer2 30, Layer3 1            174.0     0.786241     0.812500   \n",
       "Layer1 400, Layer2 40, Layer3 1            179.0     0.780098     0.819556   \n",
       "Layer1 500, Layer2 50, Layer3 1            227.0     0.721130     0.867944   \n",
       "Layer1 50, Layer2 5, Layer3 1              197.0     0.757985     0.845766   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1  197.0     0.757985     0.852823   \n",
       "\n",
       "                                           Precision    Recall  \\\n",
       "Layer1 100, Layer2 10, Layer3 1             0.838897  0.710074   \n",
       "Layer1 200, Layer2 20, Layer3 1             0.792714  0.775184   \n",
       "Layer1 300, Layer2 30, Layer3 1             0.774818  0.786241   \n",
       "Layer1 400, Layer2 40, Layer3 1             0.780098  0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1             0.817549  0.721130   \n",
       "Layer1 50, Layer2 5, Layer3 1               0.801299  0.757985   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1   0.808650  0.757985   \n",
       "\n",
       "                                           Area Under RoC Curve  \n",
       "Layer1 100, Layer2 10, Layer3 1                        0.813808  \n",
       "Layer1 200, Layer2 20, Layer3 1                        0.805763  \n",
       "Layer1 300, Layer2 30, Layer3 1                        0.798634  \n",
       "Layer1 400, Layer2 40, Layer3 1                        0.799827  \n",
       "Layer1 500, Layer2 50, Layer3 1                        0.804455  \n",
       "Layer1 50, Layer2 5, Layer3 1                          0.805572  \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1              0.809886  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model with different size of layer (layer1 - 400, layer2 - 40, layer3 - 4, layer4 - 1)\n",
    "model7 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "    keras.layers.Dense(400, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(40, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(4, name=\"layer3\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer4\", activation=\"sigmoid\") \n",
    "])\n",
    "# complie\n",
    "model7.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "# fit\n",
    "history7 = model7.fit(X_train_temp, y_train_temp, epochs=30, validation_split=0.1)\n",
    "\n",
    "# evaluate\n",
    "description = \"Layer1 400, Layer2 40, Layer3 4, Layer4 1\"\n",
    "evaluate_model(model7, description)\n",
    "architecture_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "457/457 [==============================] - 9s 18ms/step - loss: 0.6860 - accuracy: 0.5550 - val_loss: 0.6838 - val_accuracy: 0.5575\n",
      "Epoch 2/30\n",
      "457/457 [==============================] - 7s 15ms/step - loss: 0.6836 - accuracy: 0.5550 - val_loss: 0.6813 - val_accuracy: 0.5575\n",
      "Epoch 3/30\n",
      "457/457 [==============================] - 7s 15ms/step - loss: 0.6805 - accuracy: 0.5550 - val_loss: 0.6780 - val_accuracy: 0.5575\n",
      "Epoch 4/30\n",
      "457/457 [==============================] - 7s 16ms/step - loss: 0.6762 - accuracy: 0.5552 - val_loss: 0.6735 - val_accuracy: 0.5575\n",
      "Epoch 5/30\n",
      "457/457 [==============================] - 7s 16ms/step - loss: 0.6701 - accuracy: 0.5619 - val_loss: 0.6664 - val_accuracy: 0.5575\n",
      "Epoch 6/30\n",
      "457/457 [==============================] - 7s 16ms/step - loss: 0.6605 - accuracy: 0.5945 - val_loss: 0.6551 - val_accuracy: 0.6591\n",
      "Epoch 7/30\n",
      "457/457 [==============================] - 7s 16ms/step - loss: 0.6461 - accuracy: 0.6662 - val_loss: 0.6389 - val_accuracy: 0.6738\n",
      "Epoch 8/30\n",
      "457/457 [==============================] - 7s 16ms/step - loss: 0.6266 - accuracy: 0.6810 - val_loss: 0.6195 - val_accuracy: 0.6763\n",
      "Epoch 9/30\n",
      "457/457 [==============================] - 7s 15ms/step - loss: 0.6055 - accuracy: 0.6870 - val_loss: 0.5996 - val_accuracy: 0.6806\n",
      "Epoch 10/30\n",
      "457/457 [==============================] - 7s 16ms/step - loss: 0.5846 - accuracy: 0.6964 - val_loss: 0.5810 - val_accuracy: 0.6978\n",
      "Epoch 11/30\n",
      "457/457 [==============================] - 7s 15ms/step - loss: 0.5613 - accuracy: 0.7133 - val_loss: 0.5532 - val_accuracy: 0.7231\n",
      "Epoch 12/30\n",
      "457/457 [==============================] - 7s 15ms/step - loss: 0.5321 - accuracy: 0.7352 - val_loss: 0.5219 - val_accuracy: 0.7446\n",
      "Epoch 13/30\n",
      "457/457 [==============================] - 7s 16ms/step - loss: 0.5037 - accuracy: 0.7579 - val_loss: 0.4958 - val_accuracy: 0.7594\n",
      "Epoch 14/30\n",
      "457/457 [==============================] - 8s 17ms/step - loss: 0.4823 - accuracy: 0.7756 - val_loss: 0.4785 - val_accuracy: 0.7711\n",
      "Epoch 15/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.4679 - accuracy: 0.7826 - val_loss: 0.4634 - val_accuracy: 0.7797\n",
      "Epoch 16/30\n",
      "457/457 [==============================] - 8s 19ms/step - loss: 0.4574 - accuracy: 0.7904 - val_loss: 0.4551 - val_accuracy: 0.7914\n",
      "Epoch 17/30\n",
      "457/457 [==============================] - 8s 17ms/step - loss: 0.4506 - accuracy: 0.7955 - val_loss: 0.4493 - val_accuracy: 0.7938\n",
      "Epoch 18/30\n",
      "457/457 [==============================] - 7s 16ms/step - loss: 0.4448 - accuracy: 0.7990 - val_loss: 0.4436 - val_accuracy: 0.8037\n",
      "Epoch 19/30\n",
      "457/457 [==============================] - 8s 17ms/step - loss: 0.4395 - accuracy: 0.8015 - val_loss: 0.4401 - val_accuracy: 0.8062\n",
      "Epoch 20/30\n",
      "457/457 [==============================] - 7s 15ms/step - loss: 0.4352 - accuracy: 0.8056 - val_loss: 0.4381 - val_accuracy: 0.8025\n",
      "Epoch 21/30\n",
      "457/457 [==============================] - 7s 15ms/step - loss: 0.4310 - accuracy: 0.8088 - val_loss: 0.4353 - val_accuracy: 0.8018\n",
      "Epoch 22/30\n",
      "457/457 [==============================] - 7s 15ms/step - loss: 0.4275 - accuracy: 0.8119 - val_loss: 0.4321 - val_accuracy: 0.8080\n",
      "Epoch 23/30\n",
      "457/457 [==============================] - 7s 15ms/step - loss: 0.4244 - accuracy: 0.8142 - val_loss: 0.4293 - val_accuracy: 0.8098\n",
      "Epoch 24/30\n",
      "457/457 [==============================] - 7s 15ms/step - loss: 0.4211 - accuracy: 0.8166 - val_loss: 0.4285 - val_accuracy: 0.8117\n",
      "Epoch 25/30\n",
      "457/457 [==============================] - 7s 16ms/step - loss: 0.4181 - accuracy: 0.8179 - val_loss: 0.4263 - val_accuracy: 0.8129\n",
      "Epoch 26/30\n",
      "457/457 [==============================] - 7s 15ms/step - loss: 0.4153 - accuracy: 0.8196 - val_loss: 0.4260 - val_accuracy: 0.8135\n",
      "Epoch 27/30\n",
      "457/457 [==============================] - 8s 17ms/step - loss: 0.4128 - accuracy: 0.8226 - val_loss: 0.4255 - val_accuracy: 0.8074\n",
      "Epoch 28/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.4097 - accuracy: 0.8230 - val_loss: 0.4247 - val_accuracy: 0.8123\n",
      "Epoch 29/30\n",
      "457/457 [==============================] - 8s 17ms/step - loss: 0.4070 - accuracy: 0.8246 - val_loss: 0.4251 - val_accuracy: 0.8135\n",
      "Epoch 30/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.4041 - accuracy: 0.8265 - val_loss: 0.4236 - val_accuracy: 0.8092\n",
      "57/57 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under RoC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layer1 100, Layer2 10, Layer3 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>578.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.888105</td>\n",
       "      <td>0.838897</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.813808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 200, Layer2 20, Layer3 1</th>\n",
       "      <td>0.807309</td>\n",
       "      <td>631.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.833669</td>\n",
       "      <td>0.792714</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.805763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 300, Layer2 30, Layer3 1</th>\n",
       "      <td>0.800664</td>\n",
       "      <td>640.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.774818</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.798634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>635.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.819556</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.799827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 500, Layer2 50, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>587.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.867944</td>\n",
       "      <td>0.817549</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.804455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 50, Layer2 5, Layer3 1</th>\n",
       "      <td>0.806202</td>\n",
       "      <td>617.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.845766</td>\n",
       "      <td>0.801299</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.805572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 4, Layer4 1</th>\n",
       "      <td>0.810078</td>\n",
       "      <td>617.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.852823</td>\n",
       "      <td>0.808650</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.809886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 879, Layer2 586, Layer3 390, Layer4 260, Layer5 30, Layer6 1</th>\n",
       "      <td>0.808970</td>\n",
       "      <td>633.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.777641</td>\n",
       "      <td>0.834677</td>\n",
       "      <td>0.794228</td>\n",
       "      <td>0.777641</td>\n",
       "      <td>0.807421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy     TP     FP  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     0.807863  578.0  111.0   \n",
       "Layer1 200, Layer2 20, Layer3 1                     0.807309  631.0  165.0   \n",
       "Layer1 300, Layer2 30, Layer3 1                     0.800664  640.0  186.0   \n",
       "Layer1 400, Layer2 40, Layer3 1                     0.801772  635.0  179.0   \n",
       "Layer1 500, Layer2 50, Layer3 1                     0.801772  587.0  131.0   \n",
       "Layer1 50, Layer2 5, Layer3 1                       0.806202  617.0  153.0   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           0.810078  617.0  146.0   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.808970  633.0  164.0   \n",
       "\n",
       "                                                       TN     FN  Sensitivity  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     881.0  236.0     0.710074   \n",
       "Layer1 200, Layer2 20, Layer3 1                     827.0  183.0     0.775184   \n",
       "Layer1 300, Layer2 30, Layer3 1                     806.0  174.0     0.786241   \n",
       "Layer1 400, Layer2 40, Layer3 1                     813.0  179.0     0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                     861.0  227.0     0.721130   \n",
       "Layer1 50, Layer2 5, Layer3 1                       839.0  197.0     0.757985   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           846.0  197.0     0.757985   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  828.0  181.0     0.777641   \n",
       "\n",
       "                                                    Specificity  Precision  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                        0.888105   0.838897   \n",
       "Layer1 200, Layer2 20, Layer3 1                        0.833669   0.792714   \n",
       "Layer1 300, Layer2 30, Layer3 1                        0.812500   0.774818   \n",
       "Layer1 400, Layer2 40, Layer3 1                        0.819556   0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                        0.867944   0.817549   \n",
       "Layer1 50, Layer2 5, Layer3 1                          0.845766   0.801299   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1              0.852823   0.808650   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...     0.834677   0.794228   \n",
       "\n",
       "                                                      Recall  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     0.710074   \n",
       "Layer1 200, Layer2 20, Layer3 1                     0.775184   \n",
       "Layer1 300, Layer2 30, Layer3 1                     0.786241   \n",
       "Layer1 400, Layer2 40, Layer3 1                     0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                     0.721130   \n",
       "Layer1 50, Layer2 5, Layer3 1                       0.757985   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           0.757985   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.777641   \n",
       "\n",
       "                                                    Area Under RoC Curve  \n",
       "Layer1 100, Layer2 10, Layer3 1                                 0.813808  \n",
       "Layer1 200, Layer2 20, Layer3 1                                 0.805763  \n",
       "Layer1 300, Layer2 30, Layer3 1                                 0.798634  \n",
       "Layer1 400, Layer2 40, Layer3 1                                 0.799827  \n",
       "Layer1 500, Layer2 50, Layer3 1                                 0.804455  \n",
       "Layer1 50, Layer2 5, Layer3 1                                   0.805572  \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1                       0.809886  \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...              0.807421  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model with different size of layer (layer1 - 879, layer2 - 586, layer3 - 390, layer4 - 260, layer5 - 30, layer6 - 1)\n",
    "model8 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "    keras.layers.Dense(879, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(586, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(390, name=\"layer3\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(260, name=\"layer4\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(30, name=\"layer5\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer6\", activation=\"sigmoid\") \n",
    "])\n",
    "# complie\n",
    "model8.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "# fit\n",
    "history8 = history8 = model8.fit(X_train_temp, y_train_temp, epochs=30, validation_split=0.1)\n",
    "\n",
    "# evaluate\n",
    "description = \"Layer1 879, Layer2 586, Layer3 390, Layer4 260, Layer5 30, Layer6 1\"\n",
    "evaluate_model(model8, description)\n",
    "architecture_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "457/457 [==============================] - 10s 20ms/step - loss: 0.6862 - accuracy: 0.5550 - val_loss: 0.6844 - val_accuracy: 0.5575\n",
      "Epoch 2/30\n",
      "457/457 [==============================] - 10s 21ms/step - loss: 0.6842 - accuracy: 0.5550 - val_loss: 0.6829 - val_accuracy: 0.5575\n",
      "Epoch 3/30\n",
      "457/457 [==============================] - 9s 20ms/step - loss: 0.6819 - accuracy: 0.5550 - val_loss: 0.6802 - val_accuracy: 0.5575\n",
      "Epoch 4/30\n",
      "457/457 [==============================] - 9s 20ms/step - loss: 0.6790 - accuracy: 0.5550 - val_loss: 0.6768 - val_accuracy: 0.5575\n",
      "Epoch 5/30\n",
      "457/457 [==============================] - 9s 19ms/step - loss: 0.6745 - accuracy: 0.5550 - val_loss: 0.6715 - val_accuracy: 0.5575\n",
      "Epoch 6/30\n",
      "457/457 [==============================] - 8s 17ms/step - loss: 0.6676 - accuracy: 0.5663 - val_loss: 0.6636 - val_accuracy: 0.5908\n",
      "Epoch 7/30\n",
      "457/457 [==============================] - 8s 17ms/step - loss: 0.6572 - accuracy: 0.6216 - val_loss: 0.6518 - val_accuracy: 0.6683\n",
      "Epoch 8/30\n",
      "457/457 [==============================] - 8s 17ms/step - loss: 0.6422 - accuracy: 0.6698 - val_loss: 0.6351 - val_accuracy: 0.6665\n",
      "Epoch 9/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.6229 - accuracy: 0.6792 - val_loss: 0.6163 - val_accuracy: 0.6738\n",
      "Epoch 10/30\n",
      "457/457 [==============================] - 9s 20ms/step - loss: 0.6033 - accuracy: 0.6840 - val_loss: 0.5989 - val_accuracy: 0.6892\n",
      "Epoch 11/30\n",
      "457/457 [==============================] - 9s 19ms/step - loss: 0.5842 - accuracy: 0.6940 - val_loss: 0.5800 - val_accuracy: 0.6978\n",
      "Epoch 12/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.5627 - accuracy: 0.7126 - val_loss: 0.5557 - val_accuracy: 0.7169\n",
      "Epoch 13/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.5356 - accuracy: 0.7338 - val_loss: 0.5260 - val_accuracy: 0.7452\n",
      "Epoch 14/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.5084 - accuracy: 0.7537 - val_loss: 0.5021 - val_accuracy: 0.7557\n",
      "Epoch 15/30\n",
      "457/457 [==============================] - 9s 20ms/step - loss: 0.4870 - accuracy: 0.7707 - val_loss: 0.4801 - val_accuracy: 0.7698\n",
      "Epoch 16/30\n",
      "457/457 [==============================] - 9s 21ms/step - loss: 0.4716 - accuracy: 0.7817 - val_loss: 0.4656 - val_accuracy: 0.7815\n",
      "Epoch 17/30\n",
      "457/457 [==============================] - 10s 21ms/step - loss: 0.4604 - accuracy: 0.7895 - val_loss: 0.4559 - val_accuracy: 0.7846\n",
      "Epoch 18/30\n",
      "457/457 [==============================] - 10s 21ms/step - loss: 0.4529 - accuracy: 0.7943 - val_loss: 0.4481 - val_accuracy: 0.7963\n",
      "Epoch 19/30\n",
      "457/457 [==============================] - 9s 19ms/step - loss: 0.4465 - accuracy: 0.7986 - val_loss: 0.4435 - val_accuracy: 0.8012\n",
      "Epoch 20/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.4411 - accuracy: 0.8040 - val_loss: 0.4466 - val_accuracy: 0.7920\n",
      "Epoch 21/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.4368 - accuracy: 0.8066 - val_loss: 0.4371 - val_accuracy: 0.8025\n",
      "Epoch 22/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.4322 - accuracy: 0.8079 - val_loss: 0.4321 - val_accuracy: 0.8092\n",
      "Epoch 23/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.4287 - accuracy: 0.8111 - val_loss: 0.4300 - val_accuracy: 0.8111\n",
      "Epoch 24/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.4248 - accuracy: 0.8150 - val_loss: 0.4345 - val_accuracy: 0.7982\n",
      "Epoch 25/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.4212 - accuracy: 0.8158 - val_loss: 0.4257 - val_accuracy: 0.8092\n",
      "Epoch 26/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.4185 - accuracy: 0.8187 - val_loss: 0.4264 - val_accuracy: 0.8092\n",
      "Epoch 27/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.4155 - accuracy: 0.8194 - val_loss: 0.4295 - val_accuracy: 0.8092\n",
      "Epoch 28/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.4133 - accuracy: 0.8211 - val_loss: 0.4219 - val_accuracy: 0.8154\n",
      "Epoch 29/30\n",
      "457/457 [==============================] - 9s 19ms/step - loss: 0.4098 - accuracy: 0.8239 - val_loss: 0.4219 - val_accuracy: 0.8148\n",
      "Epoch 30/30\n",
      "457/457 [==============================] - 9s 20ms/step - loss: 0.4068 - accuracy: 0.8255 - val_loss: 0.4210 - val_accuracy: 0.8135\n",
      "57/57 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under RoC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layer1 100, Layer2 10, Layer3 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>578.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.888105</td>\n",
       "      <td>0.838897</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.813808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 200, Layer2 20, Layer3 1</th>\n",
       "      <td>0.807309</td>\n",
       "      <td>631.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.833669</td>\n",
       "      <td>0.792714</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.805763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 300, Layer2 30, Layer3 1</th>\n",
       "      <td>0.800664</td>\n",
       "      <td>640.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.774818</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.798634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>635.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.819556</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.799827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 500, Layer2 50, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>587.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.867944</td>\n",
       "      <td>0.817549</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.804455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 50, Layer2 5, Layer3 1</th>\n",
       "      <td>0.806202</td>\n",
       "      <td>617.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.845766</td>\n",
       "      <td>0.801299</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.805572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 4, Layer4 1</th>\n",
       "      <td>0.810078</td>\n",
       "      <td>617.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.852823</td>\n",
       "      <td>0.808650</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.809886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 879, Layer2 586, Layer3 390, Layer4 260, Layer5 30, Layer6 1</th>\n",
       "      <td>0.808970</td>\n",
       "      <td>633.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.777641</td>\n",
       "      <td>0.834677</td>\n",
       "      <td>0.794228</td>\n",
       "      <td>0.777641</td>\n",
       "      <td>0.807421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 1000, Layer2 700, Layer3 400, Layer4 260, Layer5 30, Layer6 1</th>\n",
       "      <td>0.808970</td>\n",
       "      <td>627.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.840726</td>\n",
       "      <td>0.798726</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.807786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy     TP     FP  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     0.807863  578.0  111.0   \n",
       "Layer1 200, Layer2 20, Layer3 1                     0.807309  631.0  165.0   \n",
       "Layer1 300, Layer2 30, Layer3 1                     0.800664  640.0  186.0   \n",
       "Layer1 400, Layer2 40, Layer3 1                     0.801772  635.0  179.0   \n",
       "Layer1 500, Layer2 50, Layer3 1                     0.801772  587.0  131.0   \n",
       "Layer1 50, Layer2 5, Layer3 1                       0.806202  617.0  153.0   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           0.810078  617.0  146.0   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.808970  633.0  164.0   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  0.808970  627.0  158.0   \n",
       "\n",
       "                                                       TN     FN  Sensitivity  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     881.0  236.0     0.710074   \n",
       "Layer1 200, Layer2 20, Layer3 1                     827.0  183.0     0.775184   \n",
       "Layer1 300, Layer2 30, Layer3 1                     806.0  174.0     0.786241   \n",
       "Layer1 400, Layer2 40, Layer3 1                     813.0  179.0     0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                     861.0  227.0     0.721130   \n",
       "Layer1 50, Layer2 5, Layer3 1                       839.0  197.0     0.757985   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           846.0  197.0     0.757985   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  828.0  181.0     0.777641   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  834.0  187.0     0.770270   \n",
       "\n",
       "                                                    Specificity  Precision  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                        0.888105   0.838897   \n",
       "Layer1 200, Layer2 20, Layer3 1                        0.833669   0.792714   \n",
       "Layer1 300, Layer2 30, Layer3 1                        0.812500   0.774818   \n",
       "Layer1 400, Layer2 40, Layer3 1                        0.819556   0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                        0.867944   0.817549   \n",
       "Layer1 50, Layer2 5, Layer3 1                          0.845766   0.801299   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1              0.852823   0.808650   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...     0.834677   0.794228   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...     0.840726   0.798726   \n",
       "\n",
       "                                                      Recall  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     0.710074   \n",
       "Layer1 200, Layer2 20, Layer3 1                     0.775184   \n",
       "Layer1 300, Layer2 30, Layer3 1                     0.786241   \n",
       "Layer1 400, Layer2 40, Layer3 1                     0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                     0.721130   \n",
       "Layer1 50, Layer2 5, Layer3 1                       0.757985   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           0.757985   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.777641   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  0.770270   \n",
       "\n",
       "                                                    Area Under RoC Curve  \n",
       "Layer1 100, Layer2 10, Layer3 1                                 0.813808  \n",
       "Layer1 200, Layer2 20, Layer3 1                                 0.805763  \n",
       "Layer1 300, Layer2 30, Layer3 1                                 0.798634  \n",
       "Layer1 400, Layer2 40, Layer3 1                                 0.799827  \n",
       "Layer1 500, Layer2 50, Layer3 1                                 0.804455  \n",
       "Layer1 50, Layer2 5, Layer3 1                                   0.805572  \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1                       0.809886  \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...              0.807421  \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...              0.807786  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model with different size of layer (layer1 - 1000, layer2 - 700, layer3 - 400, layer4 - 260, layer5 - 30, layer6 - 1)\n",
    "model9 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "    keras.layers.Dense(1000, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(700, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(400, name=\"layer3\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(260, name=\"layer4\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(30, name=\"layer5\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer6\", activation=\"sigmoid\") \n",
    "])\n",
    "# complie\n",
    "model9.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "# fit\n",
    "history9 = model9.fit(X_train_temp, y_train_temp, epochs=30, validation_split=0.1)\n",
    "\n",
    "# evaluate\n",
    "description = \"Layer1 1000, Layer2 700, Layer3 400, Layer4 260, Layer5 30, Layer6 1\"\n",
    "evaluate_model(model9, description)\n",
    "architecture_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "457/457 [==============================] - 4s 7ms/step - loss: 0.6787 - accuracy: 0.5550 - val_loss: 0.6698 - val_accuracy: 0.5575\n",
      "Epoch 2/30\n",
      "457/457 [==============================] - 3s 7ms/step - loss: 0.6598 - accuracy: 0.6145 - val_loss: 0.6513 - val_accuracy: 0.6560\n",
      "Epoch 3/30\n",
      "457/457 [==============================] - 3s 7ms/step - loss: 0.6386 - accuracy: 0.6758 - val_loss: 0.6300 - val_accuracy: 0.6751\n",
      "Epoch 4/30\n",
      "457/457 [==============================] - 3s 7ms/step - loss: 0.6153 - accuracy: 0.6863 - val_loss: 0.6077 - val_accuracy: 0.6849\n",
      "Epoch 5/30\n",
      "457/457 [==============================] - 3s 7ms/step - loss: 0.5906 - accuracy: 0.6988 - val_loss: 0.5816 - val_accuracy: 0.7077\n",
      "Epoch 6/30\n",
      "457/457 [==============================] - 3s 7ms/step - loss: 0.5600 - accuracy: 0.7252 - val_loss: 0.5480 - val_accuracy: 0.7372\n",
      "Epoch 7/30\n",
      "457/457 [==============================] - 3s 8ms/step - loss: 0.5258 - accuracy: 0.7512 - val_loss: 0.5145 - val_accuracy: 0.7563\n",
      "Epoch 8/30\n",
      "457/457 [==============================] - 3s 7ms/step - loss: 0.4964 - accuracy: 0.7719 - val_loss: 0.4883 - val_accuracy: 0.7655\n",
      "Epoch 9/30\n",
      "457/457 [==============================] - 3s 7ms/step - loss: 0.4751 - accuracy: 0.7824 - val_loss: 0.4706 - val_accuracy: 0.7735\n",
      "Epoch 10/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.4610 - accuracy: 0.7915 - val_loss: 0.4589 - val_accuracy: 0.7815\n",
      "Epoch 11/30\n",
      "457/457 [==============================] - 3s 7ms/step - loss: 0.4511 - accuracy: 0.7968 - val_loss: 0.4504 - val_accuracy: 0.7938\n",
      "Epoch 12/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.4436 - accuracy: 0.8014 - val_loss: 0.4445 - val_accuracy: 0.7988\n",
      "Epoch 13/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.4374 - accuracy: 0.8060 - val_loss: 0.4402 - val_accuracy: 0.8000\n",
      "Epoch 14/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.4320 - accuracy: 0.8092 - val_loss: 0.4355 - val_accuracy: 0.8049\n",
      "Epoch 15/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.4273 - accuracy: 0.8136 - val_loss: 0.4326 - val_accuracy: 0.8068\n",
      "Epoch 16/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.4231 - accuracy: 0.8146 - val_loss: 0.4302 - val_accuracy: 0.8068\n",
      "Epoch 17/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.4194 - accuracy: 0.8170 - val_loss: 0.4295 - val_accuracy: 0.8031\n",
      "Epoch 18/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.4161 - accuracy: 0.8187 - val_loss: 0.4258 - val_accuracy: 0.8080\n",
      "Epoch 19/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.4126 - accuracy: 0.8222 - val_loss: 0.4249 - val_accuracy: 0.8074\n",
      "Epoch 20/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.4090 - accuracy: 0.8254 - val_loss: 0.4247 - val_accuracy: 0.8092\n",
      "Epoch 21/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.4060 - accuracy: 0.8263 - val_loss: 0.4234 - val_accuracy: 0.8074\n",
      "Epoch 22/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.4025 - accuracy: 0.8298 - val_loss: 0.4210 - val_accuracy: 0.8123\n",
      "Epoch 23/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3993 - accuracy: 0.8293 - val_loss: 0.4199 - val_accuracy: 0.8105\n",
      "Epoch 24/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3954 - accuracy: 0.8330 - val_loss: 0.4190 - val_accuracy: 0.8086\n",
      "Epoch 25/30\n",
      "457/457 [==============================] - 3s 7ms/step - loss: 0.3911 - accuracy: 0.8358 - val_loss: 0.4206 - val_accuracy: 0.8135\n",
      "Epoch 26/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3878 - accuracy: 0.8380 - val_loss: 0.4226 - val_accuracy: 0.8086\n",
      "Epoch 27/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3835 - accuracy: 0.8414 - val_loss: 0.4179 - val_accuracy: 0.8111\n",
      "Epoch 28/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3794 - accuracy: 0.8430 - val_loss: 0.4185 - val_accuracy: 0.8154\n",
      "Epoch 29/30\n",
      "457/457 [==============================] - 3s 7ms/step - loss: 0.3744 - accuracy: 0.8479 - val_loss: 0.4168 - val_accuracy: 0.8160\n",
      "Epoch 30/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3697 - accuracy: 0.8509 - val_loss: 0.4243 - val_accuracy: 0.8086\n",
      "57/57 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under RoC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layer1 100, Layer2 10, Layer3 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>578.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.888105</td>\n",
       "      <td>0.838897</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.813808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 200, Layer2 20, Layer3 1</th>\n",
       "      <td>0.807309</td>\n",
       "      <td>631.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.833669</td>\n",
       "      <td>0.792714</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.805763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 300, Layer2 30, Layer3 1</th>\n",
       "      <td>0.800664</td>\n",
       "      <td>640.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.774818</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.798634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>635.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.819556</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.799827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 500, Layer2 50, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>587.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.867944</td>\n",
       "      <td>0.817549</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.804455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 50, Layer2 5, Layer3 1</th>\n",
       "      <td>0.806202</td>\n",
       "      <td>617.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.845766</td>\n",
       "      <td>0.801299</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.805572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 4, Layer4 1</th>\n",
       "      <td>0.810078</td>\n",
       "      <td>617.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.852823</td>\n",
       "      <td>0.808650</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.809886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 879, Layer2 586, Layer3 390, Layer4 260, Layer5 30, Layer6 1</th>\n",
       "      <td>0.808970</td>\n",
       "      <td>633.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.777641</td>\n",
       "      <td>0.834677</td>\n",
       "      <td>0.794228</td>\n",
       "      <td>0.777641</td>\n",
       "      <td>0.807421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 1000, Layer2 700, Layer3 400, Layer4 260, Layer5 30, Layer6 1</th>\n",
       "      <td>0.808970</td>\n",
       "      <td>627.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.840726</td>\n",
       "      <td>0.798726</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.807786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 500, Layer2 180, Layer3 60, Layer4 20, Layer5 1</th>\n",
       "      <td>0.808416</td>\n",
       "      <td>638.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.828629</td>\n",
       "      <td>0.789604</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.806626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy     TP     FP  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     0.807863  578.0  111.0   \n",
       "Layer1 200, Layer2 20, Layer3 1                     0.807309  631.0  165.0   \n",
       "Layer1 300, Layer2 30, Layer3 1                     0.800664  640.0  186.0   \n",
       "Layer1 400, Layer2 40, Layer3 1                     0.801772  635.0  179.0   \n",
       "Layer1 500, Layer2 50, Layer3 1                     0.801772  587.0  131.0   \n",
       "Layer1 50, Layer2 5, Layer3 1                       0.806202  617.0  153.0   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           0.810078  617.0  146.0   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.808970  633.0  164.0   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  0.808970  627.0  158.0   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  0.808416  638.0  170.0   \n",
       "\n",
       "                                                       TN     FN  Sensitivity  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     881.0  236.0     0.710074   \n",
       "Layer1 200, Layer2 20, Layer3 1                     827.0  183.0     0.775184   \n",
       "Layer1 300, Layer2 30, Layer3 1                     806.0  174.0     0.786241   \n",
       "Layer1 400, Layer2 40, Layer3 1                     813.0  179.0     0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                     861.0  227.0     0.721130   \n",
       "Layer1 50, Layer2 5, Layer3 1                       839.0  197.0     0.757985   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           846.0  197.0     0.757985   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  828.0  181.0     0.777641   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  834.0  187.0     0.770270   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  822.0  176.0     0.783784   \n",
       "\n",
       "                                                    Specificity  Precision  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                        0.888105   0.838897   \n",
       "Layer1 200, Layer2 20, Layer3 1                        0.833669   0.792714   \n",
       "Layer1 300, Layer2 30, Layer3 1                        0.812500   0.774818   \n",
       "Layer1 400, Layer2 40, Layer3 1                        0.819556   0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                        0.867944   0.817549   \n",
       "Layer1 50, Layer2 5, Layer3 1                          0.845766   0.801299   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1              0.852823   0.808650   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...     0.834677   0.794228   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...     0.840726   0.798726   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...     0.828629   0.789604   \n",
       "\n",
       "                                                      Recall  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     0.710074   \n",
       "Layer1 200, Layer2 20, Layer3 1                     0.775184   \n",
       "Layer1 300, Layer2 30, Layer3 1                     0.786241   \n",
       "Layer1 400, Layer2 40, Layer3 1                     0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                     0.721130   \n",
       "Layer1 50, Layer2 5, Layer3 1                       0.757985   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           0.757985   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.777641   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  0.770270   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  0.783784   \n",
       "\n",
       "                                                    Area Under RoC Curve  \n",
       "Layer1 100, Layer2 10, Layer3 1                                 0.813808  \n",
       "Layer1 200, Layer2 20, Layer3 1                                 0.805763  \n",
       "Layer1 300, Layer2 30, Layer3 1                                 0.798634  \n",
       "Layer1 400, Layer2 40, Layer3 1                                 0.799827  \n",
       "Layer1 500, Layer2 50, Layer3 1                                 0.804455  \n",
       "Layer1 50, Layer2 5, Layer3 1                                   0.805572  \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1                       0.809886  \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...              0.807421  \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...              0.807786  \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...              0.806626  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model with different size of layer (layer1 - 500, layer2 - 180, layer3 - 60, layer4 - 20, layer5 - 1)\n",
    "model10 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "    keras.layers.Dense(500, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(180, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(60, name=\"layer3\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(20, name=\"layer4\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer5\", activation=\"sigmoid\")\n",
    "])\n",
    "# complie\n",
    "model10.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "# fit\n",
    "history10 = model10.fit(X_train_temp, y_train_temp, epochs=30, validation_split=0.1)\n",
    "\n",
    "# evaluate\n",
    "description = \"Layer1 500, Layer2 180, Layer3 60, Layer4 20, Layer5 1\"\n",
    "evaluate_model(model10, description)\n",
    "architecture_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.6942 - accuracy: 0.5328 - val_loss: 0.6718 - val_accuracy: 0.5575\n",
      "Epoch 2/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.6639 - accuracy: 0.5868 - val_loss: 0.6577 - val_accuracy: 0.6566\n",
      "Epoch 3/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.6482 - accuracy: 0.6739 - val_loss: 0.6425 - val_accuracy: 0.6689\n",
      "Epoch 4/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.6310 - accuracy: 0.6890 - val_loss: 0.6253 - val_accuracy: 0.6769\n",
      "Epoch 5/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.6114 - accuracy: 0.7014 - val_loss: 0.6048 - val_accuracy: 0.6978\n",
      "Epoch 6/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.5874 - accuracy: 0.7224 - val_loss: 0.5786 - val_accuracy: 0.7305\n",
      "Epoch 7/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.5586 - accuracy: 0.7437 - val_loss: 0.5487 - val_accuracy: 0.7526\n",
      "Epoch 8/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.5291 - accuracy: 0.7629 - val_loss: 0.5205 - val_accuracy: 0.7588\n",
      "Epoch 9/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.5030 - accuracy: 0.7777 - val_loss: 0.4969 - val_accuracy: 0.7717\n",
      "Epoch 10/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.4827 - accuracy: 0.7901 - val_loss: 0.4789 - val_accuracy: 0.7803\n",
      "Epoch 11/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4679 - accuracy: 0.7958 - val_loss: 0.4677 - val_accuracy: 0.7846\n",
      "Epoch 12/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4574 - accuracy: 0.8003 - val_loss: 0.4590 - val_accuracy: 0.7865\n",
      "Epoch 13/30\n",
      "457/457 [==============================] - 3s 5ms/step - loss: 0.4493 - accuracy: 0.8049 - val_loss: 0.4520 - val_accuracy: 0.7982\n",
      "Epoch 14/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4425 - accuracy: 0.8094 - val_loss: 0.4455 - val_accuracy: 0.8012\n",
      "Epoch 15/30\n",
      "457/457 [==============================] - 3s 5ms/step - loss: 0.4363 - accuracy: 0.8118 - val_loss: 0.4410 - val_accuracy: 0.8043\n",
      "Epoch 16/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.4311 - accuracy: 0.8144 - val_loss: 0.4372 - val_accuracy: 0.8031\n",
      "Epoch 17/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.4266 - accuracy: 0.8176 - val_loss: 0.4346 - val_accuracy: 0.8031\n",
      "Epoch 18/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.4218 - accuracy: 0.8204 - val_loss: 0.4333 - val_accuracy: 0.8031\n",
      "Epoch 19/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.4173 - accuracy: 0.8226 - val_loss: 0.4337 - val_accuracy: 0.8037\n",
      "Epoch 20/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.4138 - accuracy: 0.8248 - val_loss: 0.4307 - val_accuracy: 0.8049\n",
      "Epoch 21/30\n",
      "457/457 [==============================] - 3s 7ms/step - loss: 0.4098 - accuracy: 0.8282 - val_loss: 0.4284 - val_accuracy: 0.8086\n",
      "Epoch 22/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.4061 - accuracy: 0.8294 - val_loss: 0.4261 - val_accuracy: 0.8092\n",
      "Epoch 23/30\n",
      "457/457 [==============================] - 3s 7ms/step - loss: 0.4022 - accuracy: 0.8313 - val_loss: 0.4273 - val_accuracy: 0.8098\n",
      "Epoch 24/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3981 - accuracy: 0.8352 - val_loss: 0.4242 - val_accuracy: 0.8105\n",
      "Epoch 25/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3947 - accuracy: 0.8361 - val_loss: 0.4256 - val_accuracy: 0.8098\n",
      "Epoch 26/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3902 - accuracy: 0.8409 - val_loss: 0.4242 - val_accuracy: 0.8092\n",
      "Epoch 27/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3861 - accuracy: 0.8415 - val_loss: 0.4249 - val_accuracy: 0.8135\n",
      "Epoch 28/30\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.3812 - accuracy: 0.8458 - val_loss: 0.4229 - val_accuracy: 0.8129\n",
      "Epoch 29/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3761 - accuracy: 0.8503 - val_loss: 0.4237 - val_accuracy: 0.8117\n",
      "Epoch 30/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3707 - accuracy: 0.8542 - val_loss: 0.4212 - val_accuracy: 0.8142\n",
      "57/57 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under RoC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layer1 100, Layer2 10, Layer3 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>578.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.888105</td>\n",
       "      <td>0.838897</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.813808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 200, Layer2 20, Layer3 1</th>\n",
       "      <td>0.807309</td>\n",
       "      <td>631.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.833669</td>\n",
       "      <td>0.792714</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.805763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 300, Layer2 30, Layer3 1</th>\n",
       "      <td>0.800664</td>\n",
       "      <td>640.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.774818</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.798634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>635.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.819556</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.799827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 500, Layer2 50, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>587.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.867944</td>\n",
       "      <td>0.817549</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.804455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 50, Layer2 5, Layer3 1</th>\n",
       "      <td>0.806202</td>\n",
       "      <td>617.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.845766</td>\n",
       "      <td>0.801299</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.805572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 4, Layer4 1</th>\n",
       "      <td>0.810078</td>\n",
       "      <td>617.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.852823</td>\n",
       "      <td>0.808650</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.809886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 879, Layer2 586, Layer3 390, Layer4 260, Layer5 30, Layer6 1</th>\n",
       "      <td>0.808970</td>\n",
       "      <td>633.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.777641</td>\n",
       "      <td>0.834677</td>\n",
       "      <td>0.794228</td>\n",
       "      <td>0.777641</td>\n",
       "      <td>0.807421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 1000, Layer2 700, Layer3 400, Layer4 260, Layer5 30, Layer6 1</th>\n",
       "      <td>0.808970</td>\n",
       "      <td>627.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.840726</td>\n",
       "      <td>0.798726</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.807786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 500, Layer2 180, Layer3 60, Layer4 20, Layer5 1</th>\n",
       "      <td>0.808416</td>\n",
       "      <td>638.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.828629</td>\n",
       "      <td>0.789604</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.806626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 100, Layer3 25, Layer4 6, Layer5 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>602.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.739558</td>\n",
       "      <td>0.863911</td>\n",
       "      <td>0.816825</td>\n",
       "      <td>0.739558</td>\n",
       "      <td>0.809254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy     TP     FP  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     0.807863  578.0  111.0   \n",
       "Layer1 200, Layer2 20, Layer3 1                     0.807309  631.0  165.0   \n",
       "Layer1 300, Layer2 30, Layer3 1                     0.800664  640.0  186.0   \n",
       "Layer1 400, Layer2 40, Layer3 1                     0.801772  635.0  179.0   \n",
       "Layer1 500, Layer2 50, Layer3 1                     0.801772  587.0  131.0   \n",
       "Layer1 50, Layer2 5, Layer3 1                       0.806202  617.0  153.0   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           0.810078  617.0  146.0   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.808970  633.0  164.0   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  0.808970  627.0  158.0   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  0.808416  638.0  170.0   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...  0.807863  602.0  135.0   \n",
       "\n",
       "                                                       TN     FN  Sensitivity  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     881.0  236.0     0.710074   \n",
       "Layer1 200, Layer2 20, Layer3 1                     827.0  183.0     0.775184   \n",
       "Layer1 300, Layer2 30, Layer3 1                     806.0  174.0     0.786241   \n",
       "Layer1 400, Layer2 40, Layer3 1                     813.0  179.0     0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                     861.0  227.0     0.721130   \n",
       "Layer1 50, Layer2 5, Layer3 1                       839.0  197.0     0.757985   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           846.0  197.0     0.757985   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  828.0  181.0     0.777641   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  834.0  187.0     0.770270   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  822.0  176.0     0.783784   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...  857.0  212.0     0.739558   \n",
       "\n",
       "                                                    Specificity  Precision  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                        0.888105   0.838897   \n",
       "Layer1 200, Layer2 20, Layer3 1                        0.833669   0.792714   \n",
       "Layer1 300, Layer2 30, Layer3 1                        0.812500   0.774818   \n",
       "Layer1 400, Layer2 40, Layer3 1                        0.819556   0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                        0.867944   0.817549   \n",
       "Layer1 50, Layer2 5, Layer3 1                          0.845766   0.801299   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1              0.852823   0.808650   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...     0.834677   0.794228   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...     0.840726   0.798726   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...     0.828629   0.789604   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...     0.863911   0.816825   \n",
       "\n",
       "                                                      Recall  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     0.710074   \n",
       "Layer1 200, Layer2 20, Layer3 1                     0.775184   \n",
       "Layer1 300, Layer2 30, Layer3 1                     0.786241   \n",
       "Layer1 400, Layer2 40, Layer3 1                     0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                     0.721130   \n",
       "Layer1 50, Layer2 5, Layer3 1                       0.757985   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           0.757985   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.777641   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  0.770270   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  0.783784   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...  0.739558   \n",
       "\n",
       "                                                    Area Under RoC Curve  \n",
       "Layer1 100, Layer2 10, Layer3 1                                 0.813808  \n",
       "Layer1 200, Layer2 20, Layer3 1                                 0.805763  \n",
       "Layer1 300, Layer2 30, Layer3 1                                 0.798634  \n",
       "Layer1 400, Layer2 40, Layer3 1                                 0.799827  \n",
       "Layer1 500, Layer2 50, Layer3 1                                 0.804455  \n",
       "Layer1 50, Layer2 5, Layer3 1                                   0.805572  \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1                       0.809886  \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...              0.807421  \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...              0.807786  \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...              0.806626  \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...              0.809254  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model with different size of layer (layer1 - 400, layer2 - 100, layer3 - 25, layer4 - 6, layer5 - 1)\n",
    "model11 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "    keras.layers.Dense(400, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(100, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(25, name=\"layer3\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(6, name=\"layer4\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer5\", activation=\"sigmoid\")\n",
    "])\n",
    "# complie\n",
    "model11.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "# fit\n",
    "history11 = model11.fit(X_train_temp, y_train_temp, epochs=30, validation_split=0.1)\n",
    "\n",
    "# evaluate\n",
    "description = \"Layer1 400, Layer2 100, Layer3 25, Layer4 6, Layer5 1\"\n",
    "evaluate_model(model11, description)\n",
    "architecture_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "457/457 [==============================] - 3s 4ms/step - loss: 0.6836 - accuracy: 0.5550 - val_loss: 0.6757 - val_accuracy: 0.5575\n",
      "Epoch 2/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.6692 - accuracy: 0.5550 - val_loss: 0.6633 - val_accuracy: 0.5575\n",
      "Epoch 3/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.6561 - accuracy: 0.5961 - val_loss: 0.6508 - val_accuracy: 0.6572\n",
      "Epoch 4/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.6428 - accuracy: 0.6765 - val_loss: 0.6374 - val_accuracy: 0.6726\n",
      "Epoch 5/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.6279 - accuracy: 0.6956 - val_loss: 0.6216 - val_accuracy: 0.6917\n",
      "Epoch 6/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.6099 - accuracy: 0.7085 - val_loss: 0.6019 - val_accuracy: 0.7145\n",
      "Epoch 7/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.5873 - accuracy: 0.7282 - val_loss: 0.5774 - val_accuracy: 0.7385\n",
      "Epoch 8/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.5608 - accuracy: 0.7463 - val_loss: 0.5506 - val_accuracy: 0.7625\n",
      "Epoch 9/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.5342 - accuracy: 0.7679 - val_loss: 0.5250 - val_accuracy: 0.7668\n",
      "Epoch 10/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.5102 - accuracy: 0.7819 - val_loss: 0.5030 - val_accuracy: 0.7754\n",
      "Epoch 11/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4904 - accuracy: 0.7890 - val_loss: 0.4853 - val_accuracy: 0.7846\n",
      "Epoch 12/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4752 - accuracy: 0.7957 - val_loss: 0.4725 - val_accuracy: 0.7920\n",
      "Epoch 13/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4637 - accuracy: 0.8004 - val_loss: 0.4630 - val_accuracy: 0.7932\n",
      "Epoch 14/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4545 - accuracy: 0.8049 - val_loss: 0.4546 - val_accuracy: 0.7988\n",
      "Epoch 15/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4467 - accuracy: 0.8098 - val_loss: 0.4486 - val_accuracy: 0.8025\n",
      "Epoch 16/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4400 - accuracy: 0.8129 - val_loss: 0.4458 - val_accuracy: 0.8018\n",
      "Epoch 17/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4344 - accuracy: 0.8166 - val_loss: 0.4403 - val_accuracy: 0.8086\n",
      "Epoch 18/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4292 - accuracy: 0.8198 - val_loss: 0.4375 - val_accuracy: 0.8105\n",
      "Epoch 19/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4246 - accuracy: 0.8239 - val_loss: 0.4347 - val_accuracy: 0.8123\n",
      "Epoch 20/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4198 - accuracy: 0.8261 - val_loss: 0.4332 - val_accuracy: 0.8117\n",
      "Epoch 21/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4158 - accuracy: 0.8274 - val_loss: 0.4311 - val_accuracy: 0.8111\n",
      "Epoch 22/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4120 - accuracy: 0.8293 - val_loss: 0.4301 - val_accuracy: 0.8098\n",
      "Epoch 23/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4080 - accuracy: 0.8321 - val_loss: 0.4288 - val_accuracy: 0.8105\n",
      "Epoch 24/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4033 - accuracy: 0.8355 - val_loss: 0.4257 - val_accuracy: 0.8135\n",
      "Epoch 25/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3996 - accuracy: 0.8382 - val_loss: 0.4274 - val_accuracy: 0.8074\n",
      "Epoch 26/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3953 - accuracy: 0.8403 - val_loss: 0.4248 - val_accuracy: 0.8074\n",
      "Epoch 27/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3912 - accuracy: 0.8416 - val_loss: 0.4259 - val_accuracy: 0.8074\n",
      "Epoch 28/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3860 - accuracy: 0.8459 - val_loss: 0.4259 - val_accuracy: 0.8074\n",
      "Epoch 29/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3810 - accuracy: 0.8486 - val_loss: 0.4240 - val_accuracy: 0.8074\n",
      "Epoch 30/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3758 - accuracy: 0.8522 - val_loss: 0.4234 - val_accuracy: 0.8068\n",
      "57/57 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under RoC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layer1 100, Layer2 10, Layer3 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>578.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.888105</td>\n",
       "      <td>0.838897</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.813808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 200, Layer2 20, Layer3 1</th>\n",
       "      <td>0.807309</td>\n",
       "      <td>631.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.833669</td>\n",
       "      <td>0.792714</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.805763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 300, Layer2 30, Layer3 1</th>\n",
       "      <td>0.800664</td>\n",
       "      <td>640.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.774818</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.798634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>635.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.819556</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.799827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 500, Layer2 50, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>587.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.867944</td>\n",
       "      <td>0.817549</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.804455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 50, Layer2 5, Layer3 1</th>\n",
       "      <td>0.806202</td>\n",
       "      <td>617.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.845766</td>\n",
       "      <td>0.801299</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.805572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 4, Layer4 1</th>\n",
       "      <td>0.810078</td>\n",
       "      <td>617.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.852823</td>\n",
       "      <td>0.808650</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.809886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 879, Layer2 586, Layer3 390, Layer4 260, Layer5 30, Layer6 1</th>\n",
       "      <td>0.808970</td>\n",
       "      <td>633.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.777641</td>\n",
       "      <td>0.834677</td>\n",
       "      <td>0.794228</td>\n",
       "      <td>0.777641</td>\n",
       "      <td>0.807421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 1000, Layer2 700, Layer3 400, Layer4 260, Layer5 30, Layer6 1</th>\n",
       "      <td>0.808970</td>\n",
       "      <td>627.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.840726</td>\n",
       "      <td>0.798726</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.807786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 500, Layer2 180, Layer3 60, Layer4 20, Layer5 1</th>\n",
       "      <td>0.808416</td>\n",
       "      <td>638.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.828629</td>\n",
       "      <td>0.789604</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.806626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 100, Layer3 25, Layer4 6, Layer5 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>602.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.739558</td>\n",
       "      <td>0.863911</td>\n",
       "      <td>0.816825</td>\n",
       "      <td>0.739558</td>\n",
       "      <td>0.809254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 300, Layer2 60, Layer3 12, Layer4 3, Layer5 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>630.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>829.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.773956</td>\n",
       "      <td>0.835685</td>\n",
       "      <td>0.794451</td>\n",
       "      <td>0.773956</td>\n",
       "      <td>0.806406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy     TP     FP  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     0.807863  578.0  111.0   \n",
       "Layer1 200, Layer2 20, Layer3 1                     0.807309  631.0  165.0   \n",
       "Layer1 300, Layer2 30, Layer3 1                     0.800664  640.0  186.0   \n",
       "Layer1 400, Layer2 40, Layer3 1                     0.801772  635.0  179.0   \n",
       "Layer1 500, Layer2 50, Layer3 1                     0.801772  587.0  131.0   \n",
       "Layer1 50, Layer2 5, Layer3 1                       0.806202  617.0  153.0   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           0.810078  617.0  146.0   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.808970  633.0  164.0   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  0.808970  627.0  158.0   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  0.808416  638.0  170.0   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...  0.807863  602.0  135.0   \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...  0.807863  630.0  163.0   \n",
       "\n",
       "                                                       TN     FN  Sensitivity  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     881.0  236.0     0.710074   \n",
       "Layer1 200, Layer2 20, Layer3 1                     827.0  183.0     0.775184   \n",
       "Layer1 300, Layer2 30, Layer3 1                     806.0  174.0     0.786241   \n",
       "Layer1 400, Layer2 40, Layer3 1                     813.0  179.0     0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                     861.0  227.0     0.721130   \n",
       "Layer1 50, Layer2 5, Layer3 1                       839.0  197.0     0.757985   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           846.0  197.0     0.757985   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  828.0  181.0     0.777641   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  834.0  187.0     0.770270   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  822.0  176.0     0.783784   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...  857.0  212.0     0.739558   \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...  829.0  184.0     0.773956   \n",
       "\n",
       "                                                    Specificity  Precision  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                        0.888105   0.838897   \n",
       "Layer1 200, Layer2 20, Layer3 1                        0.833669   0.792714   \n",
       "Layer1 300, Layer2 30, Layer3 1                        0.812500   0.774818   \n",
       "Layer1 400, Layer2 40, Layer3 1                        0.819556   0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                        0.867944   0.817549   \n",
       "Layer1 50, Layer2 5, Layer3 1                          0.845766   0.801299   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1              0.852823   0.808650   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...     0.834677   0.794228   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...     0.840726   0.798726   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...     0.828629   0.789604   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...     0.863911   0.816825   \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...     0.835685   0.794451   \n",
       "\n",
       "                                                      Recall  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     0.710074   \n",
       "Layer1 200, Layer2 20, Layer3 1                     0.775184   \n",
       "Layer1 300, Layer2 30, Layer3 1                     0.786241   \n",
       "Layer1 400, Layer2 40, Layer3 1                     0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                     0.721130   \n",
       "Layer1 50, Layer2 5, Layer3 1                       0.757985   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           0.757985   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.777641   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  0.770270   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  0.783784   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...  0.739558   \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...  0.773956   \n",
       "\n",
       "                                                    Area Under RoC Curve  \n",
       "Layer1 100, Layer2 10, Layer3 1                                 0.813808  \n",
       "Layer1 200, Layer2 20, Layer3 1                                 0.805763  \n",
       "Layer1 300, Layer2 30, Layer3 1                                 0.798634  \n",
       "Layer1 400, Layer2 40, Layer3 1                                 0.799827  \n",
       "Layer1 500, Layer2 50, Layer3 1                                 0.804455  \n",
       "Layer1 50, Layer2 5, Layer3 1                                   0.805572  \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1                       0.809886  \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...              0.807421  \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...              0.807786  \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...              0.806626  \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...              0.809254  \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...              0.806406  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model with different size of layer (layer1 - 300, layer2 - 60, layer3 - 12, layer4 - 3, layer5 - 1)\n",
    "model12 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "    keras.layers.Dense(300, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(60, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(12, name=\"layer3\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(3, name=\"layer4\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer5\", activation=\"sigmoid\")\n",
    "])\n",
    "# complie\n",
    "model12.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "# fit\n",
    "history12 = model12.fit(X_train_temp, y_train_temp, epochs=30, validation_split=0.1)\n",
    "\n",
    "# evaluate\n",
    "description = \"Layer1 300, Layer2 60, Layer3 12, Layer4 3, Layer5 1\"\n",
    "evaluate_model(model12, description)\n",
    "architecture_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.6404 - accuracy: 0.6460 - val_loss: 0.6165 - val_accuracy: 0.6751\n",
      "Epoch 2/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.5926 - accuracy: 0.7058 - val_loss: 0.5764 - val_accuracy: 0.7151\n",
      "Epoch 3/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.5502 - accuracy: 0.7393 - val_loss: 0.5342 - val_accuracy: 0.7458\n",
      "Epoch 4/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.5121 - accuracy: 0.7668 - val_loss: 0.5002 - val_accuracy: 0.7717\n",
      "Epoch 5/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4843 - accuracy: 0.7832 - val_loss: 0.4763 - val_accuracy: 0.7791\n",
      "Epoch 6/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4655 - accuracy: 0.7943 - val_loss: 0.4625 - val_accuracy: 0.7815\n",
      "Epoch 7/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4533 - accuracy: 0.8005 - val_loss: 0.4507 - val_accuracy: 0.7951\n",
      "Epoch 8/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4438 - accuracy: 0.8030 - val_loss: 0.4423 - val_accuracy: 0.8018\n",
      "Epoch 9/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4363 - accuracy: 0.8092 - val_loss: 0.4368 - val_accuracy: 0.8043\n",
      "Epoch 10/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4299 - accuracy: 0.8137 - val_loss: 0.4325 - val_accuracy: 0.8055\n",
      "Epoch 11/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4242 - accuracy: 0.8172 - val_loss: 0.4302 - val_accuracy: 0.8031\n",
      "Epoch 12/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4191 - accuracy: 0.8205 - val_loss: 0.4272 - val_accuracy: 0.8074\n",
      "Epoch 13/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4145 - accuracy: 0.8240 - val_loss: 0.4243 - val_accuracy: 0.8105\n",
      "Epoch 14/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4105 - accuracy: 0.8244 - val_loss: 0.4225 - val_accuracy: 0.8068\n",
      "Epoch 15/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4065 - accuracy: 0.8280 - val_loss: 0.4220 - val_accuracy: 0.8098\n",
      "Epoch 16/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4022 - accuracy: 0.8300 - val_loss: 0.4195 - val_accuracy: 0.8092\n",
      "Epoch 17/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3979 - accuracy: 0.8330 - val_loss: 0.4190 - val_accuracy: 0.8092\n",
      "Epoch 18/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3942 - accuracy: 0.8330 - val_loss: 0.4177 - val_accuracy: 0.8092\n",
      "Epoch 19/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3890 - accuracy: 0.8373 - val_loss: 0.4197 - val_accuracy: 0.8135\n",
      "Epoch 20/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3851 - accuracy: 0.8404 - val_loss: 0.4156 - val_accuracy: 0.8123\n",
      "Epoch 21/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3813 - accuracy: 0.8423 - val_loss: 0.4141 - val_accuracy: 0.8123\n",
      "Epoch 22/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3759 - accuracy: 0.8454 - val_loss: 0.4158 - val_accuracy: 0.8080\n",
      "Epoch 23/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3702 - accuracy: 0.8497 - val_loss: 0.4143 - val_accuracy: 0.8080\n",
      "Epoch 24/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3656 - accuracy: 0.8531 - val_loss: 0.4174 - val_accuracy: 0.8111\n",
      "Epoch 25/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3597 - accuracy: 0.8566 - val_loss: 0.4129 - val_accuracy: 0.8098\n",
      "Epoch 26/30\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.3537 - accuracy: 0.8577 - val_loss: 0.4137 - val_accuracy: 0.8080\n",
      "Epoch 27/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3474 - accuracy: 0.8624 - val_loss: 0.4144 - val_accuracy: 0.8086\n",
      "Epoch 28/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3407 - accuracy: 0.8667 - val_loss: 0.4165 - val_accuracy: 0.8098\n",
      "Epoch 29/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3333 - accuracy: 0.8715 - val_loss: 0.4147 - val_accuracy: 0.8092\n",
      "Epoch 30/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3260 - accuracy: 0.8766 - val_loss: 0.4181 - val_accuracy: 0.8068\n",
      "57/57 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under RoC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layer1 100, Layer2 10, Layer3 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>578.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.888105</td>\n",
       "      <td>0.838897</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.813808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 200, Layer2 20, Layer3 1</th>\n",
       "      <td>0.807309</td>\n",
       "      <td>631.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.833669</td>\n",
       "      <td>0.792714</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.805763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 300, Layer2 30, Layer3 1</th>\n",
       "      <td>0.800664</td>\n",
       "      <td>640.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.774818</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.798634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>635.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.819556</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.799827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 500, Layer2 50, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>587.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.867944</td>\n",
       "      <td>0.817549</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.804455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 50, Layer2 5, Layer3 1</th>\n",
       "      <td>0.806202</td>\n",
       "      <td>617.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.845766</td>\n",
       "      <td>0.801299</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.805572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 4, Layer4 1</th>\n",
       "      <td>0.810078</td>\n",
       "      <td>617.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.852823</td>\n",
       "      <td>0.808650</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.809886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 879, Layer2 586, Layer3 390, Layer4 260, Layer5 30, Layer6 1</th>\n",
       "      <td>0.808970</td>\n",
       "      <td>633.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.777641</td>\n",
       "      <td>0.834677</td>\n",
       "      <td>0.794228</td>\n",
       "      <td>0.777641</td>\n",
       "      <td>0.807421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 1000, Layer2 700, Layer3 400, Layer4 260, Layer5 30, Layer6 1</th>\n",
       "      <td>0.808970</td>\n",
       "      <td>627.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.840726</td>\n",
       "      <td>0.798726</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.807786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 500, Layer2 180, Layer3 60, Layer4 20, Layer5 1</th>\n",
       "      <td>0.808416</td>\n",
       "      <td>638.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.828629</td>\n",
       "      <td>0.789604</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.806626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 100, Layer3 25, Layer4 6, Layer5 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>602.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.739558</td>\n",
       "      <td>0.863911</td>\n",
       "      <td>0.816825</td>\n",
       "      <td>0.739558</td>\n",
       "      <td>0.809254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 300, Layer2 60, Layer3 12, Layer4 3, Layer5 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>630.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>829.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.773956</td>\n",
       "      <td>0.835685</td>\n",
       "      <td>0.794451</td>\n",
       "      <td>0.773956</td>\n",
       "      <td>0.806406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 250, Layer2 40, Layer3 7, Layer4 1</th>\n",
       "      <td>0.803987</td>\n",
       "      <td>612.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>0.846774</td>\n",
       "      <td>0.801047</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>0.803595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy     TP     FP  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     0.807863  578.0  111.0   \n",
       "Layer1 200, Layer2 20, Layer3 1                     0.807309  631.0  165.0   \n",
       "Layer1 300, Layer2 30, Layer3 1                     0.800664  640.0  186.0   \n",
       "Layer1 400, Layer2 40, Layer3 1                     0.801772  635.0  179.0   \n",
       "Layer1 500, Layer2 50, Layer3 1                     0.801772  587.0  131.0   \n",
       "Layer1 50, Layer2 5, Layer3 1                       0.806202  617.0  153.0   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           0.810078  617.0  146.0   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.808970  633.0  164.0   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  0.808970  627.0  158.0   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  0.808416  638.0  170.0   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...  0.807863  602.0  135.0   \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...  0.807863  630.0  163.0   \n",
       "Layer1 250, Layer2 40, Layer3 7, Layer4 1           0.803987  612.0  152.0   \n",
       "\n",
       "                                                       TN     FN  Sensitivity  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     881.0  236.0     0.710074   \n",
       "Layer1 200, Layer2 20, Layer3 1                     827.0  183.0     0.775184   \n",
       "Layer1 300, Layer2 30, Layer3 1                     806.0  174.0     0.786241   \n",
       "Layer1 400, Layer2 40, Layer3 1                     813.0  179.0     0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                     861.0  227.0     0.721130   \n",
       "Layer1 50, Layer2 5, Layer3 1                       839.0  197.0     0.757985   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           846.0  197.0     0.757985   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  828.0  181.0     0.777641   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  834.0  187.0     0.770270   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  822.0  176.0     0.783784   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...  857.0  212.0     0.739558   \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...  829.0  184.0     0.773956   \n",
       "Layer1 250, Layer2 40, Layer3 7, Layer4 1           840.0  202.0     0.751843   \n",
       "\n",
       "                                                    Specificity  Precision  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                        0.888105   0.838897   \n",
       "Layer1 200, Layer2 20, Layer3 1                        0.833669   0.792714   \n",
       "Layer1 300, Layer2 30, Layer3 1                        0.812500   0.774818   \n",
       "Layer1 400, Layer2 40, Layer3 1                        0.819556   0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                        0.867944   0.817549   \n",
       "Layer1 50, Layer2 5, Layer3 1                          0.845766   0.801299   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1              0.852823   0.808650   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...     0.834677   0.794228   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...     0.840726   0.798726   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...     0.828629   0.789604   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...     0.863911   0.816825   \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...     0.835685   0.794451   \n",
       "Layer1 250, Layer2 40, Layer3 7, Layer4 1              0.846774   0.801047   \n",
       "\n",
       "                                                      Recall  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     0.710074   \n",
       "Layer1 200, Layer2 20, Layer3 1                     0.775184   \n",
       "Layer1 300, Layer2 30, Layer3 1                     0.786241   \n",
       "Layer1 400, Layer2 40, Layer3 1                     0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                     0.721130   \n",
       "Layer1 50, Layer2 5, Layer3 1                       0.757985   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           0.757985   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.777641   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  0.770270   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  0.783784   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...  0.739558   \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...  0.773956   \n",
       "Layer1 250, Layer2 40, Layer3 7, Layer4 1           0.751843   \n",
       "\n",
       "                                                    Area Under RoC Curve  \n",
       "Layer1 100, Layer2 10, Layer3 1                                 0.813808  \n",
       "Layer1 200, Layer2 20, Layer3 1                                 0.805763  \n",
       "Layer1 300, Layer2 30, Layer3 1                                 0.798634  \n",
       "Layer1 400, Layer2 40, Layer3 1                                 0.799827  \n",
       "Layer1 500, Layer2 50, Layer3 1                                 0.804455  \n",
       "Layer1 50, Layer2 5, Layer3 1                                   0.805572  \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1                       0.809886  \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...              0.807421  \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...              0.807786  \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...              0.806626  \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...              0.809254  \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...              0.806406  \n",
       "Layer1 250, Layer2 40, Layer3 7, Layer4 1                       0.803595  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model with different size of layer (layer1 - 250, layer2 - 40, layer3 - 7, layer4 - 1)\n",
    "model13 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "    keras.layers.Dense(250, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(40, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(7, name=\"layer3\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer4\", activation=\"sigmoid\")\n",
    "])\n",
    "# complie\n",
    "model13.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "# fit\n",
    "history13 = model13.fit(X_train_temp, y_train_temp, epochs=30, validation_split=0.1)\n",
    "\n",
    "# evaluate\n",
    "description = \"Layer1 250, Layer2 40, Layer3 7, Layer4 1\"\n",
    "evaluate_model(model13, description)\n",
    "architecture_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "457/457 [==============================] - 3s 5ms/step - loss: 0.6260 - accuracy: 0.6674 - val_loss: 0.5957 - val_accuracy: 0.7102\n",
      "Epoch 2/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.5717 - accuracy: 0.7317 - val_loss: 0.5544 - val_accuracy: 0.7465\n",
      "Epoch 3/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.5322 - accuracy: 0.7612 - val_loss: 0.5167 - val_accuracy: 0.7723\n",
      "Epoch 4/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4998 - accuracy: 0.7806 - val_loss: 0.4887 - val_accuracy: 0.7840\n",
      "Epoch 5/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.4770 - accuracy: 0.7927 - val_loss: 0.4703 - val_accuracy: 0.7914\n",
      "Epoch 6/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.4618 - accuracy: 0.7986 - val_loss: 0.4581 - val_accuracy: 0.7988\n",
      "Epoch 7/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.4505 - accuracy: 0.8032 - val_loss: 0.4507 - val_accuracy: 0.8012\n",
      "Epoch 8/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.4422 - accuracy: 0.8072 - val_loss: 0.4429 - val_accuracy: 0.8080\n",
      "Epoch 9/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.4347 - accuracy: 0.8119 - val_loss: 0.4392 - val_accuracy: 0.8074\n",
      "Epoch 10/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.4283 - accuracy: 0.8161 - val_loss: 0.4351 - val_accuracy: 0.8068\n",
      "Epoch 11/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.4228 - accuracy: 0.8211 - val_loss: 0.4321 - val_accuracy: 0.8062\n",
      "Epoch 12/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.4179 - accuracy: 0.8222 - val_loss: 0.4300 - val_accuracy: 0.8055\n",
      "Epoch 13/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4131 - accuracy: 0.8273 - val_loss: 0.4295 - val_accuracy: 0.8037\n",
      "Epoch 14/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4087 - accuracy: 0.8306 - val_loss: 0.4272 - val_accuracy: 0.8074\n",
      "Epoch 15/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4043 - accuracy: 0.8306 - val_loss: 0.4278 - val_accuracy: 0.8086\n",
      "Epoch 16/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.4002 - accuracy: 0.8350 - val_loss: 0.4283 - val_accuracy: 0.8062\n",
      "Epoch 17/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3954 - accuracy: 0.8390 - val_loss: 0.4278 - val_accuracy: 0.8037\n",
      "Epoch 18/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3907 - accuracy: 0.8392 - val_loss: 0.4263 - val_accuracy: 0.8062\n",
      "Epoch 19/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.3860 - accuracy: 0.8436 - val_loss: 0.4240 - val_accuracy: 0.8074\n",
      "Epoch 20/30\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.3810 - accuracy: 0.8458 - val_loss: 0.4246 - val_accuracy: 0.8105\n",
      "Epoch 21/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.3758 - accuracy: 0.8509 - val_loss: 0.4267 - val_accuracy: 0.8062\n",
      "Epoch 22/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.3699 - accuracy: 0.8540 - val_loss: 0.4257 - val_accuracy: 0.8098\n",
      "Epoch 23/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.3648 - accuracy: 0.8560 - val_loss: 0.4254 - val_accuracy: 0.8117\n",
      "Epoch 24/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.3585 - accuracy: 0.8603 - val_loss: 0.4240 - val_accuracy: 0.8123\n",
      "Epoch 25/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.3515 - accuracy: 0.8664 - val_loss: 0.4229 - val_accuracy: 0.8148\n",
      "Epoch 26/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.3450 - accuracy: 0.8681 - val_loss: 0.4213 - val_accuracy: 0.8172\n",
      "Epoch 27/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3385 - accuracy: 0.8717 - val_loss: 0.4280 - val_accuracy: 0.8086\n",
      "Epoch 28/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3308 - accuracy: 0.8764 - val_loss: 0.4337 - val_accuracy: 0.8055\n",
      "Epoch 29/30\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3230 - accuracy: 0.8821 - val_loss: 0.4326 - val_accuracy: 0.8074\n",
      "Epoch 30/30\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.3155 - accuracy: 0.8860 - val_loss: 0.4262 - val_accuracy: 0.8135\n",
      "57/57 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under RoC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layer1 100, Layer2 10, Layer3 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>578.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.888105</td>\n",
       "      <td>0.838897</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.813808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 200, Layer2 20, Layer3 1</th>\n",
       "      <td>0.807309</td>\n",
       "      <td>631.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.833669</td>\n",
       "      <td>0.792714</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.805763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 300, Layer2 30, Layer3 1</th>\n",
       "      <td>0.800664</td>\n",
       "      <td>640.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.774818</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.798634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>635.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.819556</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.799827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 500, Layer2 50, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>587.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.867944</td>\n",
       "      <td>0.817549</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.804455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 50, Layer2 5, Layer3 1</th>\n",
       "      <td>0.806202</td>\n",
       "      <td>617.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.845766</td>\n",
       "      <td>0.801299</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.805572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 4, Layer4 1</th>\n",
       "      <td>0.810078</td>\n",
       "      <td>617.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.852823</td>\n",
       "      <td>0.808650</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.809886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 879, Layer2 586, Layer3 390, Layer4 260, Layer5 30, Layer6 1</th>\n",
       "      <td>0.808970</td>\n",
       "      <td>633.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.777641</td>\n",
       "      <td>0.834677</td>\n",
       "      <td>0.794228</td>\n",
       "      <td>0.777641</td>\n",
       "      <td>0.807421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 1000, Layer2 700, Layer3 400, Layer4 260, Layer5 30, Layer6 1</th>\n",
       "      <td>0.808970</td>\n",
       "      <td>627.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.840726</td>\n",
       "      <td>0.798726</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.807786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 500, Layer2 180, Layer3 60, Layer4 20, Layer5 1</th>\n",
       "      <td>0.808416</td>\n",
       "      <td>638.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.828629</td>\n",
       "      <td>0.789604</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.806626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 100, Layer3 25, Layer4 6, Layer5 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>602.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.739558</td>\n",
       "      <td>0.863911</td>\n",
       "      <td>0.816825</td>\n",
       "      <td>0.739558</td>\n",
       "      <td>0.809254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 300, Layer2 60, Layer3 12, Layer4 3, Layer5 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>630.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>829.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.773956</td>\n",
       "      <td>0.835685</td>\n",
       "      <td>0.794451</td>\n",
       "      <td>0.773956</td>\n",
       "      <td>0.806406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 250, Layer2 40, Layer3 7, Layer4 1</th>\n",
       "      <td>0.803987</td>\n",
       "      <td>612.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>0.846774</td>\n",
       "      <td>0.801047</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>0.803595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 200, Layer2 30, Layer3 4, Layer4 1</th>\n",
       "      <td>0.804540</td>\n",
       "      <td>608.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0.746929</td>\n",
       "      <td>0.851815</td>\n",
       "      <td>0.805298</td>\n",
       "      <td>0.746929</td>\n",
       "      <td>0.804647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy     TP     FP  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     0.807863  578.0  111.0   \n",
       "Layer1 200, Layer2 20, Layer3 1                     0.807309  631.0  165.0   \n",
       "Layer1 300, Layer2 30, Layer3 1                     0.800664  640.0  186.0   \n",
       "Layer1 400, Layer2 40, Layer3 1                     0.801772  635.0  179.0   \n",
       "Layer1 500, Layer2 50, Layer3 1                     0.801772  587.0  131.0   \n",
       "Layer1 50, Layer2 5, Layer3 1                       0.806202  617.0  153.0   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           0.810078  617.0  146.0   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.808970  633.0  164.0   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  0.808970  627.0  158.0   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  0.808416  638.0  170.0   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...  0.807863  602.0  135.0   \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...  0.807863  630.0  163.0   \n",
       "Layer1 250, Layer2 40, Layer3 7, Layer4 1           0.803987  612.0  152.0   \n",
       "Layer1 200, Layer2 30, Layer3 4, Layer4 1           0.804540  608.0  147.0   \n",
       "\n",
       "                                                       TN     FN  Sensitivity  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     881.0  236.0     0.710074   \n",
       "Layer1 200, Layer2 20, Layer3 1                     827.0  183.0     0.775184   \n",
       "Layer1 300, Layer2 30, Layer3 1                     806.0  174.0     0.786241   \n",
       "Layer1 400, Layer2 40, Layer3 1                     813.0  179.0     0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                     861.0  227.0     0.721130   \n",
       "Layer1 50, Layer2 5, Layer3 1                       839.0  197.0     0.757985   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           846.0  197.0     0.757985   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  828.0  181.0     0.777641   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  834.0  187.0     0.770270   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  822.0  176.0     0.783784   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...  857.0  212.0     0.739558   \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...  829.0  184.0     0.773956   \n",
       "Layer1 250, Layer2 40, Layer3 7, Layer4 1           840.0  202.0     0.751843   \n",
       "Layer1 200, Layer2 30, Layer3 4, Layer4 1           845.0  206.0     0.746929   \n",
       "\n",
       "                                                    Specificity  Precision  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                        0.888105   0.838897   \n",
       "Layer1 200, Layer2 20, Layer3 1                        0.833669   0.792714   \n",
       "Layer1 300, Layer2 30, Layer3 1                        0.812500   0.774818   \n",
       "Layer1 400, Layer2 40, Layer3 1                        0.819556   0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                        0.867944   0.817549   \n",
       "Layer1 50, Layer2 5, Layer3 1                          0.845766   0.801299   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1              0.852823   0.808650   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...     0.834677   0.794228   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...     0.840726   0.798726   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...     0.828629   0.789604   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...     0.863911   0.816825   \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...     0.835685   0.794451   \n",
       "Layer1 250, Layer2 40, Layer3 7, Layer4 1              0.846774   0.801047   \n",
       "Layer1 200, Layer2 30, Layer3 4, Layer4 1              0.851815   0.805298   \n",
       "\n",
       "                                                      Recall  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     0.710074   \n",
       "Layer1 200, Layer2 20, Layer3 1                     0.775184   \n",
       "Layer1 300, Layer2 30, Layer3 1                     0.786241   \n",
       "Layer1 400, Layer2 40, Layer3 1                     0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                     0.721130   \n",
       "Layer1 50, Layer2 5, Layer3 1                       0.757985   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           0.757985   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.777641   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  0.770270   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  0.783784   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...  0.739558   \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...  0.773956   \n",
       "Layer1 250, Layer2 40, Layer3 7, Layer4 1           0.751843   \n",
       "Layer1 200, Layer2 30, Layer3 4, Layer4 1           0.746929   \n",
       "\n",
       "                                                    Area Under RoC Curve  \n",
       "Layer1 100, Layer2 10, Layer3 1                                 0.813808  \n",
       "Layer1 200, Layer2 20, Layer3 1                                 0.805763  \n",
       "Layer1 300, Layer2 30, Layer3 1                                 0.798634  \n",
       "Layer1 400, Layer2 40, Layer3 1                                 0.799827  \n",
       "Layer1 500, Layer2 50, Layer3 1                                 0.804455  \n",
       "Layer1 50, Layer2 5, Layer3 1                                   0.805572  \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1                       0.809886  \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...              0.807421  \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...              0.807786  \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...              0.806626  \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...              0.809254  \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...              0.806406  \n",
       "Layer1 250, Layer2 40, Layer3 7, Layer4 1                       0.803595  \n",
       "Layer1 200, Layer2 30, Layer3 4, Layer4 1                       0.804647  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model with different size of layer (layer1 - 200, layer2 - 30, layer3 - 4, layer4 - 1)\n",
    "model14 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "    keras.layers.Dense(200, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(30, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(4, name=\"layer3\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer4\", activation=\"sigmoid\")\n",
    "])\n",
    "# complie\n",
    "model14.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "# fit\n",
    "history14 = model14.fit(X_train_temp, y_train_temp, epochs=30, validation_split=0.1)\n",
    "\n",
    "# evaluate\n",
    "description = \"Layer1 200, Layer2 30, Layer3 4, Layer4 1\"\n",
    "evaluate_model(model14, description)\n",
    "architecture_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment with learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "457/457 [==============================] - 8s 16ms/step - loss: 0.6872 - accuracy: 0.5514 - val_loss: 0.6850 - val_accuracy: 0.5575\n",
      "Epoch 2/30\n",
      "457/457 [==============================] - 7s 16ms/step - loss: 0.6826 - accuracy: 0.5550 - val_loss: 0.6794 - val_accuracy: 0.5575\n",
      "Epoch 3/30\n",
      "457/457 [==============================] - 7s 15ms/step - loss: 0.6762 - accuracy: 0.5568 - val_loss: 0.6717 - val_accuracy: 0.5575\n",
      "Epoch 4/30\n",
      "457/457 [==============================] - 7s 16ms/step - loss: 0.6623 - accuracy: 0.6084 - val_loss: 0.6519 - val_accuracy: 0.6498\n",
      "Epoch 5/30\n",
      "457/457 [==============================] - 7s 15ms/step - loss: 0.6335 - accuracy: 0.6709 - val_loss: 0.6181 - val_accuracy: 0.6726\n",
      "Epoch 6/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.5955 - accuracy: 0.6914 - val_loss: 0.5815 - val_accuracy: 0.6991\n",
      "Epoch 7/30\n",
      "457/457 [==============================] - 7s 15ms/step - loss: 0.5500 - accuracy: 0.7228 - val_loss: 0.5268 - val_accuracy: 0.7428\n",
      "Epoch 8/30\n",
      "457/457 [==============================] - 9s 20ms/step - loss: 0.4971 - accuracy: 0.7636 - val_loss: 0.4816 - val_accuracy: 0.7668\n",
      "Epoch 9/30\n",
      "457/457 [==============================] - 9s 19ms/step - loss: 0.4649 - accuracy: 0.7852 - val_loss: 0.4609 - val_accuracy: 0.7748\n",
      "Epoch 10/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.4495 - accuracy: 0.7968 - val_loss: 0.4496 - val_accuracy: 0.7914\n",
      "Epoch 11/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.4393 - accuracy: 0.8059 - val_loss: 0.4425 - val_accuracy: 0.7963\n",
      "Epoch 12/30\n",
      "457/457 [==============================] - 7s 14ms/step - loss: 0.4312 - accuracy: 0.8090 - val_loss: 0.4340 - val_accuracy: 0.8055\n",
      "Epoch 13/30\n",
      "457/457 [==============================] - 7s 14ms/step - loss: 0.4253 - accuracy: 0.8154 - val_loss: 0.4321 - val_accuracy: 0.8049\n",
      "Epoch 14/30\n",
      "457/457 [==============================] - 7s 14ms/step - loss: 0.4194 - accuracy: 0.8173 - val_loss: 0.4281 - val_accuracy: 0.8092\n",
      "Epoch 15/30\n",
      "457/457 [==============================] - 7s 14ms/step - loss: 0.4143 - accuracy: 0.8209 - val_loss: 0.4289 - val_accuracy: 0.8092\n",
      "Epoch 16/30\n",
      "457/457 [==============================] - 7s 14ms/step - loss: 0.4099 - accuracy: 0.8259 - val_loss: 0.4327 - val_accuracy: 0.8135\n",
      "Epoch 17/30\n",
      "457/457 [==============================] - 6s 14ms/step - loss: 0.4037 - accuracy: 0.8287 - val_loss: 0.4499 - val_accuracy: 0.7957\n",
      "Epoch 18/30\n",
      "457/457 [==============================] - 7s 16ms/step - loss: 0.3992 - accuracy: 0.8313 - val_loss: 0.4272 - val_accuracy: 0.8080\n",
      "Epoch 19/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.3931 - accuracy: 0.8332 - val_loss: 0.4357 - val_accuracy: 0.8098\n",
      "Epoch 20/30\n",
      "457/457 [==============================] - 8s 17ms/step - loss: 0.3865 - accuracy: 0.8368 - val_loss: 0.4259 - val_accuracy: 0.8098\n",
      "Epoch 21/30\n",
      "457/457 [==============================] - 7s 16ms/step - loss: 0.3777 - accuracy: 0.8427 - val_loss: 0.4203 - val_accuracy: 0.8154\n",
      "Epoch 22/30\n",
      "457/457 [==============================] - 7s 16ms/step - loss: 0.3693 - accuracy: 0.8473 - val_loss: 0.4289 - val_accuracy: 0.8043\n",
      "Epoch 23/30\n",
      "457/457 [==============================] - 8s 17ms/step - loss: 0.3591 - accuracy: 0.8537 - val_loss: 0.4219 - val_accuracy: 0.8172\n",
      "Epoch 24/30\n",
      "457/457 [==============================] - 7s 16ms/step - loss: 0.3496 - accuracy: 0.8604 - val_loss: 0.4274 - val_accuracy: 0.8105\n",
      "Epoch 25/30\n",
      "457/457 [==============================] - 9s 20ms/step - loss: 0.3348 - accuracy: 0.8679 - val_loss: 0.4327 - val_accuracy: 0.7969\n",
      "Epoch 26/30\n",
      "457/457 [==============================] - 10s 23ms/step - loss: 0.3216 - accuracy: 0.8741 - val_loss: 0.4570 - val_accuracy: 0.8025\n",
      "Epoch 27/30\n",
      "457/457 [==============================] - 10s 23ms/step - loss: 0.3087 - accuracy: 0.8782 - val_loss: 0.4394 - val_accuracy: 0.8055\n",
      "Epoch 28/30\n",
      "457/457 [==============================] - 9s 19ms/step - loss: 0.2925 - accuracy: 0.8864 - val_loss: 0.4578 - val_accuracy: 0.8049\n",
      "Epoch 29/30\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.2826 - accuracy: 0.8914 - val_loss: 0.4717 - val_accuracy: 0.7932\n",
      "Epoch 30/30\n",
      "457/457 [==============================] - 8s 17ms/step - loss: 0.2734 - accuracy: 0.8959 - val_loss: 0.4636 - val_accuracy: 0.8006\n",
      "57/57 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under RoC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layer1 100, Layer2 10, Layer3 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>578.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.888105</td>\n",
       "      <td>0.838897</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.813808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 200, Layer2 20, Layer3 1</th>\n",
       "      <td>0.807309</td>\n",
       "      <td>631.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.833669</td>\n",
       "      <td>0.792714</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.805763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 300, Layer2 30, Layer3 1</th>\n",
       "      <td>0.800664</td>\n",
       "      <td>640.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.774818</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.798634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>635.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.819556</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.799827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 500, Layer2 50, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>587.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.867944</td>\n",
       "      <td>0.817549</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.804455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 50, Layer2 5, Layer3 1</th>\n",
       "      <td>0.806202</td>\n",
       "      <td>617.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.845766</td>\n",
       "      <td>0.801299</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.805572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 4, Layer4 1</th>\n",
       "      <td>0.810078</td>\n",
       "      <td>617.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.852823</td>\n",
       "      <td>0.808650</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.809886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 879, Layer2 586, Layer3 390, Layer4 260, Layer5 30, Layer6 1</th>\n",
       "      <td>0.808970</td>\n",
       "      <td>633.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.777641</td>\n",
       "      <td>0.834677</td>\n",
       "      <td>0.794228</td>\n",
       "      <td>0.777641</td>\n",
       "      <td>0.807421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 1000, Layer2 700, Layer3 400, Layer4 260, Layer5 30, Layer6 1</th>\n",
       "      <td>0.808970</td>\n",
       "      <td>627.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.840726</td>\n",
       "      <td>0.798726</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.807786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 500, Layer2 180, Layer3 60, Layer4 20, Layer5 1</th>\n",
       "      <td>0.808416</td>\n",
       "      <td>638.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.828629</td>\n",
       "      <td>0.789604</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.806626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 100, Layer3 25, Layer4 6, Layer5 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>602.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.739558</td>\n",
       "      <td>0.863911</td>\n",
       "      <td>0.816825</td>\n",
       "      <td>0.739558</td>\n",
       "      <td>0.809254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 300, Layer2 60, Layer3 12, Layer4 3, Layer5 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>630.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>829.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.773956</td>\n",
       "      <td>0.835685</td>\n",
       "      <td>0.794451</td>\n",
       "      <td>0.773956</td>\n",
       "      <td>0.806406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 250, Layer2 40, Layer3 7, Layer4 1</th>\n",
       "      <td>0.803987</td>\n",
       "      <td>612.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>0.846774</td>\n",
       "      <td>0.801047</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>0.803595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 200, Layer2 30, Layer3 4, Layer4 1</th>\n",
       "      <td>0.804540</td>\n",
       "      <td>608.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0.746929</td>\n",
       "      <td>0.851815</td>\n",
       "      <td>0.805298</td>\n",
       "      <td>0.746929</td>\n",
       "      <td>0.804647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 879, Layer2 586, Layer3 390, Layer4 260, Layer5 30, Layer6 1, learning_rate=0.02</th>\n",
       "      <td>0.803433</td>\n",
       "      <td>626.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>825.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.769042</td>\n",
       "      <td>0.831653</td>\n",
       "      <td>0.789407</td>\n",
       "      <td>0.769042</td>\n",
       "      <td>0.801910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy     TP     FP  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     0.807863  578.0  111.0   \n",
       "Layer1 200, Layer2 20, Layer3 1                     0.807309  631.0  165.0   \n",
       "Layer1 300, Layer2 30, Layer3 1                     0.800664  640.0  186.0   \n",
       "Layer1 400, Layer2 40, Layer3 1                     0.801772  635.0  179.0   \n",
       "Layer1 500, Layer2 50, Layer3 1                     0.801772  587.0  131.0   \n",
       "Layer1 50, Layer2 5, Layer3 1                       0.806202  617.0  153.0   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           0.810078  617.0  146.0   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.808970  633.0  164.0   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  0.808970  627.0  158.0   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  0.808416  638.0  170.0   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...  0.807863  602.0  135.0   \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...  0.807863  630.0  163.0   \n",
       "Layer1 250, Layer2 40, Layer3 7, Layer4 1           0.803987  612.0  152.0   \n",
       "Layer1 200, Layer2 30, Layer3 4, Layer4 1           0.804540  608.0  147.0   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.803433  626.0  167.0   \n",
       "\n",
       "                                                       TN     FN  Sensitivity  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     881.0  236.0     0.710074   \n",
       "Layer1 200, Layer2 20, Layer3 1                     827.0  183.0     0.775184   \n",
       "Layer1 300, Layer2 30, Layer3 1                     806.0  174.0     0.786241   \n",
       "Layer1 400, Layer2 40, Layer3 1                     813.0  179.0     0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                     861.0  227.0     0.721130   \n",
       "Layer1 50, Layer2 5, Layer3 1                       839.0  197.0     0.757985   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           846.0  197.0     0.757985   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  828.0  181.0     0.777641   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  834.0  187.0     0.770270   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  822.0  176.0     0.783784   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...  857.0  212.0     0.739558   \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...  829.0  184.0     0.773956   \n",
       "Layer1 250, Layer2 40, Layer3 7, Layer4 1           840.0  202.0     0.751843   \n",
       "Layer1 200, Layer2 30, Layer3 4, Layer4 1           845.0  206.0     0.746929   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  825.0  188.0     0.769042   \n",
       "\n",
       "                                                    Specificity  Precision  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                        0.888105   0.838897   \n",
       "Layer1 200, Layer2 20, Layer3 1                        0.833669   0.792714   \n",
       "Layer1 300, Layer2 30, Layer3 1                        0.812500   0.774818   \n",
       "Layer1 400, Layer2 40, Layer3 1                        0.819556   0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                        0.867944   0.817549   \n",
       "Layer1 50, Layer2 5, Layer3 1                          0.845766   0.801299   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1              0.852823   0.808650   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...     0.834677   0.794228   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...     0.840726   0.798726   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...     0.828629   0.789604   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...     0.863911   0.816825   \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...     0.835685   0.794451   \n",
       "Layer1 250, Layer2 40, Layer3 7, Layer4 1              0.846774   0.801047   \n",
       "Layer1 200, Layer2 30, Layer3 4, Layer4 1              0.851815   0.805298   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...     0.831653   0.789407   \n",
       "\n",
       "                                                      Recall  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     0.710074   \n",
       "Layer1 200, Layer2 20, Layer3 1                     0.775184   \n",
       "Layer1 300, Layer2 30, Layer3 1                     0.786241   \n",
       "Layer1 400, Layer2 40, Layer3 1                     0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                     0.721130   \n",
       "Layer1 50, Layer2 5, Layer3 1                       0.757985   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           0.757985   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.777641   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  0.770270   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  0.783784   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...  0.739558   \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...  0.773956   \n",
       "Layer1 250, Layer2 40, Layer3 7, Layer4 1           0.751843   \n",
       "Layer1 200, Layer2 30, Layer3 4, Layer4 1           0.746929   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.769042   \n",
       "\n",
       "                                                    Area Under RoC Curve  \n",
       "Layer1 100, Layer2 10, Layer3 1                                 0.813808  \n",
       "Layer1 200, Layer2 20, Layer3 1                                 0.805763  \n",
       "Layer1 300, Layer2 30, Layer3 1                                 0.798634  \n",
       "Layer1 400, Layer2 40, Layer3 1                                 0.799827  \n",
       "Layer1 500, Layer2 50, Layer3 1                                 0.804455  \n",
       "Layer1 50, Layer2 5, Layer3 1                                   0.805572  \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1                       0.809886  \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...              0.807421  \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...              0.807786  \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...              0.806626  \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...              0.809254  \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...              0.806406  \n",
       "Layer1 250, Layer2 40, Layer3 7, Layer4 1                       0.803595  \n",
       "Layer1 200, Layer2 30, Layer3 4, Layer4 1                       0.804647  \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...              0.801910  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model with different learning rate (0.02)\n",
    "model15 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "    keras.layers.Dense(879, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(586, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(390, name=\"layer3\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(260, name=\"layer4\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(30, name=\"layer5\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer6\", activation=\"sigmoid\") \n",
    "])\n",
    "# complie\n",
    "model15.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=0.02),\n",
    "              metrics=['accuracy'])\n",
    "# fit\n",
    "history15 = model15.fit(X_train_temp, y_train_temp, epochs=30, validation_split=0.1)\n",
    "\n",
    "# evaluate\n",
    "description = \"Layer1 879, Layer2 586, Layer3 390, Layer4 260, Layer5 30, Layer6 1, learning_rate=0.02\"\n",
    "evaluate_model(model15, description)\n",
    "architecture_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMQAAAL3CAYAAABlDpnDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd5wkdZn48U91zj055815l01EycFVlFMUxQCe4fTEhP4UPEW5ZEA97hRB70RE9NRTMbECy8IiYYHNeWfD7OQcO8eq3x/V3TOzM7M7s2nS895Xvaq3p0NVzzxdVc/3+X6/iqZpGkIIIYQQQgghhBBCzBKGyd4AIYQQQgghhBBCCCEuJEmICSGEEEIIIYQQQohZRRJiQgghhBBCCCGEEGJWkYSYEEIIIYQQQgghhJhVJCEmhBBCCCGEEEIIIWYVSYgJIYQQQgghhBBCiFlFEmJCCCGEEEIIIYQQYlaRhJgQQgghhBBCCCGEmFUkISaEEEIIIYQQQgghZhVJiIkzVl9fj6IoPPbYYxN+7pYtW1AUhS1btpzz7RJCjI/EsBDTl8SvENObxLAQ05fE78whCTExZdTW1vK5z32OSy+9FJvNhqIo1NfXT/ZmCSHG6fe//z233XYbNTU1OBwOFixYwOc//3n6+/sne9OEEKfx5JNPcuONN1JSUoLVaqWsrIxbb72V/fv3T/amCSHOwPXXX4+iKNx1112TvSlCiNP4+te/jqIoIxabzTbZmzbjmSZ7A4RI27p1K//1X//F4sWLWbRoEbt3757sTRJCTMDHPvYxSkpKeP/7309FRQX79u3jBz/4ARs3bmTnzp3Y7fbJ3kQhxBj27dtHdnY2n/nMZ8jLy6O9vZ1HH32UdevWsXXrVlasWDHZmyiEGKff//73bN26dbI3QwgxQQ8//DAulyvzf6PROIlbMztIQkxMGW9729vo7+/H7Xbzne98RxJiQkwzv/3tb7nqqquG3bd69WruuOMOfvGLX/CRj3xkcjZMCHFa991334j7PvKRj1BWVsbDDz/MI488MglbJYSYqEgkwuc//3m+9KUvjRrXQoip69ZbbyUvL2+yN2NWkS6T01y6vPLIkSO8//3vx+v1kp+fz1e/+lU0TaOpqYm3v/3teDweioqK+O53vzvs+Z2dnXz4wx+msLAQm83GihUr+NnPfjbiffr7+7nzzjvxer1kZWVxxx13jNkN6vDhw9x6663k5ORgs9lYs2YNf/rTn067Lzk5Objd7jP6HISYrmZSDJ+cDAP4u7/7OwAOHTp0+g9DiGlmJsXvaAoKCnA4HNLtWcxYMzGGv/3tb6OqKl/4whcm9FkIMd3MxPjVNA2fz4emaRP6LMSZk4TYDHHbbbehqirf/OY3Wb9+Pf/6r//Kgw8+yPXXX09paSnf+ta3mDt3Ll/4whf429/+BkA4HOaqq67i5z//Oe973/t44IEH8Hq93Hnnnfznf/5n5rU1TePtb387P//5z3n/+9/Pv/7rv9Lc3Mwdd9wxYjsOHDjAxRdfzKFDh7jnnnv47ne/i9Pp5JZbbuHJJ5+8YJ+HENPNTI3h9vZ2AGntEjPaTIrf/v5+urq62LdvHx/5yEfw+Xxce+215+aDEmKKmikx3NjYyDe/+U2+9a1vyTAFYtaYKfELUFNTg9frxe128/73v5+Ojo5z8yGJsWliWvva176mAdrHPvaxzH2JREIrKyvTFEXRvvnNb2bu7+vr0+x2u3bHHXdomqZpDz74oAZoTzzxROYxsVhMu+SSSzSXy6X5fD5N0zTtD3/4gwZo3/72t4e9xxVXXKEB2k9/+tPM/ddee622bNkyLRKJZO5TVVW79NJLtXnz5mXue+GFFzRAe+GFF0bdrwceeEADtBMnTpzJxyLEtDFTYzjtwx/+sGY0GrUjR45M6HMRYjqYifG7YMECDdAAzeVyaV/5yle0ZDJ5xp+REFPZTIvhW2+9Vbv00ksz/we0T37yk2f24Qgxxc2k+H3wwQe1u+66S/vFL36h/fa3v9U+85nPaCaTSZs3b542MDBw1p+VGJtUiM0QQ8fmMRqNrFmzBk3T+PCHP5y5PysriwULFlBXVwfAxo0bKSoq4r3vfW/mMWazmU9/+tMEAgFefPHFzONMJhOf+MQnhr3Hpz71qWHb0Nvby/PPP8+73/1u/H4/3d3ddHd309PTw4033sjRo0dpaWk5L/svxHQ3E2P4l7/8JT/5yU/4/Oc/z7x58yb2gQgxjcyk+P3pT3/K008/zQ9/+EMWLVpEOBwmmUye2QcjxDQxE2L4hRde4He/+x0PPvjgWX0WQkw3MyF+P/OZz/D973+f22+/nXe+8508+OCD/OxnP+Po0aP88Ic/PLsPSJySDKo/Q1RUVAz7v9frxWazjeim5PV66enpAaChoYF58+ZhMAzPiy5atCjz8/S6uLh42IwXAAsWLBj2/2PHjqFpGl/96lf56le/Oup2dnZ2UlpaOsG9E2Lmm2kx/NJLL/HhD3+YG2+8kX/7t3877eOFmM5mUvxecsklmdvvec97Mtvzne9855TPE2I6m+4xnEgk+PSnP80HPvAB1q5de7rdFWJGme7xO5bbb7+dz3/+8zz33HPcc889436emBhJiM0Qo03JOtY0rdp5GqRPVVUAvvCFL3DjjTeO+pi5c+eel/cWYrqbSTG8Z88e3va2t7F06VJ++9vfYjLJoUbMbDMpfofKzs7mmmuu4Re/+IUkxMSMNt1j+PHHH6e2tpYf/ehH1NfXD/uZ3++nvr4+M0mGEDPNdI/fUykvL6e3t/estk2cmlylzGKVlZXs3bsXVVWHZccPHz6c+Xl6vXnzZgKBwLDseG1t7bDXq6mpAfRy0+uuu+58b74Qs95UjOHjx49z0003UVBQwMaNG0e0qAkhdFMxfkcTDocZGBg4Z68nxEwxlWK4sbGReDzOZZddNuJnjz/+OI8//jhPPvkkt9xyy4ReV4iZairF71g0TaO+vp5Vq1adk9cTo5MxxGaxDRs20N7ezq9//evMfYlEgu9///u4XC6uvPLKzOMSiQQPP/xw5nHJZJLvf//7w16voKCAq666ih/96Ee0tbWNeL+urq7ztCdCzE5TLYbb29u54YYbMBgMPPPMM+Tn55/N7gkxo021+O3s7BxxX319PZs3b2bNmjUT2jchZoOpFMPvec97ePLJJ0cs6fd/8sknWb9+/VntrxAzyVSK37F+/vDDD9PV1cVNN900oX0TEyMVYrPYxz72MX70ox9x5513smPHDqqqqvjtb3/LK6+8woMPPojb7Qbg5ptv5rLLLuOee+6hvr6exYsX8/vf/37UFuOHHnqIyy+/nGXLlvHRj36UmpoaOjo62Lp1K83NzezZs2fM7RkYGMh8ubzyyisA/OAHPyArK4usrCzuuuuu8/ApCDF9TbUYvummm6irq+OLX/wiL7/8Mi+//HLmZ4WFhVx//fXn/kMQYpqaavG7bNkyrr32WlauXEl2djZHjx7lJz/5CfF4nG9+85vn7XMQYrqaSjG8cOFCFi5cOOrPqqurpTJMiJNMpfgFvRLttttuY9myZdhsNl5++WV+9atfsXLlSv7hH/7hvH0OQhJis5rdbmfLli3cc889/OxnP8Pn87FgwQJ++tOfcuedd2YeZzAY+NOf/sRnP/tZnnjiCRRF4W1vexvf/e53R5RwLl68mO3bt3P//ffz2GOP0dPTQ0FBAatWreK+++475fb09fWNGITwu9/9LqB/SUhCTIjhploMpw/03/72t0f87Morr5SEmBBDTLX4/cQnPsFTTz3F008/jd/vp6CggBtuuIEvf/nLLFu27Hx8BEJMa1MthoUQ4zfV4vd973sfr776Kr/73e+IRCJUVlbyxS9+kX/6p3+Ssf/OM0U7XyPLCSGEEEIIIYQQQggxBckYYkIIIYQQQgghhBBiVpGEmBBCCCGEEEIIIYSYVSQhJoQQQgghhBBCCCFmlQknxP72t79x8803U1JSgqIo/OEPfzjtc7Zs2cJFF12E1Wpl7ty5PPbYY2ewqUKIsyXxK8T0JjEsxPQl8SvE9CYxLMTMM+GEWDAYZMWKFTz00EPjevyJEyd4y1vewtVXX83u3bv57Gc/y0c+8hGeeeaZCW+sEOLsSPwKMb1JDAsxfUn8CjG9SQwLMfOc1SyTiqLw5JNPcsstt4z5mC996Us89dRT7N+/P3Pfe97zHvr7+3n66afP9K2FEGdJ4leI6U1iWIjpS+JXiOlNYliImcF0vt9g69atXHfddcPuu/HGG/nsZz875nOi0SjRaDTzf1VV6e3tJTc3F0VRztemCjEtaZqG3++npKQEg+HcDgso8SvE+ScxLMT0JfErxPQmMSzE9HUu4ve8J8Ta29spLCwcdl9hYSE+n49wOIzdbh/xnG984xvcf//953vThJhRmpqaKCsrO6evKfErxIUjMSzE9CXxK8T0JjEsxPR1NvF73hNiZ+Lee+/l7rvvzvx/YGCAiooKTpw4gdvtHvU58XicF154gauvvhqz2XyhNnVKmK37Plv3G4bveyQSobq6eszYuNAkfidG9l32XWJ4epN9n337LvE7c8i+y75LDE9vsu+zb9/Pdfye94RYUVERHR0dw+7r6OjA4/GMmhUHsFqtWK3WEffn5OTg8XhGfU48HsfhcJCbmzur/iBg9u77bN1vGL7v4XAY4LyUUUv8nn+y77LvEsPTm+z77Nt3id+ZQ/Zd9l1ieHqTfZ99+36u4/fcdpQexSWXXMLmzZuH3bdp0yYuueSS8/3WQoizJPErxPQmMSzE9CXxK8T0JjEsxNQ34YRYIBBg9+7d7N69G9Cnk929ezeNjY2AXub5wQ9+MPP4j3/849TV1fHFL36Rw4cP88Mf/pDf/OY3fO5znzs3eyCEGDeJXyGmN4lhIaYviV8hpjeJYSFmngknxLZv386qVatYtWoVAHfffTerVq3ivvvuA6CtrS3zpQBQXV3NU089xaZNm1ixYgXf/e53+Z//+R9uvPHGc7QLQojxkvgVYnqTGBZi+pL4FWJ6kxgWYuaZ8BhiV111FZqmjfnzxx57bNTn7Nq1a6JvJYQ4xyR+hZjeJIaFmL4kfoWY3iSGhZh5zvsYYkIIIYQQQgghhBBCTCWSEBNCCCGEEEIIIYQQs4okxIQQQgghhBBCCCHErCIJMSGEEEIIIYQQQggxq0hCTAghhBBCCCGEEELMKhOeZVIIIYQQQgghhBBCiLOSiELUD/EQxCP6OpFax8NQczVYHOft7SUhJoQQQgghhBBiZgn1gpoAV8Fkb4kQs5eqQn8D9BzT1/2N0N8EA0367UDHqZ//qZ2QO+e8bZ4kxIQQQojzSdNAUSZ7K4QQE6FpEOiE3uNQeelkb40Q4lTCfdB5GLoOQVctdB6CrsP6hfa6f4AN357sLRRi5ktEoec4dB/R47C7FrqOQM9RveLrdEw2fTE7wJxe28/7ObQkxIQQQogzpWn6QT7Uq7d69TVAX/3w2ytvh2u/OtlbKoQYTTIBfSf0E/juI/rJe/cR6D4K0QH9MV88AY6cyd1OIWajeAQGmqG/Xq8k8bVBsBOC3XrCOn07Fhj7NULdF2xzhZjRNA0iAxDs0pPNffWpxNdRPfnVVw+aOvpzjVa9yiu7GrLKwVsOWRWp2xVgzwbD5AxvLwkxIYQQ4mTJRKq8+7he4p1egt0QD0IspI9tEAsC2qlfq+/EBdlkIcQYNE2vIPG1DLZcdx1OtVwfAzU++vMUA2RV6if/khAT4vyIhfRKzO6jg8favno9AeZvG//reEohfyEULBqyXgBW93nbdCFmnGCPfpzsOZqKyeN6HKYT0MnYqZ9v9UDefD32hq6zq8BgvCC7MFGSEBNCCDF7xUJDKkMOp1q6jkDvibEvkkdjMIG3TL94zq7UD/xZqXVOzfnaeiEE6Akvf/tgLPfVg69Vv8+fWp+qu4bZAXnz9JP2oUtOjd5tQwhxdjRNb1Dqrh08zqYrMQeaTv1cs1OvJMmuBE8JOAvAlQ/O/NTt1CKJLyFOL5nQj4t9DYO9GfpTPRq6j+iNR6dj9ejx5y0bTHilk1+uwmk3TIgkxIQQQsxMsZDe1cLXopd2+9tT6zbwd4CvWR/Uc6wKL5NdL+/OnQO5c/XFXQQWl34BbXHoJ+rp9SSVegsxY8Uj+phA4X69GjMW1LtGpdf9TSO7N56KPWcw8ZW/UD95z18AnjKJXyHOVDKuV3X5WvWL6VCPPoxAqAfCvTDQoifCTnWhbctKXVTP04+1OdWp7lRVenXmNLvAFmJShPtTjbuH9XPeUM/gEkyvO/WJJk7FWwF5c/WYzJ2rJ76GJqLN9guyOxeKJMSEmOq01MW6nAwIMVwyAQON0FOnd7foa9D/P5BKdI133BB7zvCL43RLl6dULpKFuFASUejYD627oXWXvu46dPoT9zTFoI9NkjdfT2J7SsBdrC+eYnAVSbWXEGcr1KvHafv+1HqffvF9um5UACh6kmtoV6rceXoSzJEr57lCjEc8ojf09jei9NSxtPkZjL98VE86j7eLsdEyOIZXduVg74a8+ZAzR2/onUUkISbEhaSqemZ+oEWvThlo0b/UfC0Q8emt3vF0K3ho8P9fqgebd7K3XogLKxZMdXlqG1z7WqG3Th/ToK/+9N0aLW7wluol3O5icBfqF8buQnCX6CfizrwLsjtCzDrRgJ6gHmjWu0X5WvRxSCID+hL1pW779EqS0ZJfjlw9Zi3OIYtLX7uLBhPYuXPAZL3w+yjETBPs0RuZeuuGLz3HIdI/+nMsbv2C2pGjNzJl1rl6d8Z0pcksu9AWYsKGznCcHlOv98TgsTTYmXmoCZgD0DXk+emx9LLK9fhz5KXWuXpcps+HpcE3QxJiQpypZFxvKYv06yWqw9apkvFgt16lEupN3e6Z2LhEabGQJMTEjGRKhlFad8FAw5ABPI/p1V7j6QJltOrj/OTO0cfr8pYPmb2mXO+GIa3OQpwfiSiuSBvK8c3ga9KT1OlZVvubxr54Hos9B0pWQcnK1HqVfnIvMSzEuZOeZKLnBMV9b2B4+TD0nxi8+D7dGELZVVC4FIqW6evCJXqFiVxgCzF+alJPdHUd1quh02Pr9dRBzH/q55qdkFWO6i7lhN9E5dqbMBUv1asu5XpxwiQhJsTJ4hG9pXroGAi+Vr1lOz0e0UBqTKLTzS43GsWQ6sJRop/oe8v0tT1bbzmzOFPjEg1ZnPnnfDeFOKcSMf1CeGg119DxuuJBvUtUZolgSkZ5SywIe0/xuman3t3JXaxXg7iL9G5RuXP0sm7p1ijE+aFp+jGwty41SH26ork1dSxsxRzs5FqAQ6d4HZtXT1B7y/TFVagnqm0e/WfW1NqRo8e5JL+EmBhV1Y+3vhaI+gdnQI4FB2/72/Qk9UCTvo4HMQPrAOpHeU1P6WBjU07N4JJdpZ+XCiFOLxFLxVyDPmtq35DB67uPQjI6+vMUg37cTI9fm1Mz2NjrLdOvGRWFZDzO/o0bqVi1AczmC7prM4kkxMTskEzoX0jpmadC3fo06sHu1NI1OOhgPDSBF1ZSJ/VZYM8aXNuzB0tUnUPXefrFgFFCT0xTalK/GO48qC8dqXX30QlXP6YvezVnAUruXH0Az9zUgLrpMYBk1ighzq1oQK8AifqHLD597WtNddM4rq8jp6/STBhsGPPmoGRX6RfL2VWpMUkq9Itqm+d875EQM18ykbqQrtXjMz07XF+9fqE91oX1KWjOAvo0N1lz1mDInz/84lu6NgpxevGIHn8DjcMTzum1vxU0deznm+yQPx/yFw0Zw3aefhyVIQAuGLkqF9OTpkGwC2/oBErDy6DGTmoNC+hVXH0nUv2um8Y/MC+AYhw+/oG7SB+HyFOWWqcquxx5Up0iZg5V1atB2nZD+97BGaPCfXqlSLgvdYE8RmWkxaXHhjs1PsHQcbusHv3gbrLpg3mabMQx8uxL27jhbe/CLC1bQpw78QgE2qH7WKoLRqo7cvdR/f6J8JTqVZnpY5+nJFXZXELcUcjGF15jw1veIjEsxNlQk3qjbKAjVV3doR+Pu4+kYvj4qRudFKN+vLV5Uj0NHEPWDv14nBlSoAK8pSQw8dLGjWzYsAGDxK8Qo0sm9ArL3rrUsfTY4DG1v5HT9hYy2fQuxUMHsM+blxrnqwIMxguyG2JskhATU0MyrrdOxwJ663UskGqxTt0O9QyWmvY3Qn8j5kSYqwBqx/keRqv+ReQp1Qf4dOYPVm1lbqeSYDavdNsQ05+q6uMQhPv1+Ep1VSQR0WeESkT0+zsOQtsePQkWC5z+dQ1mvRWrcDEULNbHDylYpJ9sTyRu4nESpoNnvHtCzDqqqp+Yp8fq6qvXW6DT1c6hbn1A7NONP2K06Elqqzu1pG678vWuyOluUtnVp64UicflWCnEeIT7U1UjjcOXgSY9+RXsAi156tcw2fUL6dy5J1VjVupJauMEk1rxMxjTVoiZQtP0cS79HXpDUXrta9MnPvO16kug49RVXhb38LFrh60r9WtOOU5OaZIQE+dfoCs1YGBq6T462F0jFkhdqEcm/LIaClGTF6s3H8XqSo275RhsFUuPNZRTrZ80uEukmktMb6qaShT79Ljyt6UO4u2DY3WFugcnd4gMnPogPhqTHYqWQvEKPW4ys0Vlp5bUben2K8S5o2l6vKYrRPztwytFAu1694v+Bj2ZPR5Gi57cypuXWubrXZLz5sqgu0KcS8m4ntAKdKYS1unG24bBsYPG0f0YFL1x1lWoX0R7y1PdqBbo3ao8ZXIeK8R4pMfA9LcOmem4efh40IHO8V9/GkyDlV25c1Pr1LHVmS8Jr2lOrmjE+KVP2NMn6YFOfR3u17spJiJ6N41EODUwfZ8+1kGoZ/zvYbLp3a6sLj3jbnXp/7dn6WWlWRWZstOEo5Bnnt3Mhg0bpKuGmJ4iA9B5lKKBnSi7+yDaf9KEDr36Y6I+iPhOX/UxFqNV70Zhsqe6LVoHuy+abPqFcvEKfcmbL8kuIc4FVU0luNqHJ7bSx85Qj17NFUrPQDzObv0Gk14Nkq4Q8ZTpF9HDqp7zpNJZiDORqeRq0i+ahw5MHw8P3g71QrBTT4SdblbGNEfukHPZ1Pmst1yfOMZVqMeuHH+FOLVoYHCyM18rhv4mlje9jvH/fqXHZLpRabzj2tq84CrSh/dwFQ1OeuYpGbztzJdk9Awm37qzSTIxOHBuuG9IK3Tn4Al7sFvvVpWM618kQ9eh3jMatBMU/aQ9fyEULNRbupz5qW4aLn1tSa0nUu4tpd5iqosFh83IpndxSo1r13cCQj2YgfUAdRN4XaNVj6H0rIvuotTBvCh1IZw1fJIHs/2c75oQs1YyoR8zB1pgoAlDfxNLWl7H+Mc/D5mwJTVpy+m6QJ3M4tIrQ1xF+tpdlKoWKRxMgnlK5aJZiDOVnhgmNXmEofso646/gem/v6UnwqK+M3tdxZg6LhcOjheUVTk4wYS3XD/nFUKMlIgNVm+lr0fTk52ll2C3fi4dHV5taQSqAbpHeV1HbmrMy9Qsx5mxMEsHE9FyjjzryRnVdJdMQKgXT7gR5egzEGgbXhoa6hlMgk1o9sRTsHkHT9BdBXr3KbNdrz4x2/QuiyabnuDKnatXnMhsNWK6SsRSF7lDxucJduldEuMhPYEcD6cqJFOtx/7U9OeR/tO+vObMp19z4y2uweDK1w/e9mx97UiNZ2f1DFl7ZOYZIc6liC81U1tqxrZAZyqmU9XO6dhOz8LobxuW6DICcwE6x3h9R14qsTUk0eUqPGkG4lz9cWbbed9dIaY1VU11T2wfnPRl2NKvdyvONOgm9OpLNa43AveeGNa4awSKAYbmwRy5egLLW6Yfdy0O/Tx36NAc9uzUeLSpMWnt2VJBIsRQ/g59qJxIv95AnB4XOj1edKBj8Ho10MFpB6cfyurJVHCpziKOdgSYu/JyjFklQ6q9CuV8WYzLGSXEHnroIR544AHa29tZsWIF3//+91m3bt2Yj3/wwQd5+OGHaWxsJC8vj1tvvZVvfOMb2Gxy4pehJlMH+NTAmunuUkO7T4X7BrtOpadJj4cwA1cDHB7ne5nsqaTWSa3P6eoSk12v1DKa9cGzjRa9NdqerR/45YR9WpP4PUksNDhteWbMjyED3oZ7z+71LW40TwmqtQjVVozmKgV3KZqrBM1ZSDxpZOu2N7ju1vdjsUsrlTg9ieFTUJNDTrKb9ARWpqtTeLB7fyykjy3S13BmMW4wpU7Gy1DdxdR1haheug6jp1i/OHblpy6U8yY+0LWY0SR+T0HT9HPegaaTxv1pHVz8bePvCjUWg1kfXzZnDsnsKva3hFhy2Zsx5Vbrg2FbnOdmf8SMJDE8hKbp16O+Vmjfr0/O1LFfvx0cq5VoDEZrZgbj4Y1FuYONxJ7SwdlUU5LxOIc3bqRmzQaMMoSOOAMTToj9+te/5u677+aRRx5h/fr1PPjgg9x4443U1tZSUFAw4vG//OUvueeee3j00Ue59NJLOXLkCHfeeSeKovC9733vnOzElJZM6F8I/rYhA18PGQA7PatFqHvig18PETW5seRVo2RVpEpCywb7PNs8gxUmFheYLOdwB8V0MivjNxHV4y3ddTHdXTG9DnSQiBjQVDCYNQwmbeSwO4oR1ZJL0pBDQvOQTDpJqrZUstgMBksmiaxhIhHUiPtixLv9JDq6iLe2ogaPAkdH3cRqoO4HD2GdNw/booVYFy7EtnAhlpoatGiU5ICP5EA/qs+n3/b7MBcVY1u6FHNpCcopxgnSVJV4axvxlha0RBySSbREAi2R0G/H4yT7+0n09JLs7Umte0n09qIYDBi8HoweL0avF6PHg8HrwZSdjamgILUUYirIx2DRv1fUYJDIkSNEDx8mcugwkcOHiR47htHtxlJdjaW6Cmt1NZbqagxlZRh9PiJ79hDu7CTe1ka8pZV4WxvJgQEMdjsGp3PkYrOhWK0YbFYUqw3FasFgs2EuK8NcVnbKzwNAjUQI795NtLYWxW7H6M3C6PVg9Hgwer0YvF4MTudpX2cyzMoYPpmq6onr7iPQVauPVdl7YjABNt6xuIZy5A6OyeUuTlU921JVIakKaItjsKuFqyAzVXoiFKL2N7+hwL4U2ntIdLaR6NpDorMTLanqseP1YPB4Bv/WsrL0+MnPx2A9Py3Yeuy3Ej1ylOixY0SP6utYfT3mggJsy5ZhW7oE+9Kl2BYtwuCUJMD5JvFLqstiE/Qcg57jqfWx1IyLzeMc5FrRz2/TFdWZJUtfTLZUg65JT14bUo28jlx9BlVveSZ+1Xic+o0bWTz3OpCLaXEasyqGE1H92JrqXkzvcf0aNl2kkV7GHBpA0WcrdubrSeb0uNAWl/5/Z/7gNau3XE+ATcHzLgAtmQSD4YKfF2qaBomE/t5G4wV979lkwgmx733ve3z0ox/lQx/6EACPPPIITz31FI8++ij33HPPiMe/+uqrXHbZZdx+++0AVFVV8d73vpfXX3/9LDd9igj3Q2+dXmGSGeCvRR9bxNeqJ7zGmehKxo2EA3kkVA8GlxuD24vBk43Bm4MhqwBDVl4qsTVkzC2Lm4TJxjOvvs6Gt771tIPLJwcGiDUdRfX7MOXnYyoowOB2n/MA12IxEv39JLq6SHR2kuhMrztJ9PRgzMnGUl6BpbwMc3kFlopyjF591istmUxdoPeQ7O0j2duDGoli9Lj1i1WPF2OWF9Vu11smxLjN2PhVk2gdtQQ3/RHfpheJdXRj9SaxuYNYHb3YvAkMZv1vRdMg5jMR6rIQ6rIQ7iogHhr+VahYzRgcNoxOFxoKyd5+1FAIvU/FGY4vAihmM5hMKEYjismUuR3r68MQjRLZv5/I/v0Tek1jVha2pUszF7aK1Ur06DH9Aji1aKFz1F36NNthcDqJt7aOGpeJUIhERweh114bdv8coPlcbkduLvYVK/Rl5UrsS5eA2Uxkzx6Cr79B6PXXCe/ejXaaMQgVsxljbi6mnByMOTmYcnMw5uSi2KyQSKIlk3qCcdTbCUgm0OIJtGQS1xVXkPPBD5yT/ZuxMXyyRCw1sHWDXsWV7tLYfQx6jp7yolnTjESTJYR9WUQHzGC2YrDbMDjsGJx2jE4nBocT7Fmo5iw0oxtVVdAiUbTuKFqnisE6PNmqpJJWiY7DxNteIN7aSrytlXhrK8mubmqAljPc1UxyrKAAU24OaiyGGgyiBkOpdVD//lGU1HZZUWxWDBYris2GYlBQI1G0aBQ1GkGLxtAiEZJ+P1pk9M8p1tBArKEB31/+ot+hKFjm1GCpqEwlnh2ZBLTR6cTgco9M6nk8aCYTSixGoqODZCiEOjBAMpW4V8zmzOMM3sGkumIy6Sf5qqpfZMTjetwkx7ioUlWSvb3ETz6X6OxEMZswFRdjLi7BXFKCuaQYc0kJRo9n9NeaZLMmfqP+1EyLJ8VvX71+zny6mVJdRcMbd72lwwe6dhVOmcpLNRIh3txMrLGJeFMjWiKBuVj/OzQVl2DKz0M5h10pE319qIEA5pKSCV8ga5pGsq+P2IkTxE6cIHy8jry6OvwGI65VKzGXlk7JhqCpZEbGsKbpsdm2B9p2Q9te/Tjb38S4uzFa3Gj5i9ByFqHmLEDzzkV1lYNixlxejmGc1XBaMonq9+vnx6lzZEymCf9dapqGFg6jRscY+1pV9WNmJIoWjWRuq2H9XDXdOBtvayPe2kqiowOj2506306dcy9bhqmwEEVR0GIxYg0NmYan6NGjxJpbQAHFeNK+GI1o8XjqmD3k2B2J6vcPOS6i6jkExWbDfcP1ZN16K461a89JnGqqqp+vphvJDUaMrtnZMDahhFgsFmPHjh3ce++9mfsMBgPXXXcdW7duHfU5l156KU888QRvvPEG69ato66ujo0bN/KBD5ybi4MLJtwHJ16CzoP6wbznuL4eT1cLxThk8OvizADY8YSLcIOP0NF2QgeOET1Wl/rDD6aW9nFv3jyDgRP/8SDmTNWGnuzSIlHizU3EGpuINTWhDoyc9lmx2Qafk5unX6hPgBqNoA74UifB+snwmVyAGzweFKORZH//uBNdc00mGh75EZbKCj3BVlGOuaxcT7Dl5OhVHhbLqF8cyUBw8MS6q5Okz4fR7U6d8HsHF49HT2RMczMqfkO9ULsRrfF1Int2MbCjBV+9mWR08OQwDOijg+QDGpYsA+YsG5GuBMngSckQg0FfEnpliRaNk4zGSfYNn9UxnSQx5mRj9HhRDKMdkBRM+XmYSkr0k+LiEsylJZiLijA4Ro6lF4/H2fiXv3Dd8uUkjx4jUnuYaKqyKtHeDiaTXrmUqV7y6ImnxiYiR46Q7O8n+PLLBF9+ecyPSzGb9RNdq1U/IJtN+gHaaEQxmzBmZWHMydWTPtk5GHNzMOXkgKbpMT2Qju0B1IEBEj29Q5LdnWixGMn+fj12AVNBAdaFC7AtXKRXvM2bhxoIEK3TT8Jj9SeInjhBrKERLZnEXFioX8ymLiLMJcUYs7JRI+GRiYFgcPAkIhLJ3FbDIWINjSR7egg8/zyB55/P/G4VsxntpJMiU0EB9hUr9Ao5n4+kb4DkwABq/4B+QhKPk2hv138HZ8lcVHjWrwEzLIaHSiag8wA0vg5Nr0PzNj0ZpqloGsQDRqI+E9EBM2pCwWAyYbB4MGQXYMgrxZhfiWovJNzkI3ykmcjB2lQCewIzHJ8l1WjEUlSIuaBwSPVkPorRpMdNuroznTDq7R0RO9EjR077PhMcoh/FYsFSU4N17lx9mT8PS2Ul8dY2Igf2E96/n8j+AyTa24kdO07s2PGJvYHBwDxVpX4izzGbz/ukOIrFMkoDhBHFaBqzAkFRlGHfjZnbJhMl33kA8yjVHxMxY+MX9KqR+pfhxN+g/iX9/HgUWhLiYSPxsJO4UkQ8kUU8aiMRAKxOjDl5GPOKMFqyMZg9GM1ZGDQrWncCrT0JyUa0RB1aIqlXmk2EppEMBkn29JLoHWxwTfT0MNcf4Pg//0vmojXz92IyY7BaUFLJ50xC2mol0d1FvLGJROdpuoWZzZiLivRjW3kZltQ56smNwSM2V1WJNzenKq0PET1cq58XtLUBoFitWOakY3se1nlzsVRWogaDwxqUEz29JHq6iTc0Eq2vH3EdkAN0vPgiHYDR681c8FvnzgVFGVJZnszcxmBEMaU+J6Mpc1uxWjE4XcOS6kanE8VmGzXutGhUT86fSJ0TnKjXzxGamjBlZ2NdtHDwPGLhQkz5+SiKQtLnSyUdBitfk729WObUDD5+wUL9O/gcJvhmTAwn43q8Ht8Mrbv1bo6RkdeHAFjcqN5qYolioiE38ZCRREglGYyT8IdJDgRJ9PtQBwbQ4s3oTZybhr+G2Yxt4UK9kTLVWGkuLQFNI9bQQGT/ASL79xM+sJ/IwUOjX0Om4tLgcIzoNYDNRklTE82//F9Uvz9znD3Xx5nkwADBV14h+Morg5uVl4fR6yXW0JC5hjgftEgE35/+jO9Pf8ZSWYn31neSdcstkJWVeYwaDBKtrydWd4JYfT2Jnm793KM/dd6Ruk5XQyF9W0e51rbMmYNz/Xoc69fjWLcWU3b2qNuTDASIt7aOeb2vWCyYS0vH/H6baiaU+eju7iaZTFJYOPzkvrCwkMOHRx/A6vbbb6e7u5vLL78cTdNIJBJ8/OMf58tf/vKY7xONRokOuXjx+fSKjHg8TnyMP+70/WP9fMKScZTWnSh1L6Cc2KLfPqnSS9MgETISjeeRtBZgn1eBsawaPCVobr0VS/OU6APlGoxomkZ0/34Cz20m+PzzxOvrR7ytubwcc0U5ajg87CJQCwbRYmO3qCmqSrKzk+TpDszoFRQGj4dkTw+qz4cWiRBvbCTe2Djhj+mUDAa9wiI/H2NBPqZ8vXuIMSdbb+1taiLe1Ey8uZlktx60gzuk6C3KqeoMg9VK0u9HHXJhQTKJIZEgXl9PvL6e4FjbMewL1IGWSJDo7JpQ0s5UWIi5qgpLVRXm6qrMbS0WI15fT6y+ntiJ+sxtNRDQn1NSjKmoWG/BLinGVFSEIdW6bvB4MLhcZ9RyOPTvfbx/89MxftMxk+jqRuvvRq3fhtawE63jBGpMI9BmIx4wAXrLk9FuwL2qDNuSRUR7YkSbe4meaCHZ1U2sXyPWr6fJFKsV2/Ll2C66CPtFF2FbsRzF4UCLxdDSCZhQEDUQ0P+O03+HLtcZn1wl0cc5GHXfDQaU4mLsFRXYr71mcP9jMTCbx3xPNRoldvQo0QMHiBw4SPTAAUgmMdfU6CfHc+ZgmTsPc0X5hBPdaadLBWuahurzkejsRPX7MVdWYsrNHfE4A2BasoShbU+xSITnNm3i+ptuOm1163io0SjRQ4eJ7t1LZM8eInv3kmhvR4tGMebkYF+3DvvatdjXrcVcWTnq56ppml5d099PsreXZE8vyT69G2mytxctGku1XBqHtPalL55SF9Lp1kCTEYxGzJVVI/62Z0sMj0rTUNp2oRx9BqX5DWjeSdIfJh40kggZiQVNxAY8RH0Woj4T2pjnmCH0bsgjuyIrDge2ZUuxLl4CBoMe16EhydVQEEUxoFgteiWYzYpi0bvhgoIWi6JFY4OttrEYWjKJqbAAU1Ex5uIiTCUlmIqKIT+P57dt4/obbpjQ37EeO34SnR0ku7pIdHaR7O3RLyod+vFKSZ/0OxygoW9XJF0JpieFUTV9+0/aD4PTiam4eNTYt1ZUYL14PelT1UR3N9GDB0l0dKY+pyDakM9K9QdI+nyoqSXp8+kn1KnWa4zGweOax4PR7UFLxDPHa9Xn079P4YwuUgxeb+pcoiBV3Z6PMS8fEgnibW0kUku8rQ21r0//fZ3inGmi4tHosO2e1fELJHu7CP32R2jN+7Ak6rCqjZidSZQhpzOqLYcYJYQHvIQ7IdIUINrcDWr6IixMuulqshlAbwg50+e7XJjLyzCVlaGYzCQ62km0tevJsng8db7bBKNUBRncbjCZBqs00tWSY1VMol9satEo0YOHiB48NOHtNZWUYK6qwlRRTtOJegr8fmJHjox6wT9ZYgMDxOrr8f/16cx9xpwcMJnGvNaJHjly0uOzsSxYiPPKN5H1vvcNe+ysi+GoH+X4ZgxH/opybBNqwE+k14ymKmgqaIoLzV2G6q5Ac5YQD5qItg4Qa9Cv1VBHm8LxFMzmTFWY6vcT2bePyL599P3854B+LarFYno12Hik4iIZjZLs6xvxYxcwns7WQykWSybBrQ/DYdOLRPLzMRUXY0pdw5mLizAVFZHo7iF64ADRg/o5d+zoUZLd3SS79c9GcTqxzJmTOf82V1bqje3pngOJJFpSj3PFbB6sQremqr2tVv3+IT1I9KSzkXh9Pb7fP4n/r38l1tBA13e/R9eD/4nt4ospa2/nxHe/N64cwOnEjh8ndvw4fb/8JQCWBQuwr14Nqkq8rVX/XmtrG/fvzeDx6LmNsjL9O7K4BNCGNGynK/RiaNEIamqtn3elKvhiMUq+/1+Yiooyr3sm8Xsq532WyS1btvDv//7v/PCHP2T9+vUcO3aMz3zmM/zLv/wLX/3qV0d9zje+8Q3uv//+Efc/++yzOEapsBhq06ZNp/z5qZiSYYoGdlHcv418/0FM6uCBOhlX6OktYcCfQ9xvQO2Po/QGMcTTZ+o9QA+xnAbCVVWEq6sIV1cTz2nG3tCAa/9+XPsPYB7SMqMpCtHiIsJV1ZnnJE9V5q+O0fVS0zAGg5h8vhGLZjQRz80hlptLPCeXeG4OmmVwDDElHsfk82H0+fXnBPxDTlbGRzOZUO12kg47Sbs9dduBarONPeOO2w2VlYPbEYth7u3VW/BcLpIOB5yqFFzTUGIxTIEApr4+LD09mHt6Mff2Yu7pwdzbizHdVSSRyJzEnyxptZLweEh6PCTtNgyRKMZwGEM4jDEcwhCJomgaiY4OEh0dhCdQ4pxobibRfOrOYJqi6J+X3U7S6dQXl5OEy5W67SLpdBGurkIb5UJr06ZNhM5jd7jJjF9zdzeFv38Sx/HRKhYG0yqa2Uh44Vz6Vl9McP78wb+bucB6/aYxEMDa2oa5r5doURGR0lL9BBSgvw9efPGU20WqRfZ8OpvvLtxuuHi9vgyVSMDhQ/pyoUy0ospoPLt9H01eLlx7DVx7DaaBAZRYjHjekLEpDh7Ul/Eym6GwUF/ORGuLvoxiJsfwMJqGN9xASe9r5J/YRqI+TKjTSjxoJB72gDp2K6JqMhHLzydWVEjS7sAQjQ5fYlFAIVJaSqSygnBFBbHCwvM/41s0Cg31+qIoZ/93bDHDkBM+EgkYGNCXsSgKGBU9WROPQ+Ckk9R9+ya2DU6HvuTnn/pxqWOwIRpFtVr184rTNRYkkxgiEQzxOJrRiGYw6I2FRoN+W1HGfo1T/S7zcmHZ0sx/lVgMYzCIoqqgqijJ5LDbY1I1FDWJkkw9Vk09L6ly9LXXhp07pc2a+AUM4TAFu18ka9d21CY/qEN/V4WgAG4ziZwcYmYX1pY2jKFeYHhPCtVkIpGVRTw7m0SWl3iWvkYjc+5lDIcxhMIYw2GURBzNYNQT25m/m/TfzCl3ZwTVYs2cZyVT51kJlwvVakVJdeMd9veSSKIk4hjiCZREHCWewBCPoyTiJJ1O4rm5xHJyUB2O0f92k0lMPj+m/n7MfX2Z81NLr37OavL7T3lhqZpMxAoLiZYUEy0pIVJcQqy4CNViwdzXh6W9HWtHJ5aODqwd7Zh6+1BttmH7lt7feHYOsfw84nl5w/+WV62iE1ASCSzt7diaW7A1N2Pu6QZlyGduNKAZ9NuKpkHqc9JjJKnHSzwx4vtZOU2Pj6Tdrn+/5+cRy88nnp9PLDcXk8+Pta0Na1sr1tY2LF1dJHsH/5biXi+xoiKihYXECgtIOl365zDs8X2Et26lPRalY4xKl5kew3n+g8zt3Eiu7yDJARhosxJotRHqLjophkEfEmR/ahku6XAQLSwknptL0uUi4Rq8Rkm6nPp1n9mMZjajmUyD39mahqmvD3tjI7bGRuwNjVhbW0n26BXcqsmk/22XlRIpKyNaVkYsN3eMeExgSB13hp8DxFBNZtTUdah+Leog6bCPeu2UMZ5zBDUJLS36AuBywrp1sG4dSjyOtbUNQyRCrLCAhNc7/Hsg3Qh0MpNJr6qJhPVlvNatRVmxHPfevXjf2Ia9sZHIK6/gYLB6POF0puIoj4TXO/h5OByZa3TVah31GGyIRnGcOIH9+HEcx+uwdnQQq60lVls76uYkHQ6SY3SFNaSu0VWfT08iHjgw/v0cxZa/Pk2scGSV9rmKX0XTxj8IUywWw+Fw8Nvf/pZbbrklc/8dd9xBf38/f/zjH0c854orruDiiy/mgQceyNz3xBNP8LGPfYxAIIBhlD/G0TLj5eXldHd34xkjYRSPx9m0aRPXX3/9xCoNYkGUY89iOPgHlGPPoaSmYtY0iMZyCATnEWhSCB9pGb21xmTCXF6OYrEQO3p0ZNIq1eqTpjgcON/0JpzXXovjsksxut3j39YxnPG+T3On228tmUQNhVKVAYPVdhiNg+OnnebAoiWTqAMD+tgQqeqvdEVarLERxWTCUlWJuWqwasxcVYXR69W7W7W1E29vI9GaasHu6NDLVVOVeeNV9dwmTEMuxofuezgcJi8vj4GBgTHjA6ZP/JqAvkd/St+Pf4wWi6EYNaxZcYwmDcXpwJBfiVKyAENuCZa5c3FeffVpf49T2WyNX5B9n6kxPOx36WtFef1/iDz/RwK1ffhbbCRCo7TFGY2YCgsxFRVhKi7GUlWFZe4cLHPn6hMlnGGF44Ugf8ezb99nS/xqqkrgj78h8LsnCO1vHDZ2tjVbw1RcRNwP8c7+Ed3SQa/Gti5ejG3Fcr0qe9kyjKkxd6aKyfwbVkMhvYpZVVMVxsOrjQ1u93kdsuN873t6HKcxqzWNxnFX3qvhMLFjx9CSKpY5Nae9flLDYWLHjxM9fBhzeTmO9cMbDGdDDKu1LxH9rw8QbDUSbLWOGC/XVFKC0esZrHRPVSQpJiOmomIsQ3oaGHNzzlncqpEIsdraVLffOWf9Nz5bj0Ox48fxbdnC4dZWVm54C/a5c/Xf5zmS6O4hvH0bkT17MNjteo+nkmLMxXrPp9Nde6mhEPHm5lRvsCYSTc3E29v0oQhSVXEGi2XUCne9m/rgWK72VauGvd+ZxO+pTOgM02KxsHr1ajZv3pz5IlBVlc2bN3PXXXeN+pxQKDQi2I2pCo6xcnFWqxXrKLMumc3m0/6hj+cxgD5w4EvfgyPPQCKcGackHKkkFK0keLSfeEc30JR5iqWqCvua1VirazKzpVnKyjKBnAwECO/aRWjHDsLbdxDeuxctFsPg9eK++mrcN9yA87JLz9uMUuPe9xlmzP02m8Fmg5ycs3lxsNmwFRbC2jXDfqSpKijK2AeIqqpTvrQajWaSY8mBAZJ9faPO9Jfs6cFaUIBhlH00m80kxtlnfTrEb2LfPtr++V+IparCnMUxilb3Ybn672H1nVC4ZMrOQHO2Zmv8guz7TIrhoY+J1h6g54u34q9TUeMG9E4N+qQVzssuw3XV1VjnzNEHn87Pn9JJr/GY7X/Hs3HfZ3L8JgcGaPnk3xPcPlhNa/Em8ayuxvOuD2K98j2ZmRo1TSPR2ZUZs1aLhPWxqBYsQBmlsm4qmpS/Ya8X6xQYY+e87vu5+v2bzVgvumhij1+1CveqVad52MyJYUMkQmzrVvzbdxB89WWitUeBwQSBYrHgWLcO15vehOtNV2A5zXXKeWM2Y12z5vSPm/DLzq7jkHnhQixz5uDbuBHX6ovO+b6bi4uw33wz3Hzzmb1A+vttyZJzul1DTSR+T2XCZ5933303d9xxB2vWrGHdunU8+OCDBIPBzGwbH/zgByktLeUb3/gGADfffDPf+973WLVqVaZU9Ktf/So333xz5gvhglJVePW/SD79b0R6INxtIewrJdxjIRmIAnHgGJD64li/fvCLY0gXv9EYXS5cV1yB64or9LeKxYg3N2MpL58Rg7KL4c521iCD1YqhoADOcqDeiZiq8Zsc8FHwu9/T8sYbABhzcyi8GDyu/SjzrocND8zYRJgQEzFVY3ioyMGDdP/4v/E/83RqgioDxiwX7muvw3XdDTgvuWTcM04JMZNMh/gFPYab77qLeGsbilEjZ7Ubzzveg/XGj6DYRyZwFEXBXFiAubAAx+rV5227hJhsUzGGI4cP03rffczZf4C2k3oqWbIVnNe/A+c11+Fct25a96gQ4nyZcELstttuo6uri/vuu4/29nZWrlzJ008/nRlgsLGxcVgm/Ctf+QqKovCVr3yFlpYW8vPzufnmm/m3f/u3c7cXp6BpGvGWFiKHDhHdvY3I335HtMVHPJQ39FFAFMVsxrZkCfYVK3BccjHO9esx2O1n/N4GiwVrTc1Z74MQ58pUjF8tmaT5Ax8g68QJALLedSsFV+ZifPlrYHHDzQ9KMkyIlKkYw2n2Eydo/fgnCA0ZkNlVEiH3k3dj/7tPnnUjghDT3VSO37T+J/9A+9e/jhaNYnYmKHt7HrYvbwHT+endIMR0MhVj2JiTQ3TvPhT0ydmcxSoO434cZVbMn9kMeXPP2XsJMROdUf+Eu+66a8zS0C1btgx/A5OJr33ta3zta187k7c6K0mfj6ZP/CPhHTtO+om+2+ayMuzLl2NfqU8Ba124EMM0Ke0W4kxNtfhVjEayPvgBmh9+hJpvfwvPgiL44SX6D6+/H7xl5+29hZiOploMRw4epO1f/pXyXbsIARgMeJZ4yS2txXbRFfCOuySpLUTKVIvfNCWRoPNf/gXfb/4P0JPZJZdHMf7jRkmGCTHEVIthc0EBRd/7Lq92dXHTwhjGv34BUOD2xyUZJsQ4TO8BO04h6ffT+JGPEtm7F4wKVk8UW1YCW2Uhtlu/jHXdNRjPcOA1IcS55XnHO2i0WFhy0UXwv7dCPASVl8PqD032pgkhTkOxWons3o1qNJL1jneQf8NiLJv/ARQj3PRNSYYJMcXF29spe+RH+JqaQFHIW+onb7EP5ZaHIG/eZG+eEOI0XNdfj+c3/4HhmW/rd1z7VZh/w+RulBDTxIxMiCUDQZo++jEie/ditClUXNmBLTsJV9wNV90LRhnPS4ipRDEY0EwmlN1PwIkXwWSHt/3X+KZEFkJMKuucORT88z+zNRLmxne9E/P/XKX/YP0/QMHCSd02IcSpaapK2yc+gb2pCYPHTenlIVweHyx5B6x832RvnhBiPHytrD3xAxQ1Dkv+Di6/e7K3SIhpY8ZdbaqhEE0f/wfCu3djcNoof1MntiIH3PkXuPY+SYYJMUXZYr0YN9+n/+ear0DunMndICHEuHlueTtJjwfDjp9Ady048uDKL032ZgkhTkMxGMi75x4iZWVUfmQuLk8TeCvgrf8h1Z1CTAfxCMbffhBbYgCtYAm8/SGJXSEmYEYlxJRYjLa7PkV4+w4MLhcVbzVjz4nDxZ+Aqssne/OEEGPRNJY3/Qwl6ofSNXrMCiGmFUvch+Fv39L/c+1XwZ41qdsjhBgfx/r1aO9dga31Kb2r8zv/R+JXiOmibgtK2x6iRheJdz0OFudkb5EQ08qMSYipkQglP3uc8LZtGJxOKr5yB3alVp+lbv3HJ3vzhBCnoBz8PcW+XWgGM7z9B2A4f9PJCyHOj0Vt/6cntYuWw6oPTPbmCCHGq/c4y1t+rt++6l6oWD+52yOEGL8FN5G87Zdsr74Lsione2uEmHZmREJMjUZp/+xncR47hmK3U/7jH2Fv/5X+w/X/AI6cyd1AIcTY1CTGVFWJevnnoWDRJG+QEGLC2nZT2fM3/fabvy1JbSGmC1XF+IePY1IjqBWX6uPtCiGmFW3u9XS7F0/2ZggxLc2IhJjvL38h9MqrqGYzJT98CIezHdr3gcUFl3xysjdPCHEqBiOJ9/+JY/k3oV766cneGiHERGkaxmf/CQUNdck7ofKSyd4iIcR4GQyoV96Lz1ZK8u2PSDJbCCHErDIjZpn0vuMdRBoa2YvG/NWr4dFr9R+s+5hUhwkxHbiLOFB2O5VGy2RviRBiog7+EUPz6yQMFrRrvjYzWtqEmEW0OdfwwsJ/Y4OnZLI3RQghhLigZsR5q6Io5H7qLsJz5qAcfQba94LZCZfcNdmbJoQQQsxs828iedU/cbj4nSAX1EJMT8qMuCQQQgghJmRmHf00DcNLD+i3130UnLmTuz1CCCHETGe2oV72OY4XvHmyt0QIIYQQQohxm1EJsULfHgzte8DsgEs/NdmbI4QQQgghhBBCCCGmoJmTENM0FrT/Qb+99sPgzJvUzRFCCCGEEEIIIYQQU9OMSYgpdc+THapDM9lBZqoTQgghhBBCCCGEEGOYGQmxIWOHqavvBFfB5G6PEEIIIYQQQgghhJiyZkZC7PjzGFq2k1TMqBfLzJJCCCGEEEIIIYQQYmymyd6AcyJ3Dury26lr76fKVTjZWyOEEEIIIYQQQgghprCZUSGWXUXy5v/iYMltk70lQgghhBBCCCGEEGKKmxkJsTRFmewtEEIIIYQQQgghhBBT3MxKiAkhhBBCCCGEEEIIcRqSEBNCCCGEEEIIIYQQs4okxIQQQgghhBBCCCHErCIJMSGEEEIIIYQQQggxq0hCTAghhBBCCCGEEELMKpIQE0IIIYQQQgghhBCzyhklxB566CGqqqqw2WysX7+eN95445SP7+/v55Of/CTFxcVYrVbmz5/Pxo0bz2iDhRBnR+JXiOlNYliI6UviV4jpTWJYiJnFNNEn/PrXv+buu+/mkUceYf369Tz44IPceOON1NbWUlBQMOLxsViM66+/noKCAn77299SWlpKQ0MDWVlZ52L7hRATIPErxPQmMSzE9CXxK8T0JjEsxMwz4YTY9773PT760Y/yoQ99CIBHHnmEp556ikcffZR77rlnxOMfffRRent7efXVVzGbzQBUVVWd3VafRNM0Xjnew/5ehQ3n9JWFmFmmYvwKIcZPYliI6UviV4jpTWJYiJlnQl0mY7EYO3bs4Lrrrht8AYOB6667jq1bt476nD/96U9ccsklfPKTn6SwsJClS5fy7//+7ySTybPb8iH+uLuVOx/bwe/rDSRV7Zy9rhAzyVSNXyHE+EgMCzF9SfwKMb1JDAsxM02oQqy7u5tkMklhYeGw+wsLCzl8+PCoz6mrq+P555/nfe97Hxs3buTYsWP84z/+I/F4nK997WujPicajRKNRjP/9/l8AMTjceLx+IjHXz0/B4/NRE8kwXMH27lxafFEdmvaS38mo302M9ls3W8Yvu/j3f+pGr8n789sI/su+y4xPL3Jvs++fZf4nTlk32XfJYanN9n32bfvZxK/pzLhLpMTpaoqBQUF/PjHP8ZoNLJ69WpaWlp44IEHxvwi+MY3vsH9998/4v5nn30Wh8Mx6nPW5hjY3GrgP/+6h2TjrnO6D9PFpk2bJnsTJsVs3W/Q9z0UCp23179Q8Zs223+Xs9Vs33eJ4ZlB9n32kfidOWTfZyeJ4ZlD9n32OVfxO6GEWF5eHkajkY6OjmH3d3R0UFRUNOpziouLMZvNGI3GzH2LFi2ivb2dWCyGxWIZ8Zx7772Xu+++O/N/n89HeXk5N9xwAx6PZ9T3Wdrt54X/fJWjPgPVqy5jUbF7Irs2rcXjcTZt2sT111+f6Z8+G8zW/Ybh+x4Oh8f1nKkcv/K7lH2fzfsuMTy9yb7Pvn2X+J05ZN9l3yWGpzfZ99m372cSv6cyoYSYxWJh9erVbN68mVtuuQXQM9+bN2/mrrvuGvU5l112Gb/85S9RVRWDQR+y7MiRIxQXF4/6JQBgtVqxWq0j7jebzWP+sivy3KzI1djVo/Dz15t44F0rJrJrM8KpPp+ZbLbuN+j7nkgkxvXYqRy/E3nMTCX7Pnv3XWJ4ZpB9n337LvE7c8i+z959lxieGWTfZ9++TyR+T2VCg+oD3H333fz3f/83P/vZzzh06BCf+MQnCAaDmdk2PvjBD3LvvfdmHv+JT3yC3t5ePvOZz3DkyBGeeuop/v3f/51PfvKTZ73xJ7uyWAX0Qfa7A9HTPFqI2Wcqx68Q4vQkhoWYviR+hZjeJIaFmHkmPIbYbbfdRldXF/fddx/t7e2sXLmSp59+OjPAYGNjYyYDDlBeXs4zzzzD5z73OZYvX05paSmf+cxn+NKXvnTu9gJIqklKnDGWl+Wwt9nHL19v5NPXzjun7yHEdDdV41cIMT4Sw0JMXxK/QkxvEsNCzDxnNKj+XXfdNWZp6JYtW0bcd8kll/Daa6+dyVuNy9G+o9z3yn3YIjbuvOR+7v6/ffz8tQb+4coarCbj6V9AiFlkqsWvEGJiJIaFmL4kfoWY3iSGhZhZJtxlciryxXzs79nP9th2CgtaKfRY6fJHeWpv22RvmhBCCCGEEEIIIYSYYmZEQmx14Wr+bs7fAfDN7f/G+y4uBeAnL59A07TJ3DQhhBBiRtM0jZeP9bC7R5nsTRFCCCGEEGLcZkRCDOAzqz6DS3FR76sn4d6M1WTgQKuPbfV9k71pQgghxIz11/3tfOhnO/j9CQPRhDrZmyOEEEIIIcS4zJiEmMfiYYN9AwBPHH6UG1bqLdU/feXEZG6WEGKc5DpaiOnp2kUFFHqsDMQV/rC7dbI3RwhxBmLJyd4CIYQQ4sKbMQkxgGXmZVxafClxNU6X5ZeAxjMH2mnqDU32pgkhxqBpGg+/WMd9O4yc6A5O9uYIISbIajLy4cuqAPjxSydIJCW7LcR0oWka//3yCb62w0htu3+yN0cIIYS4oGZUQkxRFO5dey92k50DfbtYPL8WVYPHt9ZP9qYJIcagKAo7G/sJJhS+/8Lxyd4cIcQZuG1NKU6TRmNvmI372yd7c4QQ46QoCnubfYSSCv/+dK2MvSuEEGJWmVEJMYBSVyn/uOIfAeix/A7FGOBXbzTR6Y9M8pYJIcby2WvnAvCXfe3SQi3ENOSwmLiyWK8M++ELx+SiWohp5Is3zsOoaLx6vJfnD3dO9uYIIYQQF8yMS4gBvH/x+1mYs5BQ0k9+5dP4own+/rFtBKOJyd40IcQolpR4WJmjomnwvU21k705QogzcEWRhtNi5HC7nxdq5aJaiOmiPNvBVcV6EvvfnjpETAb1FGJaCcUS9EcneyuEmJ5mZELMZDDx9Uu+jkExELZuJyu3jv0tPj75y50ytokQU9Sby1UUBZ450MG+5oHJ3hwhxAQ5TPDedeUAPPTCcakSE2IauaFUJddpoa47yBOvNUz25gghxmlf8wBv/cFWfnbUiKrKcVfMHDs7drKjY8d5f58ZmRADWJK3hNsX3g5AdsWfsNl8bKnt4it/2C8n6UJMQUUOePvyYgC+86xUiQkxHX3o0kosJgM7Gvp440TvZG+OEGKcbCa4+zp9+IIHnztCXzA2yVskhBiPbKeZ3mCMOr/CL95omuzNEeKc6I308v9e/H98+JkP82LTi+f1vWZsQgzgrlV3UeIsoTvSTs78RzDZG/nVtiZ+8Pyxyd40IcQo7rpmDkaDwotHuthWLxfTQkwHSTXJ/a/dz87oTgrcVt61ugyAh7bIJBlCTCfvvKiURcUefJEE/7n56GRvjhBiHMqyHfy/G+YB8J1NR2nqDU3yFglxdlRN5csvfZnOcCcVngrWFq09r+83oxNiTrOTn9z4E+ZmzcUf78VV/d+YvDv47qYj/G5H82RvnhDiJJU5Dt69Rr+Y/s4zMtuVENPBX+v/yh/r/siT4Sf5U92f+Ic36Yntvx3pYn+LdH8WYqo70HOAxwOPMxDr46tvXQTAz19r4FinTHIjxHTw3rXlzHFrhGJJ7v39Pjl/FtPao/sf5ZXWV7AarXznyu/gMDvO6/vN6IQYQJm7jCc2PMHV5VeT1OLYS/4Pa8FGvvS73bx8tHuyN08IcZJPXTMPi9HA6yd6eeVYz2RvjhDiNN5S/RbeNe9daGh6pVjfs9yc6v78wy1SkS3EVKZqKl977WscSRzh9r/ejtPTwvWLC0mqGv/61KHJ3jwhxDgYDArvmZPEajLw8rFufrNduk6K6Wlnx05+sOsHANy77l7mZ88/7+854xNioFeKPXj1g3xs+ccAsOT+DXPpY3z8Fy+z6WDHJG+dEELVVIJqEICSLDu3r68A9LHEpJVLiKlNURTuWXMP6y3r0dC475X7WDhPHwfwr/vbOd4VmOQtFEKMxaAY+NZl3yLPkEdnuJM7n76T5Yv3YzbCltoutsiMsUJMCwV2+FxqHMB//csh2gcik7xFQkxMf6SfL/7tiyS1JBuqN/COee+4IO87KxJioB/wP7XqUzzwpgewGm2YXLWoJf/Fx3/3Cz702Os09AQnexOFmLWeOPwE/+X/L15pfQWAf7x6Djazgd1N/Tx/WE7GhZjqFEXhrfa3ZirFfrj/31mx6CiaBo/IWGJCTGlzsubwcffHua78OhJqgh8f+C4Llv4FlBj/+tQhmaFdiCnuz3V/pl/t585LKllRnoU/muCfnpSuk2L60DSNr7zyFTpCHVR6KrnvkvtQFOWCvPesSYil3VR9Ez9782MUOAoxWrtwVPyU12Nf5saffJtvP7OXcCw52ZsoxKySUBM82/AsQS3Ip7Z8im+98S2yHAbuuLQKgO88e0SmkRZiGkhXit224DY0NE7wKCbvdp7c1cL/vFQnF9VCTGE2xca3Lv8WX1jzBYyKkYbYy7hrfsjx/hN86+nDROJyfizEVNToa+SfX/9n/sP3H3x7xzf50lsKMRsVNh/u5I+7Wyd784QAwBfzsalhE4d7D6NqI88HHz/4OC82v4jFYOE7V34Hp9l5wbZt1iXEAJbkLuE3b/01H1z8QexGB0ZrJ+bC3/Oz5o9x+Y+/yP/tPigZdSEuEJPBxE+u/wkXWy4G4IlDT/C+je/jzSsNuKwmDrX5eHxrvcSkENOAoij80/p/yiTF7CW/Q/G8zr8+dZC3P/QKe5v7J3sThRBjUBSFO5bcwf/c8D/k2fPA0o6z6gf87OBPufI/fsevtzVKYluIKSaWjLGqYBVJkvzf0f/jky+9i4tWPY9i6ufrfz5Alz862ZsoZjF/zM/Dex7mpt/dxN1b7uZdf34XV/zqCj79/Kf5+cGfc7j3MLs7d/PgjgcB+OLaL7IwZ+EF3UbTBX23KSTXnsv/W/v/+MSKT/D7o7/nf/Y+Th8dxNzPcv+uzTywYwHritbxvpVXs7Z4OSbDrP2ohDjvrEYrb3W8lfdc8h7uf+1+Dvce5mPPf4ArLrqTv26t4Ot/Pshvdzbzuevmc83CggtWQiuEmLh0Ugzg17W/xlb8e2x5L3K0fyV/9+M6PrBmDZ+/YT5um3mSt1QIMZo1RWv4zVt/w+df/Dy7OndhLXiaEE9z/44y/mPbGj697p28d/UKORaL807TNJoDzezp2sOezj0oisL64vWsK1qH2+Ie83mRRIR93fvY3rGdxTmLubL8ygu41RfW3Oy5/PjaH/PQnx5ij3MP2zu2czD4DK65mwn3reGLT8J/v+86TMZZWQcjJkkgFuCJQ0/w+MHH8cf0GYtLnCX0R/vxxXy80PQCLzS9MOw5N1TewLsXvPuCb+usz/K4LC4+uOSD3L7odv5at4n/eON/6IofIWw4yIvdB3nxuccwYmNR9gquq76EtUVrWZSzCLNRTuTF2QvEAjxT/wybGjahoZFvz6fAUUCBo4B8Rz6FjkLy7fnkO/IxKDP/QPam0jfxu7f9ji+//GVea3uNl/sfZumqizlRezX7W+DDP9vOivIs7r5+Pm+alycn40JMUemkmMfi4YlDTxCmB2v+ZsjfzG9ay/nTj9bx5Te9h3euXCBxLM4rTdPoj/bTGepkIDrAgpwFeK3e0z6vJdDCcw3PsbdrL9+58juz7u8035HPT278CX889keeqvsrOzq2Y7Q3E6SZbxz4A9/bW8UVZZeyvnwOZZ4SihxFFLuKL2g3FzHzhOIhavtq2dO5h91du9nduZueyPAZx//38P9iVIwsz1/OpSWXcmnJpVR5q9jXtY8dHTvY0bGDfd37iKtxAN5c/eYZnRBLqzZV88lrP8nunt08vOdhtrVvw5LzGtvU11n9aCnL89bw/hXXckX5Ohxmx2RvrpjGfDEf29q20RvtxWKwYDFasBgsmI1mLEYLezr38PjBx/HFfADUeGv4xIpPcEPVDaiayqGeQ2zr2Ma29m3s7NhJKBGiwl3B1y/9+qQca2d9QizNZDBx89w3c/PcN/NGywF+tus5Xm97g4jxCEljhP19r7O/73UALAYry/KXsaZwNRcVXMTy/OW4LK5J3gMxXaiayrb2bfzx2B/Z1LCJSPL0s8BsfMdGyt3lF2DrJl++I58fXf8jHjvwGN/f+X0aIq9hqHyNMmMZfd1z2N8znzse7WF1ZR7/8KYa3jQ/H5vZONmbLWYhTdNo9jdzoPcAzf5mwokwsWSMSCJCTNXX0WSUS4ov4baFt0325l5wiqLw6Ys+zUeWfYTnm57nL8f/wqutWzHam4jbm/j6nt/zLzvzKLZXcVHxIi6rWML8nHlUeaqk0Umcka5QF882PMuezj10hDroCHXQFeoipsYyj0lfSF9eejmXl17OwpyFmQanZn8zmxo28Wz9s+zv2Z95Tm1f7QXvwjEVmA1mbp1/K7fOv5XucDdPHX+WJ/b9ibboQaLGep5rq+e5tuHPcVvclLvLuajgItYVreOiwovGlYAUs09/pJ9DvYc43HuYQ72HONRziAZfAxrDh8gwGUwszlnMioIVxJNxXmt7jXpfPbs6d7GrcxcP7X5o1NfPt+ezpnANV5bN/GTYUGuL1rK2aC3b2rdx/0sP0hDai2ppZrevmd0v/QEFIwuzl3JVxaXMy9aPuRWeCqxG62RvupiiEmqC/d37ebX1VV5tfZV93ftGHQfsZDXeGj6+4uPcUHkDRoN+rWZQDCzLX8ay/GX8/dK/J6EmONZ/jGJn8SmrPs8nSYiNYl3pEtaVLkHTNHY29vCTN7byt8bXSFiPYrI3EDOF2NGxnR0d2wFQMFDpqcBhdmA1WjNZUqvRis1ko8JTwbyseczNmku5uzzzByEurISaoCPUgaZplLhKJlRxpWoq3eFu2oPttAXbaA+20xHqwGq0Uu2tptpTTZW3atRADsaDtARaaA20cqDnAH8+/mdaAi2Zn1d7q3n7nLeTa8+lK9SVOYHvCuu3e8I9FDgKzslnMF0YFAN/v/TvWVe0ju9u/y47O3cykGzGkN2MI/tFtKSNA8F5fPLPczEnqnlT5VJuWlrC1QsL8NrlQlqcHy2BFvZ17+Ng90EO9hzkYO/BTBn4qWRZs87/xk1hDrODt9a8lbfWvJXucDd/OvYUj+/9PT2JOlRTFy3xLloat/HnRv3xBsVIjbeahTkLM8uC7AVk2bImdT/E1NQT7uG5hud4uv5pdnTsGHExnZZjy8FustMSaMlcSH9/1/fJteWyvng99b56DvYczDxeQWF14WpuqLqBIkfRhdqdKSvPnscdS2/njqW3U9vVwjde/A27O2qJaj0o5n4M5n4UYwR/zK9/P/Yc5IlDT6CgsDBnIWuL1rK6cDW59lzsJjsOkwO7yZ5ZZlsF3mzVE+7h2YZn2Vi3kd1du0d9TL49n2V5y1hZsJKVBStZnLt4RLKmJdDC1tatvNr6Kq+1vYY/5qfUVcrqwtWsKVzDmsI1lLnLZvXf1dqitfzlXb+gxdfJj7c9wzPHX8avHMRg6edQ3x4O9e3JPNagGCh2FlPtrabKU0W5u5xSVynFrmJKXaXnrPJT0zQa/Y3s7dpLti2b9cXrMRvkvH2iIokIfzz2R55reA41pGJttHJJ2SVn1PjQEmjhtdbXONR7iFgyRlJL6ouqr8OJMHu69ow43632VlPpqSSuxokn48SSMWJqjFgyhtPs5PaFt3Nj1Y2nzXuYDKZJb3CShNgpKIrC6so8VlfeTCj2Zp450M7mQx282nAQv3IUo70eo6MBg6WXel/9uF7TYrBQk1XD3Ky5FDuL8Vq9eK1esqxZmdsuswujYsRkMGEymDAqRowGIybFNKu/2E9F0zT8cT/d4W56wj10hbpoDbbS7G+mOdBMi7+F9mA7CS0B6GNWVXmqqPHWUJ1VTY23hkJHId3hbr1VOdiRSXq1B9vpDHVmnnsq+fZ8qrxVeCwe2oJttARaGIgOjHicy+zipuqbuGXuLSzPW37K32tSTc7aJOrSvKX89KafMhAdYGvrVv7W/DdebnmZvmgfZs8+zJ59ALwct/LiqxVoz1eyIHspN81dw+U1lSwq9siYCbNYLBnjpeaXONJ3hGgyOmyJJWOomkq5u5yarBrmeOdQ7a3OdCPQNI0mfxPbO7azvX072zu20xZsG/EeZoOZ+dnzmZM1B6fZidVoHbHMyZpzoXd9ysqz5/H3y+7g75fdQbOvgycP7GBL3T6O9B4laWrDYO1ANUY51n+MY/3H+EvdXzLPLXIWkW/PJ5aMEVfjmXVcjWdOqJbmLWVp7lKW5i0l25Y9iXsqRtMaaKU10IrRYMSgGDAqw9caWmYClfRtDY1IIkI4ESaUCBGKhwgnwgTiAd5oe4M32t8gqQ3OgLgifwVXlV9FmbuMQkehPgyBvSBTddgaaOXllpd5peUVXmt7jZ5IDxtPbAT0i8K1hWu5vvJ6rq28Vh9YXoywIL+Ux279HKqqsb2hj4372vjr/jY6Aj4Mpn4MtjaMjhPY3CdQTZ169U/vIR4/+Pior6egkGfPo9RVSqm7lDJXGaWuUsrcZRQ4CnCZXbgtbixGy6jPT6gJArEA/pifYCKYOb8W50YwHuSllpd4vuF5tndsp8BRwNK8pSzJXcLSvKXUeGtOeZ4aiAXY3LiZjSc28nrb68PitdxdzsKchSzOXZxpABlP3JW6SjPVi0k1iT/ml0aTMZR6Crj/2g/w9Wvez+t1PTz8yja2tm7FYG/AYO3CYOlENUZpCbTQEmjh5ZaXR7yG1+qlxFmSOQ7nOfIosOvDu+TZ88ix5WAxWjAbzJnFaDCSUBPU9tays3Mnuzp3sbNj57AusDm2HG6supG31LzltNdDAgaiA/zq8K/45eFf0hvpzdz/xstvZBofLi6+mIuLL6bSW6kX5xhtWE3WTOJxIDrAG+1v8Frra2xt20qTv2lc7+2xeLi4+GIuLbmUS0ouocRVcl72cTJIQmycHBYTf7eqjL9bVYaqXsThdj+vHOvm5WPdvH6ijrihA5QEiiEBir7kuw0UZYPZ1k1Qa6EjUk80GeVw72EO9x6e8DYoKLgsLjwWDx6LB7fFjdvixmly0hHq4NCOQ9jMNr3/rkH/UtLQiCQjg914kjEiSb0bTzgR1pd4OHM7moziMDv01za7M+/hsuhJuoSaIKklUTU1czuWjBFKhDKvlb4dT8bxWD1kWbP0xZZFtjUbj8VDQksQiocIxoOEEoNrs2Im25ZNti2bHFuOftuajdVopTfSS0+kh55wD72RXrpD3dT56/jhH39IT6SHaPL0s6iYDWYUFKLJKLV9tdT21Y778zcqRvId+RQ5iihy6ksoHuKE7wT1A/V0hbsyy8m8Vq9+cucq45qKa7im4hrsJvv43neWJsOG8lq93FR9EzdV30RSTXKg5wAvtbzEzo6d7OnaR5QwJtdRcB2ljuf44Ql46JgVElm4TfkUu0qYl1PORaXVzMku1S+SnAVSHj4DaZrGrs5d/LnuzzxT/8y4KriGKnYWU+Gu4MTACTrDncN+ZlJMLMhZwJLcJSzOXczi3MXMzZor3fvOUJmnkE9dsoFPXbKBaCLJq8d6eGpvK88drcWvNWG0tuoX1rZWDJZe2oPttAfbx3y9zlAnf2v+W+b/pa5SFuUsyiQ5FfQT7fQJt6qpxJNxElqCeDJOXIuTUBOYDCaKHEUUOgopdBbqa0chRc6iWTM8QjQZpcHXQP1APfW+ekLxEItyF7E8bzlFzqJxX7SE4iG2tW/LdLMYb+PhRC3JXcJNVTdxY9WNFLuKT/nYElcJ717wbt694N3Ek3F2d+1mW/s28ux5XFtxLbn23POyjTORwaCwrjqHddU53PfWxexs7OOpfW28fLSbo+0ribaDYvJhdNRhdNRhdjRhMccwGOOoSpS4qp+3aWiZ86exqoZAP4dzW9yZxodAPJUEiwdHPLbEWTKsynRR7iJy7blomoaqqZklFo8R02KjvNuZiyfjdIW76Ax1ZpbucDcDsQF8Ud/gOjpAIB6gxFXC/Oz5LMhewIKcBeelIjYUD9Eb6R22dAW7OBw5TORYhAJnAbn2XH2x5RJOhNnStIXNjZvZ2rp1WLfjrnAXB3oOZP5vN9lZlKN/vkMbndLrRl/jsOcvzV3KhpoN3Fh14znpAWE0GCUZNg6KonDxnDwunvNmmvuu5MmdLWw50sWuo71ohkAqOdaFzdFDtieI0dJHWOsmmND/VgeiAxzqPTTu9zMoBhSUYQlQ0ON4ce5imvxN9EZ6+d/D/8v/Hv5fyt3lvKXmLVxdfjVFziKyrFlnNX5yunFlJiTZ2oPtPH7wcX575LeEE2FA/45759x3su3QNjrtndQN1GUaH3564KcjXsOoGLEarYQT4WGV1OlhBC4quChzvW9QDMOKcuZnz2dp7tIZe00qCbEzYDAoLC7xsLjEw0ffVEM0sZr9LT72NPWzp7mf3U39NPSEaBuAtuahz1Rxu3yUFAzg8fRgs4UwmcNoSoiI6mcg2s9AdIBQIjTiywP0EwZ/zI8/5qeFlhE/f7329XOyfycPXnk2Tr6gPC+GnAe5zW7yHHnk2nIpcZVkWhjTyah8Rz6aptEaaKVuoG7Y0h3qJs+Rl7nwSV8MpRNgefa8U8426o/5MxcPvpiPEmcJpe5SSpwls+Yi6kIwGvQv7uX5ywEyfc/3dO7h5ebt7OzYjS/RjmKMgrGDAB0cDe/naAtsPClsHEY3BY5CSt2FZNmyMq3QQ9fDkrrWLJxm54w4uJ4pTdNIqIkJJYE0TSOajGaqPMJJPQEfiAQ4kTjBgZ4DOK3OTCuW1WjFbrLrCexTfNaaphGMB/HFfPRGetnStIW/1P1lWJfkAkcBl5denrmAshgtmcotVVNp8DVQN1DH8f7j9EZ6aQu2ZSrBzAYzy/KW6V0witawMn+lDER7nlhNRq5eWMDVCwtQ1RUc6wqwvb6P7Q297Gjoo6GvF6O1DYxh0EygGVE0E6VZbubmZ1GeawBrE/3JOo77DlHvq8+0dp9LLrOLImcRxc5iip3F+rHBlkdtvJacthwcVseIv7P0YjPZzujkPp6ME4wHUVEz1eNDK8cTakK/wI758EV9+GL6xUskGSHLmkWuLZccWw659lxcZheKoqBpGj2RHtoCbbQEW2gLtNEaaKXJ30S9r57WQOuYXQ/z7fksz1/OsrxlLMhawPH4cV5oeoGopje0BeNB/DE/u7t2s6tzFwl1sLraqBgpc5ehaVqmcS29To9HoqCgKArpfyhkutWlu9k5zPq62lvNDZU3UOGpOKPfp9lozoy3I86OwaCwpiqHNVU5AAyE4uxq6mNnYz+7GmvY3diPv/3kSnuVLCcsKrVSnh/H6/ZhtPQR0bpoC+lV/j2RnkzCK67GM8mc0aT/TnojvbQGW2kNtvJ80/Pj2v7v/OY7mWqXPHse+fZ8sm3Zwxp909WJoUQok0xPqINLUtMrlcbavrH4en0jGsoLHYVkWbMyXZDiyXjmdkJNZOJTQ2OMUIX04VPjlL0cnnvjudNuY6WnkmsqruGK0ivoifRwoPsA+7v3c7DnIKFEiJ2dO0/5/GpvNRuqN7ChesMZx6s4d8qyHXzq2nl86tp59AVj/O1oF1tqu9hS20lffxx/6+BjDcYoNUVxqorC5Hoj2O1BVIOPnkh3ZoiX/kj/iL+x9He62+JmVcEqLiq4iIsKL8p0gY2rcV5rfY2nTjzF843P0+Rv4pE9j/DInkcAvREy1547LB4VRSGpJtHQMsePRDJBY6CR3236HaFEiEA8QCAeIBgLggJeixeP1TNs7TA7hnXxSydwE2oCl8VFtjV7WDGH1+rFbDBnuhImtESmSyEwWBln1NfpataecE8mOd4V6qIz3ElPuAeDYsBpduIwO3CaUmuzM3NeG4wH9X1IrZt8TZnPd372fD609EPcWHUjJKGwoZANGzbQH+/n9fbXeb3tdba1b6Mn3DNsnOqkliSUCAEwN2tuppJsdeHqWX+dekYJsYceeogHHniA9vZ2VqxYwfe//33WrVt32uf96le/4r3vfS9vf/vb+cMf/nAmbz0lWU1GVldms7pysHtGXzDGnuZ+9jYPUNvh50i7n7ruIP5AFrWBLKDypNcwUJ3nZGW+k6oCJyVZNoqzrBR7zeR7zFhM+omAL+bDH/Pji/oyybH+SD/7D++nak6V3tKd6kISS8YwKAYsRot+oZk+MR9ywXnyYjVaCSVC+nvEfJkSdH/cj6Zpw07CDYoBo8GI2WDGaXZmTlbTJ6omgwlfzEd/pJ++aB/90X76I/pUq8Oek/oSsJvsxNU4fZG+zAlPX6SPvkgf0WQ0c0KfXmeZs6g/UM/1l11PsaeYXFsuNpPt9L8wBco95ZR7ys/prDNuizszSOBUN5NiON1VamHOwszA5eFEmFZ/Gztb69jeUkdtdyMtgTYCiS4MZh+KaQDFkCCU9FPv91PvPzah98uyZuGxeLCZbKNe/HqtXrKt2ZlqxyxrFjm2HJxmJyaDKVNWbjHoB0xVU+kJ9zDgH8hUQvaGe/HFfLjMrlG7VseTcfxxP4GYfuBPrzVNw2Vx4TK7cJqdmdsWo2XYQTb9+HAiTL49nzJ3GWWushEHxVgyxsGeg3q5e8cudnftpj/aj8PkyFRwZtkG9y8YDzIQHaA/leBPX5yPluRP+8kzPxn1foNiwGa0YTPZMt9RZoOZUCKUufAf7XUdJgfXV17PzXNuZk3hmnG3aPVH+qkbqKPR30iJs4Tl+cvH951ygc2k+B2NwaAwv9DN/EI3t6/XL5w6/RF2NvSxt3mAA60+DrT66A5EaQhDQ6YnazlQjtt2LXMKjeTndmFzdpDjNJLjsuCymka0ipoMJswG87B1NBnNdJ1PD8zeEezQj4nxQKY758l+8cIvTrtvJoMJm9GmjzV6UveSdBeTdFIpvaRnSjsXLAYLWdYsBmIDp62qdlvcmfExrUYr+7v3c6TvCF3hLjY3bmZz4+bBB7809uuUukq5rOQyLi25lHXF6yZt0NypZKbHMIDXYeaqBQVctUCvAEqqGsc6A6lzY/38+FCbj/6gxtYjcbYeAfAAHkyGKmrynSwo8vDmIheVuXZKsg3kuFUS6N1lo8noiJ4MQ7sEHek7wqGeQ9T21XKo9xB1/XWnPA6FEiEafA00+BrOyf6bDWZ9xvDUTOH59nz93MHq0Y/jqYtzu8lOk69J77XQW8uRviM0B5oz3z1n5aREmdVozSTIc+w5eC1eWppbcOQ56Iv2ZXphpL9zFuUs4pqKa7iu4jrmZM0Z1kB1U9VNgD6sR72vngM9BwjFQ8POidLrPHseNd6aGdOYONPiN9tp4e0rS3n7ylKSqsa+lgF2NPSxs7GPXQ19tA7AsRYrx1oGzw8tJgMLCt0sKfFwc4WXJSUe5hc6M9erCTWRWRc4CkZtDDIbzFxRdgVXlF1BKB7i+abnearuKfZ376c/qifYJhQHIzvogKYXepzLYo/JsrZoLX+/9O+5rOSyTCzFk4PnB/mO/Mx4rWmapmUmeUpP9OQwO2Q4gJNMOCH261//mrvvvptHHnmE9evX8+CDD3LjjTdSW1tLQcHYZa/19fV84Qtf4IorrjirDZ4usp2WYScCANFEkhPdQWrb/Rzp8HO8M0hdd4D67hDRhMrhdj+H20fv3pPtMFOabacsy0FZtp2y7DLKsh2syLFT6DJT1PAsG1ZuwGyePV134vE4G49uZEX+ilm132drNsSw3WRnTnYNc7JreNeSwfv9kTiH2/3sb+5nb1s7+zuaaBxoJWkYQDGGUQwRFGMExRABYwSzKYbVGkUxhojjJ6npLbPd4W66w93nZFsNikEfJ+fJsZp4L6xsa3ZmMNWOUAf7u/cP6+qQFkqECAVCE67AMRvM2E12PclltBMMBjHZ9CREujt3ulVR1VT9fVItWmOxGCx4rB4W5SzirTVv5eqKq8fdJXmoLFsWF9n0FsypajbE72gK3DZuWlrMTUsHu8N1+iMcaPVxsNXHwTYfRzv81HUF8UcS7G5IQIN+cZ2W5TAzr8DFvEI38wpczC90s6DITZ5rfF2nQ/EQ7aF22gPtmUrC9mC7Xl3V3YrD7SCmxkaMVze0QiqhJgioATh3OS5g+JAKXqtXT9gbbfRH+zMXuaFEiJgay1RuKyjkO/L1gZOdxZS4SihzlVHlraLKU0WOLWfEBWw4EeZgz0H2de1jb/dejvQeIRKMUJBdgMviwmF2ZBrG5mTN4bKSyyh3l8+YC+FzYbbGsNGgsKBIj7l3r9FnzY4mktS2+9nTPMDhNh+17X5q2/34owmOdAQ40hHgzye9TmmWnZp8JzV5LuYVulhY5CKryDVsYG6v1Tui8i+WjBFOhDEohkxXLqPBSDKe5M9P/5nVV6ymL96XqehIV71YjJbM3/XQ6kSLwZIZ69dkMGFS9LXT7KTAUUCWNWvcf/fzs+dzbeW1mf8HYgGO9h8lFA9lEudDJ+0yGYaPKZyuqhwq3V0M9Coyj8UzYvKCeDzOxo0b2XDV4PWDpmkE4gESamJc4zAaDUbmZM2ZNWNlzvT4NRoUVpZnsbI8iw9TDUD7QISdjX3sbOhjX8sAB1t9+KMJ9rUMsK9lALbpY1ApClTlOllU7GZRkYdFxR4WlXgzwxWcytDJd0BP9PREejLn213hLvoifZm/9XS3PoNiABWOHjzKJasvwWvz4rQ4M43Cmqbp1dOpxtn0OpwIZ+Ipnbg1G/VGsUAsQH+0n75I37B1ekiFTHFIKu41tMGB5dVY5raqqeTac8m35+vJ8VRiPM+ep1eCJfRGr1A8lBk+SEHRG7PNrmH7UeAooNJTeZpPcSRFUYY11ovRTTgh9r3vfY+PfvSjfOhDHwLgkUce4amnnuLRRx/lnnvuGfU5yWSS973vfdx///289NJL9Pf3n9VGT1dWk5GFRR4WFnmG3Z9UNZr7QtR1BTneFaCxN0RLX5iW/jAtfWH80QR9oTh9oTj7W3yjvrbTZOQnja9RkeukIseRWcqyHRR6rVhNM7PPr5i42RzDbpuZtVU5rK3KAWoAiCVUjnUGONrp52hHgCMdfo52BmhoDxLRYFiKWomhGENYrWGKszUKvEby3EZyXApeB3gcYDIm9MrIaD+9kd7MwbQv2kc4Hh6RXBraTSg9dl66Bddj9RCIB/SDeFR/zfTYIyaDKdOtM10Flu4OlS4Vz5SNx4NEk1GcJr1ibOjB1ma00RXqosnfRF+0L7Ps7d6b2cYcWw6rClZllgp3Raab4tD9C8QCuCwuvBbvsJZwj8WDy+zCZrIN63acORnfMPxkPKEmCCfDRBOpbpbJcKZ1K5KM4DQ7h1/4T8EqrvNlNsfvyQrcNgoW2Lh6SMNTLKHqDU+pyuzD7X6Odfpp6A3RH4qzrb6PbfV9w14nz2XJJMcWFLqZV+iiPMdBvss67OLRYXZQ462hxlsz7Pmj/R0PlVSTI5JkkURkcOyyVFV3ukXdbrTjtDhxmpyDXSrMTgyKYdjMT+kuWkbFqE/Gc5pKyHAirMdspB+P1UORo2jC49/ZTXZWF65mdeHq4ft+4+xqkDsbEsODrCYjy8uyWF6WlblP0zRaByLUtvtS8RvgRHeQuq4gA+G4fm7cH+alo8MbpUq8NhYUuZlf5GZuvouafCfVeS6yHXrX+3RV5sniahybYqPSU8lc89zzvcvj4rK4WFWwalLeW1EUqeI8hdkYv0VeGxuWFbNhmd4gpaoaTX2hVLX2YNV2lz/Kie4gJ7qDbNw3ON6n125mUbGbxcVefV3iYV6BG4tp7CEEzEZzZrzm04nH42w8vpHrKq4b9ThUzKnHlRRiQgmxWCzGjh07uPfeezP3GQwGrrvuOrZu3Trm8/75n/+ZgoICPvzhD/PSS6eoq0+JRqNEo4Ol/D6fngSKx+PE46M3q6bvH+vnU12Jx0KJx8Llc0a2xvjCcVr6I7T2h2kZiNDSF6a5P50wi9AfjhNMKOxt8bF3jIRZvstCsdeWWUqy7JRl2SnNtlGebcdtm34nstP9d342hu77RPb/QsTwdItfBZiXb2devh2WDKnojCep6w5xvCvA8a4gdd1BjncFOdFjIxJUORGEE80jX89hMVKdN5e5+S7m5TuZU+JiboGT8mw7JqNeDTb0QjgcC/O3F//G2254GzbL+BI7mqadl4qLQDxAS6CF5kAzrYFWPBYPq/JXjVrh4bQ7KbZP7CRDS2rDyrtP9Xu3K3bsZjuc7qtJm57fAWcSw3IMPj0FqMm1UZNr482L8zP3R+JJ6rqDHOsMphLgAY50BmjqC9MdiNEd6OHV48O7VNjMBsqy7JRl2ynPtlOe42BugZP5BS4K3IPJsvHsuxl9bBGX8czG6dCSGkn07l7G1L90l2sANamiJtVTvoYJEwXWAgqsqe85lbPujjlVfu8XmhyDz68Cp4mCOTlcMScnc5+mafSG4tR3BzPH5mOdevK73ReldSBC60CEF2qH95vy2k1U5zmpznVQnedkTr6TOfkuKnLsmI2GKbfvF5LsuxyDz5R+3ZrH9QsHu971BKIcag9kejwdbvdzPJXIfq2ul9fqBsfWMxkUavKcqaptF/MK9NsVOQ6Mhomd38rf8ezb9zM9Bo9lQgmx7u5ukskkhYWFw+4vLCzk8OHRZ018+eWX+clPfsLu3bvH/T7f+MY3uP/++0fc/+yzz+JwnHpA402bNo37faajvNSywgt4gUqIJKAnCj1RhZ4I9EQUuqP6ui8KcU2hKxCjKxAbM2FmN2rk2iDHqpFjHb7OtoJjCk+/MNN/56eyadMmQqFTdycb6kLE8EyLXwMwD5jnBtygVkNvFDrCCl0R6E6tuyIKvVEIxZIcaPVzoHV492ejopFvg3ybRr4dCmxa5rbH7OL558Y38O+Fkos+09r+2v3sZ/95fa+p+Hu/UCYSw3IMPnsmYCGwMBvIhmgS2sPQFlJoCym0hqArrNAfg0hc5VhXkGNdI2ewcxg1ih1Q5NAodmgU2hX6/7IJr0XvNjLbTPXf+/kix+DJ4QSWA8tTJ8WhBLSF9DhuDyl0RPQ47ospDIQT7G4aYHfTwLDXMKSOyYV2jUK7gW2/fC51G6yzrFPFdPm9nw9yDD73SoASB1xTA4kq/RjbElT0JaTfDifhSKphaugppknRKHJAiUPTFyeUOjRc46jbmAr7Pllm675P9Bg8lvOa5vD7/XzgAx/gv//7v8nLG//gbffeey9333135v8+n4/y8nJuuOEGPB7PqM+Jx+Ns2rSJ66+/ftaV7af3/c5bRpaKplvU2gcitPZHaPPplWat/RFa+sM09YXpC8UJJxWag9AcHP1M3m0zUZZlpzxnsKW8PNVqXpJlx3qKstfzRX7n+r6Hw+Hz9j5nEsOzOX5jCZWmvjB1XUGOpSrLjnUFqOsKEo6rtIehPazA8B5bWA0acwrd1OS5qM5zpFqznVTlOXBZp3A2+izNlN/7mbgQMSzH4DMXS6i0DURo7AvR3BemuS9MfU+IY50B6ntChJIKx/1w3D/8mOmwGKlKVaLU5DmYk+9ifoGLqjwHZuOFP06ebzPt9z5ecgyeHsKxJA29oVQ3rlCm0ruuO0golqQjrDdunazYa0tVkjlZUOjSu1IXuLBbZlambKb+3sdDjsGTR9M02gYiekKsI8CxVGLseFeQSFwd9Xq00G1lQZEeiwsKXSwoclOT58RiMkyrfT/XZuu+n+v4ndCVVl5eHkajkY6O4bM9dHR0UFQ0so/v8ePHqa+v5+abb87cp6p6Sb/JZKK2tpY5c0YOwmi1WrFaRw5yazabT/vLHs9jZqqx9r3IYqEoy8nKMcbiC0YTqRP+EE29ocz4DOmLgN5gDH8kwaF2P4dGGfRfUaDQbUsN9m+nLNuRWVfkOCjJsmE6jxcCs/13nkiMPZX2yS5EDM/m+DWbYaHdysKSrGH3q6pGS384M7bC0KW5L0RUVTjYFuBgW2DEaxZ6rMzJd6UWJzX5LuYUuCj22DBMsKx8qpruv/ezMZEYlmPwhWM2w1y7lblFIwehjcSTHO/Sxxs80hHgcNsA+xq66IsZCMWSHGzzc7Bt+LHSbFSoznPqY5UV6uMcLSxyU57tmBFxPFN+7xMlx+CpzWw2s8xpY1l5zrD7VVWjzRfheGeA2vYBXthxiIQ9l7ruIN2BGG0DEdoGIrx8bLAbtaJAda6ThcVuFhR6mF/oYm6Bi8pc5ynHQpoOZtrvfSLkGDw5KvMtVOZ7uH7IxFdJVaOpN0Rth59DbT4Ot/k51O6joSdEhz9Khz/K344OxqTJoDAnX+9uaRhQ8DT4WFGRQ45z5FiBM910+b2faxM9Bo9lQgkxi8XC6tWr2bx5M7fccgugB/bmzZu56667Rjx+4cKF7Nu3b9h9X/nKV/D7/fznf/4n5eXlZ77l4pxxWk2ZmX9GE4olaOkL09QXorEnRGNvmMZePXnW2BsiHE/S7ovQ7ouwvaFvxPONBoXSLLs+0H+ug8ocB+U5g0mz9ICn4vyTGJ4cBoOiV1XmOHjT/PxhPwuEo/ziD09TsWQNDX0RTnTpibK67gDdgRgdvigdvuiI8Y0cFmPqREBPkM0r0E/OK3Ic5zUBLSaPxO/UYDMbWVLiZUmJnixLDyx/3Q3X0+aPU9cVoK47SF2XPlbZ0Y4AgSGz5v2FtsxrOSxG5hfqybGFRW4WFHlYWOQmexae0M8GEsNTgyF1XlqaZeeS6iwK+g6wYcNazGYz/aGYPnZoZ5AjHf7Uxbmf7kBUj+uTBgw3GhQqcxypxion8wvcLCx2n3bQcDH9SPyeX0aDQlWek6o8JzcuGUwwBqOJTJKstt2fSZT5I/r9tR1+wMiffrYD0Cs8l5R4WFLiZVmplxXlWeS7xzebtJidJtwX5+677+aOO+5gzZo1rFu3jgcffJBgMJiZbeODH/wgpaWlfOMb38Bms7F06dJhz8/KygIYcb+YuhwWkz5NfeHIhJmmafQGY5lqsuZM9xI9WdbUFyaWUGlMJc84NtrrG4dVlKUHPK3Jd1HosUqy7ByTGJ5arCYDRQ64blHBiNadgbB+cX08NQPt8U79Qrs+1d0jM+X1EBajgZp8J3MLXMwrcKcGK50ZrdhC4ncqs5gMzE0lpodKz5p3pN1/0uyXAUKxJLub+tnd1D/sOfluq15JVuhmQZGL+anbzhnchXq2kBie2rIcFlZX5rC6cnhVWZc/ql+Mt/s42ObjeKqLVyCayCTKnjs0+HiTQWFugYtFxZ7MDHtLSz1kOSTZPZ1J/F54TquJiyqyuahicOK5dLfLw+0+9jf38/yuI/RpLhp6Q5kKz+cOdWYeX5plZ0W5l5XlWawoy2JpqVeOpyJjwn8Jt912G11dXdx33320t7ezcuVKnn766cwAg42NjRgMctE1WyiKQq7LSq7LyoryrBE/V1WNTn+Uhp5gJinW0KN3y2zqDdHpjxKKJTMt5ydzWozUZKbPHlyq8pzYZ9ZQDheMxPD04bWbWVWRzaohJwEA8aRKQ2o8o2Od+oX1sS59HIZIXM3M7sOQSpT0yfnCIjcLi/UqlEXFnmGz5YmpT+J3+lGUwWqUqxcOzmSbSKrU9wQ51ObPXGgfbvfT3Bemyx+lyx/l5WPdw16rIseRqSZbWOxhQZGbqlznhGflEpNHYnh6yndbyXdbuXze4FhQmqaf4x4fcgyubdcrWXyRROZY/OSuwdepyHGwrMzL8lIvy8q8LC314pmGM73PVhK/U4OiKJRk6eNYXzEnh8rgYTZsuJxIEg61+TnQOsCBVh/7mgc40unPDAeUru5UFKjOc7K4WK8kW1ziYXGxRyrJZqkzSo3eddddo5aGAmzZsuWUz33sscfO5C3FNGUwKBR5bRR5bayvyR3x80g8SWtqvLKmvpA+nXZqwNPG3hDBMapgAHKcZrwGIy9G9lOT79LLbHP1ZNlMHoj8XJAYnt7MxqGVKINl5emxyo516uMbHe3Uu2wd6/ATjCUHE2W7WzPPyXaYmVfoZn6hXoUyr0C/neuSk4KpSuJ3ZjAZDcwtcDO3wM3NKwbvD0YTHO0MDFaUdehx2+WPZhqWnj04OIaNNVWZlh6bLL0u8dok2T1FSQzPDIqiUOixUeixcenc4Ymy1oEIh1p9HGrzcajdx/4WXyZ+G3tDPLV3sMGqPMfOwiIPi4Y0WFVKonvKkvidutw2M+uqc1hXPVjhGYgm2Nc8wO6mfvY09bOnuZ+2gYh+vdkV5C9DYjHfbdW7WZZlsbxcX8/GMclmG8kaiEllM6crwFwjfqZ3tUzNCNSldxM70aOPr9Tlj9IbjNOLwoldrSOem+eyMrfAycIiT6rLiX6R75ZWODGDDR2rbGgliqbpibLaVELsUJteiVLXFaAvFOeNE728caJ32GvlOC0sKNSryBYWu1lc7GFugQubWUozhTifnFYTK8uzWHlS1XVvMKZXkQ2pKDvSESAcT3Kg1ceBVt+wx7utJpaUeliR6iKyvMxLaZZdkmRCnGdDq0KvW1yYub8/FGN/iy/V0NvP3uYBvUG4V182DUl028wGFhV7Mt8FK8uzqMhxSPwKMUEuq4lL5uRyyZzBwoxOf4RDbX4OtupdoA+2DlCXur58/nAnzx8e7G5ZnmNneVkWK8uyWFGexdJSDw6LpFBmEvltiilLH49Fbz0/WSCa4Fj7AE8+9wrZFQto6otQ36MnzXqCMboDUboDUV6rG36RX5plZ36hi3mF7kyFzdwCl5SrixlNUZTU7K8Orl00eHIeiSc51hngaKc+W97R1Kx5TX0heoMxttb1sLVucDB/o0FhTr5eYr6sLIuV5V4WF3tn3FT0QkxFOU4Ll87J49I5g5UoSVWjuS9Ebbs/NQC4Xll2vCuAP5rgtbreYcfBXKeF5WVeVpZns7JCP8H3OuT4J8SFkOWwcPm8vGHdLvuCsVT1tp7sPtzuo7bDTySusquxn12N/ZnH5jgtrEjF79oqPYblwlyIiStw2yhw27hyyERXoViCQ21+9jbryeo9Tf3UdQczCet0VadBgfmFbn08slSyen6hWyo6pzH5FhXTkstqYkmJh4Y8jQ1X1QwbjHwgHKe+O8jRzgC17T5qO/R1hy+a6UP+Qm3XsNcr8thS02c7qMp16us8JxU5DqmIETOWzWxkaak+hslQ4ZieKDvc7uNQmz/T5aM/FM+M9/eHVLdLo0FhfqGbFWVelqeqUBYUuTHLTJdCnHdGg0JlrpPKXCc3DJmVK5ZQOd4VYG9zP3uaB9jb3M/hNj89wRgv1HYNOwbW5DtZWZ7FqopsVpZlsaBIZscT4kLJdlpGVK8kVY36nmCmm9eupn4OtfroPSl+jQaFpSUe1lTlsLYqmzVVOeTJcAdCnBGHxcTqymxWVw6O2zsQjrO/RY/Dvc36BDgdvmhmCJJfbWsCwG3Tn7u2Koc1ldmsKM+S68dpRBJiYsbx2s16F5GTupv0h2LUtuvjKqWrYo52BOj0R2n3RWj3RXh5lFkwi702FhV7WFbqZXmZPghqgdt2YXZGiElgtxhZlvpbT9M0jQ5flENtPva3DLCneYA9zf10+fX7DrX5MicGVpOBJSUevcS8XE+SVeU6MUjrmRAXhMVkSM1u5+G2tfp9kXiSg20+9qZmtdzV1E9DTygzjsrvd7bozzUaWFDk1r8DSvVlfqEkyYS4UPRqbBdz8l3csqoUgGgiyaE2P7sb+9jZ2M+2+l7aBiKpY/EAP3n5BAAlXhuLS/QZLZek1kUeGU9QiDPhtZu5bG4elw0ZI7B9IKKPR9bcz+5GPVHmjyTYUtvFllSy2mxUWFbqZX1NLpfU5LKmKluqOacw+c2IWSPLYWF9Te6Iwf0HwnGOdQY43hmgoTdIQ48+E2Z9TxB/JJGZvndof/Iij41lZV4Wpmb4qspzUJnrJNdpkZMOMSMpyuAEGenxyTRNo90XYU/TwGCJeerEYGdjPzuHdPVwW00sLtETy8vKvCwp8VLulYFKhbhQbGbjiKnre4Mx9jT1s6uxj11N/exrGaA/FB8xmY3FZGBxsSdTCbqi3EtN3sixP4UQ54fVZMyMJXbnZfp9Lf1httf3sq2+l+31fdR2+GkdiNA6EOG5Q4PjkeU6Lawoz2JtVQ7rqrNZVpolCW4hzlCR18ZN3iJuWqpXZSeS+uzu6TjcVt9Lpz+aOQ9+eMtxzEaFFWVZejVoTS6rKrJluJEpRBJiYtbz2s0jSmRBv9jvC8U50R1gf4uPvc36IKhHOwN6RdnByLABUEG/6K/Mc1Cd52JhkT4Q+aJiD4UeqyTKxIyjKArFXjvFXnvmxEBNdfXY2zxYYr6/1Yc/muD1E728PmTwfqfFSJHVyG6llpUV2Swvy6IqVwYNFuJCyXFauHphwbAkd3NfmL3NA+xt6Wd/ywB7mwfwRxLsTlWWQQOgD12wtMSNJ2bAeaSLtTX5eO0yHpkQF0pplp3SlaW8faVeReaPxDnU5md/y0Bqoo0BjnYG6AnGhg0UbjUZWFmexeqKLLR+hTdFE2SbJXaFOBMmoyEz/MiHLqtG0zSaesO8fkIfh/e14z20DkTY3tDH9oY+vv/8MUwGhSWlXtakrj/XVGZT4JHeR5NFEmJCjEFRFHKcFnKcOayuHJy+NxhN6N1Omgc41hmgoUevKmsdCOOPJtjfok+v/ec9g6+V7TDrU2rLjH1ihjMYlMzMsemuHvGkyrHOAPtaBtifWg62+QjGkhyPKRx/tQFe1S+yPTYTy1JVKPq4RlnSRVmIC0RRBmeqfcvyYkBPktX3hPTxyFLVoPtbBwhEE7x2og8w8OzPd6EosKDQzZqqbNZU5rC2OofSLPvk7pAQs4jbZmZddQ7rqgfPWSPxJIfb/ZlKsm31ffQGY0MaqIz86N+eZ3GJR68gq8phTVUO+W4Zi0yIM6EoChW5DipyHbxrTXkmQba1rputx/UkWYcvyp6mfvY09We6O5fn2Lm4OpdrFxVw+bx8XFZJ01wo8kkLMUFOq4m1VTmsrcoZdn8knqSpN8SJ7iDHugIcavNzuM1HXXeQvlB81Bn7qvOcepKsyM381MyX5dl2TDIguZhBzMbB8YzevaYc0EvMa9v6+eVfX0bJq2J/q5+DbT58kQSvHOvhlWODsVKaZWdlRRarUgmyJSVeSSYLcYEoin6sqs5zZipREkmVo50BdtT38KdX99ORdNHQG8oMNPzEa42APp7R2mr9AntdVQ7zClwylqAQF5DNPNjV8iNX1KBpGse7gmyr7+X149387XArvVEl05j701fqAajOc3JxTQ6XzMnjkppcSZAJcYYGE2QV3La2IlOJvaOhj+0Ng92d9dksm/m/Hc2YjQoX1+RyzcICrllYQGWuc7J3Y0aThJgQ54jNbGReoZt5hW5uGHJ/JK7P2HcwNfD44TZ/Zsa+Y6kB/odWk5mNClW5TuYW6AOqzi1wcc2iAjw2KWcXM4fJaGB+oZt1BRobNizCbDYTT6rUtvvZ1zLA7ka9e9aRTn9mdtj0lNcWo4FlZd5MV+fVldkys5YQF5ApleSem2fH3bmXDRsupy+SZGdDH9vq+9he38v+Vh+tAxH+uLuVP6ZmpU0PUbCqPIuVFfrkN3JsE+LCURSFuQX6ueWtq4rZuLGJVZddw+4WP9tO6FVktR1+TnQHOdEd5H/f0CfLmVfgyox/dOmcPLwOiVshzsTQSux0Twp/JM7Oxn7+dqSLzYc6qO8J8dLRbl462s39fz5ITZ5TP3ZWZLOqIov5hW6M0rh0zkhCTIjzzGY2ZvqWp2Vm7GtPJcjafBzrDFDXHSAS11vej3YGMo9/5Z5r5KJBzHjmIeMwvHddBaCfJOxrHmBXUz+7GvvZ3dRHdyDGjoY+djT0ZZ5bletgdWUOF1Vmsboym3kFcrIgxIVU4LZx09Jiblqqd7UMxRLsSs2Gt62+l50N/QyE48PGMlIUmJPvSlV/ZnPpnFwqZRxBIS6oYq+Nijw3b1tRAsBAKM72hl62Hu/h1eM9HGr3Zc5LH9/agEGBVRXZXDk/nyvn57Os1CuVn0KcBbfNnImnr751MXVdAZ4/3MnmQ51sq++lrjtIXXeQ/9vRDIDDYmR5mZcVpV6UfoWrYgm8Mg7gGZOEmBCTYNiMfQsKMverqkbrQJjj/5+9+w6Tqjz/P/4+07d3ttN7F5BqB8UuGqPRqOgv0cRoYiQm0XxVUowaW7Bj19hLYseCINhApAvS2y7be9+ddn5/nGVhBZSFhd2d+byu61yze+bMzHPPzr1nzn2e8zwlddbMlyW15JbXk66BFiVMxXicTOybzMTmKa9N0ySnvJ6l263BSZftKGdjUS3by+rZXlbPf5dbXxZi3A5Gdo9nVPPZtGGZcSSpF5nIERPpcrSart4XCPJdfjXLcyqai9uV5JTXt/SU3vVFPyshgmP6JnNMv2Qm9kkmMUqz0YocSXGRTiYPSmXyoFQAKuu9LN5azqItpXy5pYzNxbUtJ6Xum7uRhEgnx/ZLYWKfJEZ2j9cJKZFDtGss3l8e25uqBh/fbCtnZW4lK3IrWJXbPIbn1nIWb7XGAXzq9k8Z1T2hZZ87IitOw++0gQpiIp2IzWaQlRBJVkIkx/dP6ejmiHQ6hmHQIymKHklR/GR0FmCdzV6eU8HyHOsL+srcSmqa/C3dzXfJjI9gaGYsw7PiGZoZx7DMOB1sixwhTruNEdnWZZJXTLLWldZaAwuvyKlkyfZyVuRUsLOigVe+yeWVb6xLtYZkxDK2VyKjeyQwqnsCGRqoX+SIio90cerQtJbZpPMqG/hsYwkLN5Tw5eZSKup9vLMqn3dWWZdGR7rsDMuM22PszwRSdWJX5KDERTiZMjiVKYOtAnUgaLKlpJYVORUs2VbG/DV5VHhpmSjjvrkbiXY7GNcrkUnNJ5f6dYtWz+sfoIKYiIh0aXGRTk4c2I0TB1q9Lf2BIBuKalieU8my7eWs3lnF1tK6lrHIPlpb1PLYvt2iGd87kfG9kxjXSwMHixxJydHuVj1R6pr8LNlezpebSvlicynrC2tYm1/N2vzdg32nx3kY1T2BUc1T1Q/JiNWZcJEjKDM+govGdueisd3xBYKszK1k4YYSlu2oYPXOSuq8gT1msbRkJUQwujlnR/dIZECaepGJHAy7zaB/qjUZ23kj03nflcPQ8SeweHslX20p5astZVTW+5i3vph5zcMTpMS4mdQnqaUHmU4staaCmIiIhBSH3caQjDiGZMRx6fgeAFQ3+libV82avCq+zatiTZ5VJNt1udauWfH6pEQxvncSY3pavVG6J2o8I5EjJcrt4MQB3VqGEiiuaWTRljKW76hgWU4F6wpqKKhq5P1vC3j/W2uSjSiXndE9ExnXy1qGZ8XjcqhAJnIkOO22VjOvB4Imm4trWZlr9dZekVPJxqIadlY0sLOioWWCjV3DGkzsk8yx/ZIZnB6rcchEDoJhQI+kSPqmxXHJ+B4EgyZr86v5ckspX24uZcm2ckpqmnhrZT5vNedf75Qoa2iCvsmM75MU9uNUqyAmIiIhL9bjtGbI6pPUsq6izsuS7eV8vbWcxVutgYO3lNSxpaSOF7+2CmRJUS6O6h7fMrPPiKx4otzadYocCd1iPJwzMpNzRlozcdU1+Vm10zrIXrq9nKU7Kqhp9PPZxhI+21gCgMdpaxlLZWKfJIZlaiwVkSPFbjMYkBbDgLQYLjx69+Q4K3MrW8YdW5HTeliDf31o7Wsn9k3m2OZLvNSDReTg2GwGw7LiGJYVx6+P70OjL8DynAq+3FzKF5vL+HZnJVtL6thaUsd/Fu3AbjMYkRXHMc3j9R7VPR63w97RYRxR+lYvIiJhKSHKxdQhaUwdYo2LUlnvZUnzZR7LcypYm1dNWZ2XT9YV88m63bPi9U2JZnhWPCOyrXHIBqXH4nGG15cHkY4Q5XYwsY812D5YvVHWF1Zbebu1nCXbyymv8/JV8+x4ADEeBxN677pUJIk+KRpLReRIivFYg+4f288aGzcQNNlQWMOSbWV8sbmURVvKKKvz8u6qfN5tHoesT0pU82OSGd87SSeiRA6Sx2lv2W/+cao17u6irWXNBbJStpXWsTynkuU5lTwwfzNuh9Xrc0KfpLA5qaT/LiIiIlgDB58yJI1TmgtkTf4Aa/OrWd58Rnt5TgUFVY0t08/vmtHSYTMYlB7LuF7WF4ixvRKJCfPu5yJHgt1mtFwefcWkXpimdbnW4q3WgfZXW8qoafTz8XdFfPydNXZgUpSL0T0SOLpnImN6JjAkI06XWIocQXabweCMWAZnxHL5pF74AkFW5FTyxaYSPttUyuqdlS29tZ/9ajtOu8FR3RM4rl8yx/RLYajGDRQ5aHGRzlaTZOysqOerzWV83lycLq1t4ovmYhlAtNvB+N5JHN8/meP6p9AjKaojm39YqCAmIiKyD26H3Rq8u3tCy7rimkZW51axOq+K1TsrWb2zivI6L982j0325BfbsBkwLDOO8X2SmNA7iaN7JurstsgRYBgG/VJj6Jcaw6UTehIImqzJq2oujpXyzfYKyuq8rQpkboeNkdnxzQVt63IR9fgUOXKcdhtjeyUytlciM04Z0NyDpZTPNpXy+aYScssbWLKtnCXbyrnn443EeByM65XEpL5JTOyTTP9U9foUOVhZCZFccHQkFxyd3XJSyeplbRXIqhv9fLKuiE/WWfvM7omRHNc/meP6pTChT1JInADWN3QREZED1C3Gw5TBnpbpr03TJK+ygWU7Kli0pYxFW8vYUVbPqp1VrNpZxWMLt3LigBSeuWJsB7dcJPzYbQYjsuMZkR3PNSf2pckfYE1eFd9sr2Dp9gqW7iinst7XMiPerstFRvdIYGLzmIPDs+JxqjeKyBFj9WBJ59Sh6QDsKKuzimMbS1i01er1uecBenK0i4l9kjlxYAon9O9GQpSrI5sv0mXteVJp+kTrpNLa/Co+31TKwo0lLN9RQU55PS8szuGFxTk4bAZHdY9vubx5eFZ8l5w9VgUxERGRg2QYBlkJkWQlRLYM/J1f2cDirWUtBbLxvZN+5FlE5EhwO+yM7pHI6B6JcDwEgyZbS2tZsq2CxVutccdKa5tajUEW6bLzylXjGZ4V37GNFwlTPZKiuDQpikvH92jp9bmrB8s328sprfXyzqp83lmVj82AUd0TOGlQNyYPTFXvMZFDYLcZDM+KZ3iWdVKptsnPoi1l1kQ2m0rYUVbPN9sr+GZ7BffN3Uisx8Gk5okxJvROoldyVJfIPxXERERE2lFGfATnjcrivFFZAPgDwQ5ukYjsi81m0LdbDH27xXDxuO6YpsmWkloWNRfEFjf3RumTEt3RTRURWvf6vPqEPjT5A6zMqWThxhLmry9mfWENS3dUsHRHBXd9uIHM+AjOH53F9Sf37+imi3R50W4HJw9O5eTmqyRyyur5fHMJX2wq5cvNpVQ3+vlgTSEfrCkEoFuMm/G9k5qXxE5bIFNBTERE5DDS4L8iXYNh7C6QXTqhJ8GgyY7yeo0BKNJJuR12xvVOYlzvJP506kDyKhuYv76Y+euK+GpLGXmVDRTXNHZ0M0VCUvekSH6e1IOfj+uBPxDk2zzr8sovN5eyIreS4pqmlt6bYBXIJg/qxmlD05nQJ6nTDEegPbyIiIiIyPfYbAa9kkNvRi2RUJUZH8Gl43tw6fgeNHgDfLWllLQ4T0c3SyTkOew2juqewFHdE/jd5H40+gKszK1k8Vart/XyHKtA9vKSXF5ekktchJOTB6dy2tA0jumXjNvRcZPZHFRZ7uGHH6Znz554PB7GjRvHkiVL9rvtE088wbHHHktCQgIJCQlMmTLlB7cXkcNPOSzSdSl/Rbo25bDI4RfhsjN5UCpDMuLa9XmVvyI/zuO0M753Er+f0p9XrprA6pmn8PwvxnLxuO4kR7uoavDxxrKd/OK5pYz5xydc8cwS7vxgPW+tyGN9YTVe/5EbbqTNBbFXX32VGTNmMHPmTJYvX86IESOYOnUqxcXF+9x+wYIFXHTRRXz66acsWrSI7OxsTjnlFPLy8g658SLSdsphka5L+SvStSmHRbou5a/IwfE47RzbL4Xbzx3G13+ZwitXjefyiT1JjXVT0+Tn0w0lzF64hd+/upJTZ33O4Fs/ZOq/P+N3L69ga0ntYW1bmwti9913H1deeSVXXHEFgwcPZvbs2URGRvL000/vc/sXX3yR3/zmN4wcOZKBAwfy5JNPEgwGmTdv3iE3XkTaTjks0nUpf0W6NuWwSNel/BU5dHabwfjeSfz17CEsunEyb10ziX9MG8rPx3VnTI8EYtwO/EGTDUU1zbPHHt6B+Ns0hpjX62XZsmXcdNNNLetsNhtTpkxh0aJFB/Qc9fX1+Hw+EhMT29ZSETlkymGRrkv5K9K1KYdFui7lr0j7s9kMRmbHMzI7vmWdaZrkVzWyobCaDYW1dE+MPKxtaFNBrLS0lEAgQGpqaqv1qamprF+//oCe489//jMZGRlMmTJlv9s0NTXR1NTU8nt1dTUAPp8Pn8+3z8fsWr+/+0NZuMYernFD69jbEv+RyGHlb9sodsV+oPFrH9w5Kfbwi1374NCh2BW79sFdm2IPzdi7RTno1ieRY/skEgj4CQR233ew++D9OaKzTN5555288sorLFiwAI9n/zN+3HHHHfztb3/ba/3HH39MZOQPVwjnzp17yO3sqsI19nCNG6zY6+vrj9jrHUgOK38PjmIPT0cyh7UPPrwUe/jRPjh0KPbwpH1w6FDs4ae98rdNBbHk5GTsdjtFRUWt1hcVFZGWlvaDj73nnnu48847+eSTTxg+fPgPbnvTTTcxY8aMlt+rq6tbBiGMjY3d52N8Ph9z587l5JNPxul0HmBEoSFcYw/XuKF17A0NDQf8uCORw8rftlHsiv1Ac1j74M5JsYdf7NoHhw7Frti1D+7aFHv4xX6w++D9aVNBzOVyMXr0aObNm8e0adMAWgYGvPbaa/f7uLvuuot//vOffPTRR4wZM+ZHX8ftduN2u/da73Q6f/SPfSDbhKpwjT1c4wYrdr/ff8DbH4kcVv4eHMUevrEfaA5rH9y5Kfbwi1374NCh2MM3du2DQ4NiD7/Y27oP3p82XzI5Y8YMpk+fzpgxYxg7diyzZs2irq6OK664AoDLLruMzMxM7rjjDgD+9a9/ceutt/LSSy/Rs2dPCgsLAYiOjiY6OvqQAxCRtlEOi3Rdyl+Rrk05LNJ1KX9FQk+bC2IXXnghJSUl3HrrrRQWFjJy5Eg+/PDDlgEGc3JysNlsLds/+uijeL1ezj///FbPM3PmTP76178eWutFpM2UwyJdl/JXpGtTDot0XcpfkdBzUIPqX3vttfvtGrpgwYJWv2/fvv1gXkJEDiPlsEjXpfwV6dqUwyJdl/JXJLTYfnwTERERERERERGR0KGCmIiIiIiIiIiIhBUVxEREREREREREJKyoICYiIiIiIiIiImFFBTEREREREREREQkrKoiJiIiIiIiIiEhYUUFMRERERERERETCigpiIiIiIiIiIiISVlQQExERERERERGRsKKCmIiIiIiIiIiIhBUVxEREREREREREJKyoICYiIiIiIiIiImFFBTEREREREREREQkrKoiJiIiIiIiIiEhYUUFMRERERERERETCigpiIiIiIiIiIiISVlQQExERERERERGRsKKCmIiIiIiIiIiIhBUVxEREREREREREJKyoICYiIiIiIiIiImFFBTEREREREREREQkrKoiJiIiIiIiIiEhYUUFMRERERERERETCigpiIiIiIiIiIiISVg6qIPbwww/Ts2dPPB4P48aNY8mSJT+4/euvv87AgQPxeDwMGzaMOXPmHFRjRaR9KIdFui7lr0jXphwW6bqUvyKhpc0FsVdffZUZM2Ywc+ZMli9fzogRI5g6dSrFxcX73P6rr77ioosu4he/+AUrVqxg2rRpTJs2jTVr1hxy40Wk7ZTDIl2X8leka1MOi3Rdyl+R0NPmgth9993HlVdeyRVXXMHgwYOZPXs2kZGRPP300/vc/v777+fUU0/lj3/8I4MGDeIf//gHo0aN4qGHHjrkxotI2ymHRbou5a9I16YcFum6lL8ioadNBTGv18uyZcuYMmXK7iew2ZgyZQqLFi3a52MWLVrUanuAqVOn7nd7ETl8lMMiXZfyV6RrUw6LdF3KX5HQ5GjLxqWlpQQCAVJTU1utT01NZf369ft8TGFh4T63Lyws3O/rNDU10dTU1PJ7VVUVAOXl5fh8vn0+xufzUV9fT1lZGU6n84DiCRXhGnu4xg2tY29sbATANM0ffdyRyGHlb9sodsV+oDmsfXDnpNjDL3btg0OHYlfs2gd3bYo9/GI/2H3w/rSpIHak3HHHHfztb3/ba32vXr06oDUiXUNNTQ1xcXEd3Qzlr8hBUg6LdF3KX5GuTTks0nUdSv62qSCWnJyM3W6nqKio1fqioiLS0tL2+Zi0tLQ2bQ9w0003MWPGjJbfg8Eg5eXlJCUlYRjGPh9TXV1NdnY2ubm5xMbGHmhIISFcYw/XuKF17DExMdTU1JCRkfGjjzsSOaz8bRvFrtgPNIe1D+6cFHv4xa59cOhQ7Ipd++CuTbGHX+wHuw/enzYVxFwuF6NHj2bevHlMmzYNsJJ03rx5XHvttft8zIQJE5g3bx6///3vW9bNnTuXCRMm7Pd13G43bre71br4+PgDamNsbGxYfSD2FK6xh2vcsDv2A62IH4kcVv4eHMUe3rEfSA5rH9y5Kfbwi1374NCh2MM7du2Duz7FHn6xt3UfvD9tvmRyxowZTJ8+nTFjxjB27FhmzZpFXV0dV1xxBQCXXXYZmZmZ3HHHHQBcd911HH/88dx7772cccYZvPLKKyxdupTHH3/8kBouIgdHOSzSdSl/Rbo25bBI16X8FQk9bS6IXXjhhZSUlHDrrbdSWFjIyJEj+fDDD1sGDMzJycFm2z155cSJE3nppZe4+eab+ctf/kK/fv146623GDp0aPtFISIHTDks0nUpf0W6NuWwSNel/BUJQWaIaGxsNGfOnGk2NjZ2dFOOuHCNPVzjNs3Qiz3U4mkLxa7YQ0GoxdMWij38Yg+1uEMtnrZQ7Io9FIRaPG2h2MMv9vaO2zDNQ5ijUkREREREREREpIux/fgmIiIiIiIiIiIioUMFMRERERERERERCSsqiImIiIiIiIiISFgJiYLYww8/TM+ePfF4PIwbN44lS5Z0dJPa3WeffcZZZ51FRkYGhmHw1ltvtbrfNE1uvfVW0tPTiYiIYMqUKWzatKljGtvO7rjjDo4++mhiYmLo1q0b06ZNY8OGDa22aWxs5JprriEpKYno6Gh+8pOfUFRU1EEtbj+PPvoow4cPJzY2ltjYWCZMmMAHH3zQcn+oxK0cDt0cVv4qf0NBuOYvKIeVw6EhXHNY+av8DQXhmr+gHD4SOdzlC2KvvvoqM2bMYObMmSxfvpwRI0YwdepUiouLO7pp7aquro4RI0bw8MMP7/P+u+66iwceeIDZs2fz9ddfExUVxdSpU2lsbDzCLW1/Cxcu5JprrmHx4sXMnTsXn8/HKaecQl1dXcs2119/Pe+++y6vv/46CxcuJD8/n/POO68DW90+srKyuPPOO1m2bBlLly7lpJNO4pxzzmHt2rVAaMStHLaEag4rf5W/oSBc8xeUw8rh0BCuOaz8Vf6GgnDNX1AOH5Ecbpe5KjvQ2LFjzWuuuabl90AgYGZkZJh33HFHB7bq8ALMN998s+X3YDBopqWlmXfffXfLusrKStPtdpsvv/xyB7Tw8CouLjYBc+HChaZpWrE6nU7z9ddfb9lm3bp1JmAuWrSoo5p52CQkJJhPPvlkyMStHA6vHFb+Kn+7unDOX9NUDiuHu75wzmHlr/K3qwvn/DVN5fDhyOEu3UPM6/WybNkypkyZ0rLOZrMxZcoUFi1a1IEtO7K2bdtGYWFhq/chLi6OcePGheT7UFVVBUBiYiIAy5Ytw+fztYp/4MCBdO/ePaTiDwQCvPLKK9TV1TFhwoSQiFs5bAmnHFb+Kn9DTTjlLyiHlcOhJ5xyWPmr/A014ZS/oBw+HDnsaO/GHkmlpaUEAgFSU1NbrU9NTWX9+vUd1Kojr7CwEGCf78Ou+0JFMBjk97//PZMmTWLo0KGAFb/L5SI+Pr7VtqES/7fffsuECRNobGwkOjqaN998k8GDB7Ny5couH7dy2BIuOaz8Vf6GonDJX1AOK4dDU7jksPJX+RuKwiV/QTl8uHK4SxfEJPxcc801rFmzhi+++KKjm3LEDBgwgJUrV1JVVcUbb7zB9OnTWbhwYUc3S6TNlL/KX+nalMPKYem6lL/KX+nalMOHJ4e79CWTycnJ2O32vWYTKCoqIi0trYNadeTtijXU34drr72W9957j08//ZSsrKyW9WlpaXi9XiorK1ttHyrxu1wu+vbty+jRo7njjjsYMWIE999/f0jErRy2hEMOK3+Vv6EqHPIXlMPK4dAVDjms/FX+hqpwyF9QDh/OHO7SBTGXy8Xo0aOZN29ey7pgMMi8efOYMGFCB7bsyOrVqxdpaWmt3ofq6mq+/vrrkHgfTNPk2muv5c0332T+/Pn06tWr1f2jR4/G6XS2in/Dhg3k5OSERPzfFwwGaWpqCom4lcOWUM5h5W9ryt/QE8r5C8rh71MOh55QzmHlb2vK39ATyvkLyuHvOyw53I6D/neIV155xXS73eazzz5rfvfdd+ZVV11lxsfHm4WFhR3dtHZVU1NjrlixwlyxYoUJmPfdd5+5YsUKc8eOHaZpmuadd95pxsfHm2+//ba5evVq85xzzjF79eplNjQ0dHDLD93VV19txsXFmQsWLDALCgpalvr6+pZtfv3rX5vdu3c358+fby5dutScMGGCOWHChA5sdfu48cYbzYULF5rbtm0zV69ebd54442mYRjmxx9/bJpmaMStHA7tHFb+Kn9DQbjmr2kqh5XDoSFcc1j5q/wNBeGav6apHD4SOdzlC2KmaZoPPvig2b17d9Plcpljx441Fy9e3NFNaneffvqpCey1TJ8+3TRNa8rZW265xUxNTTXdbrc5efJkc8OGDR3b6Hayr7gB85lnnmnZpqGhwfzNb35jJiQkmJGRkea5555rFhQUdFyj28n/+3//z+zRo4fpcrnMlJQUc/LkyS3/BEwzdOJWDoduDit/lb+hIFzz1zSVw8rh0BCuOaz8Vf6GgnDNX9NUDh+JHDZM0zTb1qdMRERERERERESk6+rSY4iJiIiIiIiIiIi0lQpiIiIiIiIiIiISVlQQExERERERERGRsKKCmIiIiIiIiIiIhBUVxEREREREREREJKyoICYiIiIiIiIiImFFBTEREREREREREQkrKoiJiIiIiIiIiEhYUUFMRERERERERETCigpiIiIiIiIiIiISVlQQExERERERERGRsKKCmIiIiIiIiIiIhBUVxEREREREREREJKyoICYiIiIiIiIiImFFBTEREREREREREQkrKoiJiIiIiIiIiEhYUUFMRERERERERETCigpiIiIiIiIiIiISVlQQExERERERERGRsKKCmIiIiIiIiIiIhBUVxEREREREREREJKyoICYiIiIiIiIiImFFBTEREREREREREQkrKoiJiIiIiIiIiEhYUUFMRERERERERETCigpiIiIiIiIiIiISVlQQExERERERERGRsKKCmIiIiIiIiIiIhBUVxEREREREREREJKyoICYiIiIiIiIiImFFBTEREREREREREQkrKoiJiIiIiIiIiEhYUUFMRERERERERETCigpiIiIiIiIiIiISVlQQExERERERERGRsKKCmIiIiIiIiIiIhBUVxEREREREREREJKyoICYiIiIiIiIiImFFBTEREREREREREQkrKoiJiIiIiIiIiEhYUUFMRERERERERETCigpiIiIiIiIiIiISVlQQExERERERERGRsKKCmBy07du3YxgGzz77bJsfu2DBAgzDYMGCBe3eLhE5MMphka5L+SvStSmHRboG5WpoU0FMOp1XX32VCRMmEBUVRXx8PBMnTmT+/Pkd3SwR+RE9e/bEMIx9Lv369evo5onIj/jkk0848cQTSU5OJj4+nrFjx/L88893dLNE5AC98sorjBo1Co/HQ0pKCr/4xS8oLS3t6GaJyB42bNjA9ddfz8SJE/F4PBiGwfbt2/e7/TvvvNOS1927d2fmzJn4/f4j1+AQ5+joBojs6a9//St///vfOf/887n88svx+XysWbOGvLy8jm6aiPyIWbNmUVtb22rdjh07uPnmmznllFM6qFUiciDeeecdpk2bxoQJE/jrX/+KYRi89tprXHbZZZSWlnL99dd3dBNF5Ac8+uij/OY3v2Hy5Mncd9997Ny5k/vvv5+lS5fy9ddf4/F4OrqJIgIsWrSIBx54gMGDBzNo0CBWrly5320/+OADpk2bxgknnMCDDz7It99+y2233UZxcTGPPvrokWt0CFNBTDqNxYsX8/e//517771XX7xFuqBp06btte62224D4Oc///kRbo2ItMVDDz1Eeno68+fPx+12A/CrX/2KgQMH8uyzz2q/LNKJeb1e/vKXv3Dccccxd+5cDMMAYOLEiZx11lk88cQT/Pa3v+3gVooIwNlnn01lZSUxMTHcc889P1gQu+GGGxg+fDgff/wxDodVuomNjeX222/nuuuuY+DAgUeo1aFLl0x2cbvO4m7cuJFLLrmEuLg4UlJSuOWWWzBNk9zcXM455xxiY2NJS0vj3nvvbfX44uJifvGLX5CamorH42HEiBE899xze71OZWUll19+OXFxccTHxzN9+nQqKyv32ab169dz/vnnk5iYiMfjYcyYMbzzzjs/GsusWbNIS0vjuuuuwzTNvXqaiISiUMrhfXnppZfo1asXEydOPKjHi3RmoZS/1dXVJCQktBTDABwOB8nJyURERLTtjRHpIkIlh9esWUNlZSUXXnhhSzEM4MwzzyQ6OppXXnml7W+OSCcSKrkKkJiYSExMzI9u99133/Hdd99x1VVXtRTDAH7zm99gmiZvvPHGjz6H/DgVxELEhRdeSDAY5M4772TcuHHcdtttzJo1i5NPPpnMzEz+9a9/0bdvX2644QY+++wzABoaGjjhhBN4/vnn+fnPf87dd99NXFwcl19+Offff3/Lc5umyTnnnMPzzz/PJZdcwm233cbOnTuZPn36Xu1Yu3Yt48ePZ926ddx4443ce++9REVFMW3aNN58880fjGHevHkcffTRPPDAA6SkpBATE0N6ejoPPfRQ+75ZIp1QKOTw961YsYJ169Zx8cUXH9qbI9LJhUL+nnDCCaxdu5ZbbrmFzZs3s2XLFv7xj3+wdOlS/vSnP7XvGybSyXT1HG5qagLYZ/E6IiKCFStWEAwGD/VtEulwXT1X22LFihUAjBkzptX6jIwMsrKyWu6XQ2RKlzZz5kwTMK+66qqWdX6/38zKyjINwzDvvPPOlvUVFRVmRESEOX36dNM0TXPWrFkmYL7wwgst23i9XnPChAlmdHS0WV1dbZqmab711lsmYN51112tXuPYY481AfOZZ55pWT958mRz2LBhZmNjY8u6YDBoTpw40ezXr1/Luk8//dQEzE8//dQ0TdMsLy83ATMpKcmMjo427777bvPVV181Tz31VBMwZ8+e3S7vl0hnEyo5vC9/+MMfTMD87rvv2vy+iHQFoZS/tbW15gUXXGAahmECJmBGRkaab7311iG/TyKdVajkcElJiWkYhvmLX/yiVXzr169vyefS0tKDf6NEOlio5Or33X333SZgbtu2bb/35eTk7HXf0UcfbY4fP37fb5a0iXqIhYhf/vKXLT/b7XbGjBmDaZr84he/aFkfHx/PgAED2Lp1KwBz5swhLS2Niy66qGUbp9PJ7373O2pra1m4cGHLdg6Hg6uvvrrVa3x/LILy8nLmz5/PBRdcQE1NDaWlpZSWllJWVsbUqVPZtGnTfgfH33V5ZFlZGU8++SQ33HADF1xwAe+//z6DBw9uGYdIJFR19Rz+vmAwyCuvvMJRRx3FoEGD2v6GiHQhoZC/breb/v37c/755/Pyyy/zwgsvMGbMGC655BIWL158aG+QSCfX1XM4OTmZCy64gOeee457772XrVu38vnnn3PhhRfidDoBq5eMSFfX1XO1LXbl7J5DGezi8XiU0+1Eg+qHiO7du7f6PS4uDo/HQ3Jy8l7ry8rKAGv2t379+mGzta6L7jp43bFjR8tteno60dHRrbYbMGBAq983b96MaZrccsst3HLLLftsZ3FxMZmZmXut39XF2+l0cv7557est9lsXHjhhcycOZOcnJy94hQJFV09h79v4cKF5OXlaSBuCQuhkL/XXnstixcvZvny5S1tuuCCCxgyZAjXXXcdX3/99X7jF+nqQiGHH3vsMRoaGrjhhhu44YYbALjkkkvo06cP//vf//Z6fZGuKBRy9UDtOj7edUn0nhobGzW+ZztRQSxE2O32A1oH1vXRh8OusQluuOEGpk6dus9t+vbtu8/1uwYjjI+P36vd3bp1A6CiokIFMQlZXT2Hv+/FF1/EZrO1OhsnEqq6ev56vV6eeuop/vSnP7U6YHA6nZx22mk89NBDeL1eXC5X+zdcpBPo6jkMVgHg7bffJicnh+3bt9OjRw969OjBxIkTSUlJIT4+/nA0W+SICoVcPVDp6ekAFBQUkJ2d3eq+goICxo4de8ivISqIhbUePXqwevVqgsFgqy/A69evb7l/1+28efOora1tVTHfsGFDq+fr3bs3YH2BnjJlSpvaYrPZGDlyJN98881eX7rz8/MBSElJadNzioS6zpTDe2pqauK///0vJ5xwAhkZGQf9PCKhrDPlb1lZGX6/n0AgsNd9Pp+PYDC4z/tEwllnyuE9de/eveUEcmVlJcuWLeMnP/nJQT+fSFfXWXP1x4wcORKApUuXtip+5efns3PnTq666qrD9trhRGOIhbHTTz+dwsJCXn311ZZ1fr+fBx98kOjoaI4//viW7fx+P48++mjLdoFAgAcffLDV83Xr1o0TTjiBxx57jIKCgr1er6Sk5Afbc+GFFxIIBFpNgdvY2MiLL77I4MGDdWAt8j2dLYd3mTNnDpWVlfz85z8/mLBEwkJnyt9u3boRHx/Pm2++idfrbVlfW1vLu+++y8CBA3Vphsj3dKYc3p+bbroJv9+v4QskrHWFXN2XIUOGMHDgQB5//PFWJ6UeffRRDMNoNcyQHDz1EAtjV111FY899hiXX345y5Yto2fPnrzxxht8+eWXzJo1i5iYGADOOussJk2axI033sj27dsZPHgw//vf/6iqqtrrOR9++GGOOeYYhg0bxpVXXknv3r0pKipi0aJF7Ny5k1WrVu23Pb/61a948sknueaaa9i4cSPdu3fn+eefZ8eOHbz77ruH7X0Q6ao6Ww7v8uKLL+J2u3VGWuQHdKb8tdvt3HDDDdx8882MHz+eyy67jEAgwFNPPcXOnTt54YUXDut7IdIVdaYcBrjzzjtZs2YN48aNw+Fw8NZbb/Hxxx9z2223cfTRRx+290Gks+tsuVpVVdVSZPvyyy8BeOihh4iPjyc+Pp5rr722Zdu7776bs88+m1NOOYWf/exnrFmzhoceeohf/vKXmrSqvXTAzJbSjnZNQVtSUtJq/fTp082oqKi9tj/++OPNIUOGtPxeVFRkXnHFFWZycrLpcrnMYcOGtZpSdpeysjLz0ksvNWNjY824uDjz0ksvNVesWLHXFLSmaZpbtmwxL7vsMjMtLc10Op1mZmameeaZZ5pvvPFGyzb7m4K2qKjInD59upmYmGi63W5z3Lhx5ocfftj2N0akiwi1HK6qqjI9Ho953nnntf3NEOliQi1/X3zxRXPs2LFmfHy8GRERYY4bN67V40RCTSjl8HvvvWeOHTvWjImJMSMjI83x48ebr7322sG9MSKdTCjl6rZt20xgn0uPHj32atObb75pjhw50nS73WZWVpZ58803m16v98DeOPlRhmkeptHmREREREREREREOiGNISYiIiIiIiIiImFFBTEREREREREREQkrKoiJiIiIiIiIiEhYaXNB7LPPPuOss84iIyMDwzB46623fvQxCxYsYNSoUbjdbvr27cuzzz57EE0VkUOl/BXp2pTDIl2X8leka1MOi4SeNhfE6urqGDFiBA8//PABbb9t2zbOOOMMTjzxRFauXMnvf/97fvnLX/LRRx+1ubEicmiUvyJdm3JYpOtS/op0bcphkdBzSLNMGobBm2++ybRp0/a7zZ///Gfef/991qxZ07LuZz/7GZWVlXz44YcH+9IicoiUvyJdm3JYpOtS/op0bcphkdDgONwvsGjRIqZMmdJq3dSpU/n973+/38c0NTXR1NTU8nswGKS8vJykpCQMwzhcTRXpkkzTpKamhoyMDGy29h0WUPkrcvgph0W6LuWvSNemHBbputojfw97QaywsJDU1NRW61JTU6murqahoYGIiIi9HnPHHXfwt7/97XA3TSSk5ObmkpWV1a7PqfwVOXKUwyJdl/JXpGtTDot0XYeSv4e9IHYwbrrpJmbMmNHye1VVFd27d2fbtm3ExMTs8zE+n49PP/2UE088EafTeaSa2imEa+zhGje0jr2xsZFevXrtNzeONOVv2yh2xa4c7toUe/jFrvwNHYpdsSuHuzbFHn6xt3f+HvaCWFpaGkVFRa3WFRUVERsbu8+qOIDb7cbtdu+1PjExkdjY2H0+xufzERkZSVJSUlh9ICB8Yw/XuKF17A0NDQCHpRu18vfwU+yKXTnctSn28Itd+Rs6FLtiVw53bYo9/GJv7/xt3wul92HChAnMmzev1bq5c+cyYcKEw/3SInKIlL8iXZtyWKTrUv6KdG3KYZHOr80FsdraWlauXMnKlSsBazrZlStXkpOTA1jdPC+77LKW7X/961+zdetW/vSnP7F+/XoeeeQRXnvtNa6//vr2iUBEDpjyV6RrUw6LdF3KX5GuTTksEnraXBBbunQpRx11FEcddRQAM2bM4KijjuLWW28FoKCgoOWfAkCvXr14//33mTt3LiNGjODee+/lySefZOrUqe0UgogcKOWvSNemHBbpupS/Il2bclgk9LR5DLETTjgB0zT3e/+zzz67z8esWLGirS8lIu1M+SvStSmHRbou5a9I16YcFgk9h30MMRERERERERERkc5EBTEREREREREREQkrKoiJiIiIiIiIiEhYUUFMRERERERERETCigpiIiIiIiIiIiISVlQQExERERERERGRsKKCmIiIiIiIiIiIhBUVxEREREREREREJKyoICYiIiIiIiIiImFFBTEREREREREREQkrjo5ugIiISJdmmtBUA4YBhh0MG9iabw2btV5ERERERDoVFcREREQORDAIVblQsgFK1u+xbARvzf4fN+oyOPvBI9dOERERERH5USqIiYiI7Mk0obYYir+D4nVQvLb5dj346tr+fIZGJxARERER6WxUEBM53HZdTtVUDQ2VUF8KdaXWAXddSfNSCt5a8DVYi7/51lcPvka4YSNExHd0JCKhwTShoQIqd0BlrtXra9dtVS5U5lj374vdBcn9IWUApAzcfRvfvfm5gxAMWLe7FrvryMUmIiIiIiIHRAUxkYPh91oFrtpiqM6H6rw9lnyoLYGmKmissophZvAQX6+xfdotEoqCAau4VV9h5Yq/wSok+5uX+vLdha5di7f2R57UgMTekDoYuu2xJPYGu3adIiIiIiJdnb7VS3gzTfDWQUO5ddBcV9rcY6t4d8+tuhKrsNVYBY3V1q2/oe2vZXOCJw6ikiEqZfcSnQKRyeCJBUcEOCPAGQlOj3Xr8FjbiYQ7X6NV+CrZsMc4XhugdCMEmtr+fNGpEJcN8dnW7Z4/J/YGV2T7xyAiIiIiIp2CCmISmvxNUFO4R++t/N0/15VYxa+GCmsJ+g7+dSISIDYLYjOal0zrNjrVKn554qxClyfOKmxptjmRH+ZvssbrKlkPFdublx3WbU3+/h+3q3Ds8FjFZEfz4owAd6x1SWPL0gPisqztREREREQkLKkgJp3Prl5bTTXW4q2xemY1Vbe6tTVUMHLHd9hff8W6PLGh0ipwNVZaY2+1hd0NkYl79N7qtsfPyeCJb13ccsdaiy6dEvlhwYDV0zLgBUxrndl86/eRVLse25JcKPkOClZDyToI+vf/fK7o5jG8BkJK/93jeMX3AJv9sIcjIiIiIiKHWcBndWKJSj6s3/F1NC9HRjDYXNiqsopW1QVQvROqmsfdqsqzfq+vsLY7gDG37EAPgPL9beBu3Wtr18/R3aziV0QCRDTfOiPUe0ukrYJBqC3aPT5XVe7u3pg1BVae1xaBGdjnw53AMQCbvneHJx7ShkFiL6vQldATEnpZt5GJylURERERka4oGITaQijfBhXbrKtAaougrmz35HP1pVbdAOD3a6whTQ4TFcTkwJmm1fuqptA62N11W1/ePBtig9Wzq+Xn2uYCWKXVq6utA8sbtt09sdzR1q0ntuU24Ixmw/YCBowchz0qyZqFMSLBOpiOiLdudeAscuBM08rn6p1WUauhYvcMqbt6bDZWWzupyhyo2tnc8+tHGLY9ZlpszknDwAQa8ODpORZbxkhIHw5pw63LGZW7IiIiIiKd1676QG2xVdSqLbaOJby1u+sCu35urG6e3GpHGyaMM6zjERXEpN3t+vDWle4eOL6+1KrMNlZaRazGyuaB5CuhocoaaP5QZzu0u6xCVUyaddAbmwlxmdY4XHGZuweXd8dYA8r/wEFx0Odj05w59Bt1Onan89DaJRIO/F6rR+au3lyVudZtVW5zL838tk8YYditPI7Pbs7pDIjJgNj03bdR3fZ5ebHf52PunDmcfvrp2JTDIiIiIiIdw1sH9WXWUle2++ddk8s1Ve8x0VxV84R0xQd2cvz7DLt17LDrCpDYzN3DF0UmN98mWZ1dDvOQKCqIdXWmCU01RDYVY+QtB29V84yJzR/ghordvbR2Fbd2/X6wg8lHJEJMulXUikm3PryuqN2zI+762RW9x8Dy8datBrEWaT/BoFXMrs5rvkQxv/WOq2WptHZsNQW0jOP1Q6K6WYWtqBSrON2yNBerIxKsnVh8d6vopbH0RERERESOPDMItSXW9/zaImsJeMHmsApPNnvzzzarc0tNobVNTQHUNN/WFrf9pPiePHHWpHLRqc21gRhrtnZXFDijrFtXlHXyPLGXNaO7vXOcDNdRTGdjmtblhrtmQNw1SHxDhXWgW1NkXXNbU9jyYXb66jkZ4LuDeD13rFV9jUqxlpaxteL3KGTFW79HpVgfchW1RNqVPdBoXUPfWGGdaakttgpddaXW/wN/o7Xs+tnX0Nw1ufCHB6DfF4fH2gnFd2/u1bVrydw93p7DfXgCFRE5nAI+67tSU431vzEYsA4UzIB1AiHoB18deOutM+He2ubLOZon8vHWQlPtHrc11u0v5kJUUkdHJyKwe6DthvLdtw2Ve+e0t9bK9e4TYNxVHd1qkR/mrW8eR6uk+Tig2Cpy1RVbdYCA1/rs73Hr8DVwSlkujlU1bT8e2B+7y+qhFZlk7fciEnfXBdyxe3R2ibNqBtGpVo2gC9cHDqog9vDDD3P33XdTWFjIiBEjePDBBxk7dux+t581axaPPvooOTk5JCcnc/7553PHHXfg8XTdN65NAj6r50ZVrjXmzq7b+jLrWtqWLojNPx9Ezy2/zYU9uhtGVFJz98LE3d0MW4pbe/TUioi3Puxd+MMrB0f5ewT5m/YoXhdag8zX7LFUF+CoKeBMby2sPsjXMGzWzig2w+qxGd2t1c7KdEbjqwkS9DtxDR6NLaXHQY3PZZomwZoa/MXFmIEArp49sbl/vHBmmiaBigpsERHYIiIOJkL5HuWwhJRg0JopurG6uejfAL7G5ttdy54HuHW7l4aK5sF3y1oPwNvemqrarSCm/JWwE/BbRatdA2XXl1k/N1RaB/dBn3WsFPQ33/p2j0v8/ZzfdczUFjZ7uxbElMOyX7v2Z7uuzGr57Nbu/iw31Vp5UFvU3NGledwtb02bX84AWn2zjky2ruCKTrVOgJuBPU4OBaxbu6v5Sq/U5uOG1N3HD1HJ1hVeR3gcXzMYxLDZjuhr7qnNBbFXX32VGTNmMHv2bMaNG8esWbOYOnUqGzZsoFu3bntt/9JLL3HjjTfy9NNPM3HiRDZu3Mjll1+OYRjcd9997RJEhzFN60Ncvs0qcLX07Cjd/fOuXhxtHVDe5mguZn1viU7d/UGPSYOYNJqI4qN5n3HqGWfg9HgO6gPVcrBbVmbFtY9YzUAAAgFMvx/T7we/31pnmmC3YzicGA57y88E/PgKC/HlF+DLz8dXkI8vP59AaRme4cOIP/dcoiZOxHB0vo6KgaoqvDm5+HJz8BUUYo+Pw5mejjMjA0d6+j4LAaZpYtbXE6iqwgwGcXbrhuFy7ePZd2/vLyykadMmmrZsJVBWSqCqmkBVFYHqagLVVQQrrZ/7fbYQW2TkIcel/G1HpmkdjFVsg4od1gCRFdsJlmwnWF6IWVVMsK4KM2AQDBiYAWvnYhiAzcQwwLCZYIDNbscW6caekIwRm2pdshjd3GvTGWnt1Jwe63bXEpWCGZ1GIOAhUFmFv6ycQEU5vvwCvLk5+HK/s27z8sG/+6yRMzMTd9++uPv3w923L67evTF9fuvzVl1NoPkzF6iqIlBWiq+4GH9xiVUIa9xjDEGbDVf37rj79cPdry/ufv1wZmTgy8+nads2vNu24922De+2bQTr6gCwJyTgzMjAmZGOIz0de2oaMTt3UhcXhzspCXtsLPa4OGwxMRh2+x5vtbn7/00wiBERgXGQO+tgY6P1P6kgn2B1NZ4hQ3BmZx/08x2I9tzRK4el0/I37R6TtK50d+/2lrFIK1t+NmsrCNRUEqypIVhXZ31f99kwAwZmEIJ+AzO4+3+nGQQzaIBp3ZomEDSwu4O443y44/y4ov0Ydpon5IlpuTzExI6/wYa3xoavzoYZdBHEiWk6MU0HQdOOGbRji47EmZyIMy0ZZ1oqzox0bDFJ1qQ+Ment8hYpf6UrMoNBgrW1BMvyMSsLcEb6MeqLmmeVzms+2ZdvHejvKmgFvFYhLOg7qPGHzSB4ax00Ve1anDRVOQh6I8Dmsb5D2W3NxxwOa3E5sLmcGG4XhsuFze3G8HiISO9DfDu9F8rhMLDr+33LeLs51pi7TdXWfi7QZI3JG2iyfvfW7R5vu6maAxqaZH8cnubCVLfm25TdlyDaXc2Ls3lx4TdtfLlyIxOnnoczPoNAbb11/Jq3EzMQwBYVhT0qCtv3FsPj2e/33mBjI76dO63n2ZmLLy8fW1wsruzuuLpn4+zeHXt8/F6PN00Ts6GBQHU1/rIyfPn5+AsK8OXl4yuwagH+4mJMr9eqJQQC1nd7vx9ME0e3bniGDsUzdAgRQ4fiGTIER9KR6Znd5krEfffdx5VXXskVV1wBwOzZs3n//fd5+umnufHGG/fa/quvvmLSpElcfPHFAPTs2ZOLLrqIr7/++hCbfoT4m6wkqNjWPDXo9tY/H+i1tnaXdc1sXBbEdSfg7kbQiAFnNKY9AtMehWn3gCMS0xlpHQTzvQ9aU/MHdH0u3tzF+HJy8e7cSaC0lH7AlltutTa02ayDSYcDW0TE7oPMuFjssXHY4+IwHHb8JSX7P9g9zHx5edR88CGOlBRizz6L+GnTcPfrZ8VpmviLi2lcs4aGNWtoXLMWf3Extpho7HHxVjyxsRATQ3zODirLy7GZWAkV8GP6A5gBP47ERJzZ2bi6d8eZlbVXEStQW9tywN60bRu+HTvw5uTizc0lWPXDZ5ntyck409MxbLbdxYPq6laFBwwDR0qKVUjLtAppjoQEvDtyrCLY5s0Ea2sP6P0KVFe3S0Es7PL3UPkarGJ3xfbvLTsIlmynqbSx1Re1pioH/vpd/1Y9zUtb+LHFVGOPM7DHNmGLqYJgELO5EL2rKGT6fNbnrrzcOhv1IwynE1tUFIHKSnx5efjy8qhduLCNbbPY4uLANAlWV+Pdvh3v9u3UzJ17QI8NVFQQqKigce3alnXpQMHLL+/d5sjI3UWwQKD1fW43jm7dmpcUnM0/Gw4HwcYmzKYmgk2NmE1ezKZGApVVLTvjQHn5Xq/lyEgnauw4IseNI2rcWJwZGZimiS8vj6b162lct57G9etpWr+eYFMTjoQE7ElJOBITm28TMCIiCFRUEigvs4qT5eX4y8sJlJURf/75pN60d34dDOWwtBczECBQXW0VwquqCFRVYzgdLblli4rCCHh3H/DWlexxKYf1s722mMklO3B8dw3+qjrr/2C19T8x0GQj6DMI+nfdGi2/m8Fd328im5d2YLfj6pGNu/8AHIlJePN24svdiW/nTkyvFwg2Lwd+WcmuIn7mfffi6tHjkJuo/JUOs2fPleYhWYzaUnqULsJYnIO3qITG7QU05pTQlFuOt6SWQIOXoDeA+b0LVxyeALE9Gojt0YAnwbfPziT+Rhu1+W5q8yNoqo4BDKtYbbPvMaaR3VqP0Xy20LB+DYKvvBbTfyCdCUzA17zsJ/SYnu1WEFMOd3Etha48q/PKrhM4dSWYtcUESosIlhYSqG9otc8K+g1r97EPht3EERHEERHAEWFgd5kYrsjmSwxjCAQj8Na58NXa8VaDrzqAaXNhuKMw3FEQEYPhicaIiMU0DYJl9QRz6qyTRXUVBOp3gs+HERm5u7gVad2aTgcRK1aS+8YX+HbuJFh9gL0n7XZskZHWc0U3F8lsdqtoVVT0ow+3RUfjzM7G5vG0HAMHq6owfQc5PjngLy6mdv58aufPb1nnyEgnYshQUn5/He4+fQ76uX9MmwpiXq+XZcuWcdNNN7Wss9lsTJkyhUWLFu3zMRMnTuSFF15gyZIljB07lq1btzJnzhwuvfTSQ2v54VCdD9u/gJxFULoJKrZjVuwk4DMIeg0CXusMv90VxOYKYnea1tmJuCyI79FS0TWjkjFdCQSNWAKmB2+5H29BhXXwuGQbTdtXEygtPXxxBIOYwSD4fAQaGvZ5ALg/tujoVj0zWmk+C4PDjmFvPhvjsLa1ilC7K71mIACGgTPVOsu6q2eVMz0De2wMNfM/pfrdd/GXlFD+1NOUP/U0nqFDcSQn07B2DYGSA3t/ugGl77x7QNs6UlNxZWeDYdC0fduPvoY9JRlXdnecaWkEamqae7gVWL3ASkv3+zc0nE4wDEyvF39xMf7iYhpWrdpPoxy4evbA3bcfztRUq2gZF9dcuGwuZMbGtkuFPOTz92B466BgNRSsss4C1RbtMdBkkfXlsZkZhMYKJ7X5HmoL3DSWRwMx+31qw+XEcHuweTwYbre12AxMX3NRK+AHnx8z4MdXW4fNa83QEqypIVhT8wNf7fZmi4uzijOJiTi6pew+i9N86+jWDcNux19R0VKM9W7eTNPGTXh37MDweJoL57HYmovm9thY7EmJVrEpNdU6SE5JwebxWEXrkhKaNm3Cu3kzjZs24d20GV9BAc70dFy9ejUvPXH36oWzRw/MhobmolRBS29R7848ijdtIt7pJNi8Mw3W11vvd/PtvphNTfhyc/Hl5rbhXdrj/YqMxJmZgRERSeO6dfjzC6h66y2q3noLAGdGBoHmv8O+BEpLYdOmA349fxv+B/8Q5bAcrEBlJXWLv6buyy+p/2YJ/tJSgrV1P/gYw2HijAjg8ASwe4IYzT1bMUwMm3Vsa5rgrXaQXxVJoGn//w/3+xouF7aoSGxR0c1nrd3Y3J7mWzeG22P19nA6W7537P4OYp3Ya9rYfIKprg7v1u14t27f+4UcDqt3amYG9uho63k9bmwuqweJ4XISqKqyDgaae7UH6+paivi2qKg2x/Z9yl85HAI1NXhzcvDl5uIvLsKTGUNEioFRvR1KN0PZZijfYl2m2Hy1SjAADSUuags8xJe52FzpwPQfQC9mw/of4G+0U74hmvIN0bjS4og7ZjixU0/CtEdQu3gVNV8tp2Htxn1fcYKJVZT+8cK0ERFh9WjftfTvhyM5GdMfaD4BvvskuOnzYTY2YXqbCDY27vFzE+7+/drylu6XcrgLaKq1vs9X7MCs2IFZvJVgyXbM8hyrh2NDLWbAIOCz4a2146t1tLo1AzYgunk5OIbTaZ1UionBV1BAsKqk3cLblxigaY/f7SnJuLKyMZzO5qLaHsuu79aBQMvxxr7YoqNxds/GlZWNMzPT2j/m5ODNzcVfVESwtpamdev23SCHA3tCPM70jJarq6zbdBypadgiPM37cgfGrtqCzYZ3x45WnWG827bhzy+gJr+Abn/6Y7u+Z3s1uS0bl5aWEggESE1NbbU+NTWV9evX7/MxF198MaWlpRxzzDHWQZTfz69//Wv+8pe/7Pd1mpqaaGra/aetbq52+nw+fPupPO5av7/792T6fNbB1MbVBDYvJbhjLcGC7QSqavA32gg02Qh4rSXo++Fu8rboaGxxcdg8EKzfTrBurfVh8x/AGcjmLr7Y7bs/EA7H/i/dcThwZmbgzM7GmZWNMzsbR1YWpHbj0y++4KTjjsNhGLt7k/j8BBvqCVZV7z4LXF1FsKoa0+/DkZKCPcXqYeFI6YY9JRnbEbqePWnMGBKv/z11n31GzdvvUPf55zSuWbN7A7sdV58+uIcMwTNkMI7MTIK1dbtjqK7GX1lJweYtpGZkYHc6WxfsDBv+slLr7HBuLmZdHf6ior2q3vakJJw9e+Lq2RNnzx44s7vjzM6yepTto0eW2dwzxp+fj6+gEEwTe2xsc++7WGyxsRjN4yQFysvxFxQ0L4X4CvIJlFfgzMrC1a8vrj59cPXsaRXQfoQfYI/P9p6f9wP5zEPo5O9BC3gxClZhFKzEKLRuKd2IYQats0D+3ZfhmGbzOMxBB0210dSWxFGXGyRQ37qnkj0hoflv2RdX3764+vbB1aePdcnfAV4i5/P5mDt3LlNOOAFbQ4NVGKquJlBVTbCuFsNmbz4AtDfvPKzPuD02FntCAvaEhB/9DPmDQevscHQ0rqOOwnXUUQf3FgKBXX+jhATcY8fiHjv2B8qCux9HZCT2Pn2w9+nT0m/O5/OxfO5cBp18Ms7mGHb1fjPrG1ritv5POjCc1i4rUF6Ov6SEQHEJ/pLi5sJzCQQDVhFyVwHS7bYOeqNjcKan4cjIwJGWji02puX/bLC+nsaVq6hfsoSGb5bQtPY7fPn5VgMdDlx9++IeMAD3wAG4BgzAHhNDoLyCQLl1iWqg3FqCDQ3YE6yipD0hAXtS88+JiTiSkvb6bCuHQ0dnit2sr4D8dQTy1uPfsoH61ZuoX19AY97+i182R/NJPpeJGQR/g926fNFv4K1x4K058K+Kjqys5v+Dfa0C+q6zz5FR2KIiMfY8ux0ZcUD7vwOxawgCb3OxP1BVbX0Jz87GmZ2FIy2tTcMztAwjUVCIvyCfYGxsq7+v8jd0dKXYfbnbqZvzJo0rV+DLK8BXVEGw3rvXdoY9SGSKl8hUL1HdmvAk+PA32KgtiKS2MIq6Qifm9w5TDIcNV3oM7swEPN2TcWWlYktKw0hMw0jKwJaSjRGfAaZB/RdfUPPe+9QtXIi3sIqSNz6n5I3P92qHe9BAIk84gYijRrV5eBRH8z67vYYb0D44RJgm1JdhVGyF8q0Y5Vvxb1rLuHXrqf7fH/BVNO0uctU5WoYrsRxYj2QjMqLlJI21RGKLjALnvj/DZn0D/tJSAiXFBMorrDpDXl6rbezJyTizsqz9UWYmhtsNzcXclqs//AEMu83aP+7qtbVr3+l0EqxvwKyrI1i/q8BVT6Chns3lFQyZfBKeHj32e/za0tZgELO+vuXxez4XPh+O9DSr59c+LoncJdjUhD8vzzq+9vuxNV+5ZWs+md7WYU12lc2dw4bhHDas5ZjCKrqtp2n9OkhNPeR98A857IM3LViwgNtvv51HHnmEcePGsXnzZq677jr+8Y9/cMstt+zzMXfccQd/+9vf9lr/8ccfE/kjl43N/d6lO46KCqI2bsJZUoKrpARPcQGOiqr9XN67/+cOuN0EIyKsAkhDw+7eHLW1P3jZW8DtxpeYiC8lBW9KMt6UFLwpKfiSkwkeavEp4Icd263F5WLe4sU/vL3bBSkp1rJLMACFhdbSUU6div2YSUSvWYMRCNCYmUVTRjrmnuNv7eoCGh1lLRkZ1u/jx1PwY89vmtjr6nCWl+MsKwfTxJeSjDc5hWDE9/4GTY2webO1HKiSRigp/uFtkpOsZZdg0Oph0oZeJvsyd+5c6n+gJ82h6uj8PSSmSUxjHik1a0ipWUti1Xp8ZUF8NQ68LWeEEmmqcxJs/LF/3NY/24DbTX3//tQNGEB9/3744+Jab3YIufTJggX7viNgXQq8l5LDe8bpSDqkv3tiorUMHPjD2zU0wJYt1rIv/ftB/37YGhtx79xJICoKb0oK7PklvqRk9/tuMyApyVr2pakJCgqs5Qcoh0PHkYzd0VRLyrqviP52LfaSCoxGH2ZjgKDXAHPf/89csT6i0pqISmvCEWMQiIwgEBGJzxWHzx6F1x5FkzOORmciDcThbXLjb7BBrQ97QwMEghjB5nH8AkGMYNDanyYl0pSWhrdbt9b77V28XmuprDjM70qz1FRrAagot5bVBztrSbMPPtjnauVv6Og0sZsmkd5iEuq2Et1UQERxPsbGIvzbGmkq2/cVHHZPAFdUALs7SH2Zi2CTjbpCD3WFHkoA0+HA+N6Jen9MDHUD+lPfty9NGRl4k5NhX1eIVAPVNbDtO1pNZz/5JGyTJhK9Zg0xK1YSuWUL2GzU9+lD7eBB1A0ahD8+3tq24iB6SZcUH3reHgDlcOfm9NeSXLuepNr1JNZtJrqpEGegHm+NneqcCKpzI2iq3HVixdm87M202zAdDoJOF6bTSdDtxpeYgC8xCW9SknWsnpSILyGh9fe+tvL7cdTU4qiuxtbQgD8uDl9S4r73jQciGIA9e3HZbRATYy17+NLna/vx677s3GktbbHnd+PDISnpsO+DDdPcZ3/WffJ6vURGRvLGG28wbdq0lvXTp0+nsrKSt99+e6/HHHvssYwfP5677767Zd0LL7zAVVddRW1tLbZ9VP73VRnPzs6mtLSU2NjYfbZtVy+Lk/foaVDz7nsU//3v+xwby3AEcUUHcMRFYk9Jw5bZG3v3wdi7ZWBPTGi5VK1lgOfvncXc1YthV+8rs6lxj2t6rWtyjYiI/V9+2I72FXs4CNe4oXXsDQ0NJCcnU1VVtd/8gK6XvwfL2LoA25rXMLYtxF9UQm2BdYljfZGb4I9dEtDcW5M9emw6UlKIPOYYoo49Bs+IEe3Wo2EXfY4Vu3K4azvssQe8ULIBc9vXNCycR+3SDdRu9RL0/cD/Mxs4ol1E9EslckR/Io4+Cmf3fpjRqdbwDq6DvxxkT+H6d1f+ho6Ojj1YWURw/RcEN39DYPu3BPK3Eqyux99op67IvcfBPoBJRLcA0X1jcGZ2s65q6NUPI7U3xGVhxmVjehLxbt5CwzdLaFjyDQ1Ll1qXRdlseIYPJ/LYY4g69lhcAwbgDwTaLfZdYxC2x3i3R4JyuJNqrMLY8SXGji+x7fgSitdiNPdi8dbaqcmNoDrHQ2PFHgUmm0EgOZaYvn1x9e6Ps1ef5t5Y2diTkqyrBY7A8XhHCJm/exsdTP7+kDaVQF0uF6NHj2bevHkt/wiCwSDz5s3j2muv3edj6uvr90p2e/OHcn+1OLfbjXsfs/g5nc4f/WM7nU7swSBF/7ydytdeA8CT4CUixYs7xo8rwY5r+AQcR0/D6H/qwU+j7XRCZCSkpR3c4w+DA3l/QlG4xg1W7P4DuTyXrpO/B/u3NIu+w//fG2lYuZiGYmtsjKaq1vlpT0zE3a/f7vG1srNabttymePhEO6f43COXTkcGtoldl8DFK2FgpWYO1fS+O1yGjbkUldop67Q3Ty+CYANeyTEDO1G1OjhODL6YMvshz1rIPbk9EOaifVghOvfXfkbOo5Y7KaJf/0iat54mpovllKX0/i9Xp1OYI/e5zaDqKF9iDnpWGJOPxdHdl/2OYr9HlxDhxA9dAhccQVmIIB361bsyck4EhJabWc0X2rUHrE7kw/yeKqDKYc7mGlC8Xew6WPYNBdyFoMZsMbtrXTSUBZBQ00yDWUufGV79ASy24kaN47Y00/Dc8IJfPTll5x++uldK/Z21OX+7u2kLfn7Q9rcJ3DGjBlMnz6dMWPGMHbsWGbNmkVdXV3LbBuXXXYZmZmZ3HHHHQCcddZZ3HfffRx11FEtXUVvueUWzjrrrJZ/CO3Jl7uT3Bv+QNN368CA5ME1JI8MYgw/FwaeCb1PAGdEu7+uSFfQ2fO3LXz5+dQvXUrjtytoWjyXxpwSAk02YI8vZTYbESNGEH3csUQddxyeQYM6tOglcqhCKYdlD2VbMBfcQ/38t6gvstFQ4qKhzNXcq3V3by5nYhQxx4wh5uyfEjHxRP0/62KUv2Eq4Me35G2q33qFmq/X0lAYZPdM8gaGDewxLhzx8dhTUnGk98CelIx7wABiTjwB+65LDw+CYbe3zOIuh0453A5ME7Z+Ct+9YxXBqnfib7DRUOaioTSShuo4GkrA9O2a1rF5EgbDIPLoo4k9/TRiTjkFR2IiEAbjpslh1+aC2IUXXkhJSQm33norhYWFjBw5kg8//LBlgMGcnJxWlfCbb74ZwzC4+eabycvLIyUlhbPOOot//vOf7RdFs6i1a8m97Z8Ea2qwx8eRMaaQ6OQaOO3fMOb/tfvriXQ1nTl/D5RpmlQ8/zxFd939vckrbGADd4/ueIYfRdSxxxI1aeJeZ0RFurJQyGHZLZi7irrn/krNlyuoyXMT9Ma3ut8W6SFi5DAixx9D1MRJeIYMPqI9v6R9KX/DS7CqnOqn/kHlOx/RULhnbyADT2YEscceTcz5v8A55GjldRehHD5EhWswP7iRxuWLaSh10VDmpKEsFV/dnsVBqxBmi4khYsQIaxk5kojhw7B/f+xekXZwUKPGXXvttfvtGrrgewNDOxwOZs6cycyZMw/mpQ6I6fNReu+9ZP7neYJAxMiRZE514dyxDjJGwajph+21Rbqazpa/bRGoqiL///6P2k/mAc2XQyd7cfdIx3P2dbiP+8kRmylVpKN05RwWa2bT2rf+Q83//kPt+rLmXmBWz3V7fAxRE44hYsxoIseMwd2vn3qBhRjlb2gzTZPG5V9T+fi/qP5qHUFfc6HLMInsmUDM5OOJueBKnN37dGxD5aAph9vGDAZpWr6Iulfuon75aupLXAR9Ka03Mgzc/fo1F7+sApirVy/t/+SIOOyzTB4JVW+/TeWzzwEQd+mlpF84CeOFswEDzrgHbGHaJVUkhDSsXk3e76/Hl5+PYTPpNrKKhFFxGCf/E4ZdANppikgn1rRpExXPP0PVO+8QbAw0r7XhiHUSM2UysedeTMSoUSE7+K9IqDJNE++2bdR+9B5V/32Zpp2VzfcYOGMh/pRJxP36FpxZPTqymSJHVP3y5ZQ/8wz1X31OoG7XJAHWSWtbdBSRo8cQcdRIIkaMwDNsGPbo9pnsRaStQqIgFnfuudR89jkbu6XQ9w+/x3h6snXH6Mshc3SHtk1EDo1pmpQ/+xzF994Lfj/OGJPMCaVEDOgLl70NMakd3UQRkX0Ker3UfDyXyldeoX7p0pb1zig/saO6E/Pz6/Acd6bOgot0McGGBuq+/pq6zz6jduFCfHn5LfcZNpOYvi7iL7yIyAtmYDj3HiBdJFQ1rltH8axZ1C38rGWdzREkIttD1ORziDz1QjyDBurkj3QaIVEQM+x20u69h+Vz5mBb+oQ1W0VEIky+taObJiKHIFBbR/6f/kTt/PkAxPQMkD6qGHv3oXDp2wc/S6yIyGEUrKuj7KmnqHjlVQLl5dZKwyQms5H4sRlEXfMwRuZRHdtIEWkzX34+hf+8nbrPP8f0elvWGzaTyJQmooekEvf/bsA+6jz1XJew4t2+nZIHHqR6zhxrhWES36ue+KEePD+9GWP0JcoJ6ZRCoiC2i8dXge2zf1m/nPw3iEzs2AaJyEEzTZOC//s/aufPx3A6SR1VS3zPMoys0XDJfyFCg+WLSOdimibVc+ZQfNfd+IuKAHBEBIjvU0f8QBvOs26Bo3+hoRxEuqC6r74ib8YfCFRWAuCINohOqyU6vZGogZnYTrsLBp0FGiBfwoi/pISSBx6k8n//g4A1HEBs93pShtXgOu4iOPVOcMd0cCtF9i+kCmJD8l7G8NZB5hgYeUlHN0dEDkHFyy9T89FHYLfT/aRKIhOqoPsEuPg18MR2dPNERFpp2rSJ/DvupP6bbwBwxkK3YeXEZDZiDDkLTv0XxGV2cCtFpK3MYJCyx5+g5IEHIBjEk+oifeRO3PF+jKgkOOGf1jAtdmdHN1XkiGpYuZKdv/0d/pISAKIyfXQbWoEnPQrOegqGnNvBLRT5cSFTEDO2f05WxWJMw4Zxxr3qkinShTV+9x3Fd9wJQLeRtVYxrNdxcNEr4Irq4NaJiOwWqK4m5Z13yV28GAIBDIdB8qAqEgfWYkvIhNPvgYGnd3QzReQgBKqryb/xppahG+J61ZM2Jh+bOwIm/B4mXaeTdBKWKv/3JoUzZ2L6fLi7RZA2LJfIFC/0mATnPgbx2R3dRJEDEhoFMb8X+0d/BiA46grsGSM7tj0ictACtbXsvP56TJ+P6O4miX0roO8UuPAFcEZ0dPNERFrUfPIJBbfOJKF5nLCYbC+pIytwxhjWwfJxfwS3Zs4S6YoaN2xk529/iy8nB8Nmkjq6ioQ+9TDspzDlb+rxKWHJ9PspuusuKv7zPAAxvQwyRm3F5rLBiTfDMTM0LIB0KaFREPv2NYzSjTQ5YrAdfxNKQZGuyTRNCm+diW9HDo4YOxmjd2KkDoafPqdimIh0GoHaOoruuJ2q//4PAEesSfpR5USnN1m9WU+/B1IGdHArReRgBBsaqHjxRUoefACzyYcj0k/WpAoihgyC0+6CHhM6uokiHcJfUUHejBnUL1oMQPLQWpKHVGMk9IDzn4asMR3cQpG2C42C2IiL8Hsb+XbdFkZExHd0a0TkIFW/8V9rdhqbQea4QuxxsVbPMPWwEJFOon7ZMvL/fCO+nTsBSBpYQ/KwGoy4NDj1dhhyngbVFumCTJ+PyjfeoPShB/CXVQIQldpIxmQDxxn3wFGXqueLhK3GjRvZec21+HJzMZwGGWPLiM1uhKHnw5n/1qXD0mWFRkHMZsccNZ28wjmM6Oi2iMhBcRUUUProbAC6DasiMtkP5z0JSX06uGUiImB6vZTcfz9lTz8NJjgj/WSMryQi3WBL0mn0uOwRnNGa3VqkywkGqXnvfcofnIUv35od1hnpJ3lYHXEXXIJx0k2a2VrClun1Uvb005Q+8iim14szOkjWMaV4Ulxw+iMw8mKdBJIuLTQKYiLSpQXr68l48SXMpiaiMrwkDqyFk26G/qd0dNNERKj/aj6Ff51JU04pYA2snTo+iH3SNfhG/5K1ny2jh6aVF+kyTNPEu2ULNV8vodfjj1BUVAaA3RMgeUgd8dPOwDb5Rkjs3cEtFek49cuXU3jrTJo2bwYgKq2RjAmVOHoMgfOfgeR+HdxCkUOngpiIdCjTNCn5x224SkpwRJlkjCvHGHQmHPOHjm6aiISrhgrMbV9Q99H/KHvvG+rzAgDYXQHSjoXYi66HMVeAJw58vg5urIj8GNPno/G776hfuoz6ZUtpWLaUQFUNAE7A5gySNKiWxHMmYzvlZkjp37ENFulAgaoqim/7PyrfnQeA3R0g9ahqYns0YIy/Gk7+GzjcHdxKkfahgpiIdKxAAMPjBgMyx5XhyOwL0x4Fm62jWyYiB6Ckto5Z8xdRkd9AzdIdJMdEERvhJK55SYh0EemyY3TWSyrqyqBkPZSsg5INmLlLqPlmA2Vro2iscFnb2EziBnlIufqXOI//JTg9HdtmkXb01JIlLMjLY9W8hSRERhPniSbBE0VCZBRxHjexEQ5iPU5iI5zYbZ00j/fDl5dHxcuvUPn6awSqqlvdZ9iDRCT5iEptIu60STjPmAmpQzqopSIdLBgguHUxNa8/RdFriwg0WKvjetXRbayJY+S5MOpS6DGxY9sp0s5UEBORDmU4HKSNbyS5vhhXsgd+9pIG5hTpQr4t2sY7FddDJHy+EcyABzMQ2WqxmTFE2hKIdcaT4EkiOSKJtOhu9ElMIyshkoz4CDLjI4jxOA9/g0s2wIoXIH8FZuF6fKXl+Ors+Ort+OrsVOdE4K22xgsynDbiT5lA0m9m4Owz+PC3TaQDvLblGUqivmZt0d73mUEnZiCiJZcdZhROWzQeWwxRjnji3YkkeZLoFplCZmw3MmISSYnxkBkfQVqcB6f9CJ7caqiE3CWYZZupX7KU8vlrqd1YDaZ1t90VJCKlichkL5Fp4DlqLME+J7Ag381x5/0SnEfg/4/IYTDn20KqvW1/nFlbStP8l6ib9wG1q7fQUGTDDFpFb1dsgLTzhxJ11hXQ92SdCJKQpYKYiHSsgB+jthB3rB//OY/i0HgEIl2KzebFQQR+rNPJhr0Rw94IlLfargkoaV42NgKNYBbbMf3xBL0JBP3xuMxkElyp9IztzfBuAxiUlkj/1Gh6Jke1+cA6UFlJ7Wef4S8tI1BRRmDHtwRz1hKoLCPgteFvsONvcACpe8cUE03CJZeQeOmlOBI1UL6Etp7xKVSVxmPaAwRoIsjuI2vD5sOw+cC5u3eVr3mpAQoDQF3zUgKmacf0xRL0JmH6kom2pdPNk0V2TA/6JmYzKD2eIRlx9EiMxHaovc28dZCzCLZ9hrllIU0bvqO+yEHF5ii81buLW1GpTST0ryd6RE+MfpOhz0lWLxdnBEGfj9o5cw6tHSIdKKesnj+8sRobdvKiNnH1Cf2Ii/zh4m79vP9S8dDt1G2tIdC0a+ZU69YR6yL+1Ekk/fEf2GKSDnPrRTqeCmIi0rHsDgLnPc2Xr89ifP/TOro1ItJGJ/QaxZKsL3n3/XeZNHkSdcE6qpuqqWqqospbRWFtKfk1JRTUllDWUEpFUzk1vgoaglUYtgCGqwybq6zl+SqAigAsz7cT3JpGoDEDw5tJmqcvI1IHcWzfDCb1TSI9LmKvtpimSeOqVVS88irVH3yA2dS0jxa3PsttuN04MzJwpqfjyEjHM2AgcedOwx4d3c7vlEjn9Nhpf2fOnDmcfvrpOJ1OgmaQRn8jDf4G6v31VHurKauvpLC2jKLacsoaKilrqKC8sZyKxjKq/RXU+yvwUYdhBDBcFdhcFcBmmoBcINcLXxbYCW5LJ9DQHYevB31ihzAyrTdDM+M5ulcivZKjWrWrcd06GlatxhYViS0qCltklHVbvQm+fIjGdetpKLPRWO6kscKJGUhueazN7SDuuGEknHcm7uHjIC4bHK4j+r6KHAk1TV4S+jxBVUVPZn9xLC8uyeVXx/Xmikm9iHK3PtRvXL+ekn//m9qFnzWvsWM4IWpABlHHHEfUGRfh6tuv8w5xIHIYqCAmIh3PMCiPHtDRrRCRQ2A37CR6Ekl17t3jal98QR/F9cXk1+aTX5vPjqqdbKnIJadmJ7m1W2gK1mKPyMMekQd8Qxkwr97JR1/1x//xYLLcozm2dw8m9U1mXKoH5n1IxSuv0rR+fctruON8uON92F1B7DFR2PuMxTb4ROypPXGkpODMzMCekKAv/yJ7sBk2Ip2RRDojSaK5h8gBdBTxBryUNZRRUFfA9qodrC/bwqaK7eTW5FDWlIcfL/aIndgjdgJfsQ3YUhbF6zuz8c/vS6pjDCf1HcAJA1IYm+wk79LLCNbW/sArth5ewRYZgWfIUGJOPpm4885VUVvCQklgJY2OLbhTtuBJ+orG0mO555NJPPPldq45sS8Xj+uOLX8nJQ88SPWcOWCaYJjE9QsSd909RB57KoZLxWIJXyqIiYiIyBHntDnJjM4kMzpzr/tM0ySvNo915ev4ruw7VhatZX35Omr9lThj1+KMXUup+V/eyO9J/gexpHy5mki/dZmX4XYTe+pUEhwf4nHkY/SYABOugf6ngl1jBIkcLi67i/TodNKj0xmVOqrVfUEzSF5tHmtK17CqeDXfFKxgS/UGcNRhi1mPI2Y9VbzHGwXZvLJhKD9dWs0ltbV44xOJGdAPo6GBYG0tweLtBJv8gB33wIF4Ro4mYuhQPEOH4urVC0MT8kiYOS7rOP51zL+456t7KKEEd7eP8SR/SXXJcTzw3wKa7vqM4zcvwggGAYjt6SN5cDnuS2bBqLM7tvEinYAKYiIiItKpGIZBVkwWWTFZnNzjZMAqkq0rX8f8nPl8smMeW6o24/Zs4cpvAkT6YWe8mzm9x7B20Nn8qe8WpmzYDpFJ8PPXwR3TsQGJhDmbYSM7JpvsmGxO62UNj+ANeNlQvoHlxcv5ZMd8VpWswB6RS4Qjh7M2BwB4cEQPvko/m3NH9OMP5rMkrv4CPHHwq88hoUdHhiTSKdgMGyd3P5mmb5uwD7Hz+JrH2VG9A0+3Odz2/hz6FFm5tLHnMCacbNCt5kPIGAUjL+nglot0DiqIiYiISKdnGAaDkwYzOGkw1x51Lbk1uSx/60ni6l+jKhL+eJWfgP1rgg257MzdgQ941/MTehX5Oap7R7deRL7PZXcxLGUYw1KGMX3IdEobSpmfM5/i558jrn4rxXHwzfjV2NjAku09aKpdAMDXI2/nqJhsdJGXyG42w8ZpPU/j9D6n897W93j//fvpU1SI1wH/+EkSNc5szql5EoCqk+4gTr0pRQBQJoiIiEiXkx2TzZjV1syWiWeezXmDLsBtd2OLyOfeVCdTs7O4uTHAubM/5dfPL2Nz8Q+NRSQiHS05Ipmf9jmPUxdZk2EEfnYmfRL7Y9i8FCZu4vTsDH6aNJyLFjUx8c75PP3FNpr8gQ5utUjn4rA5mNZ3Gn+rOhGAlYPcbOhdRX72x/y2WzKPGpM49oUqnv1yG/5AsINbK9LxVBATERGRLidYV0fNJ58AkP2Ti7l1wq18fO4crmmAxECAEocNe+pcovvcxbz8Nzhl1jxu/O9qCqsaO7jlIrI/1R98iC8vD3tiIif8+u/89/SXme2NZVxDI37DYH1sJVG9Z1GXMJvbPvmQk+5ZyH+X7SQQNDu66SKdhun1UjvnAwBOv/ouLksahcM0WRAVyaM98mmMeY+/vreCaY98ydr8qg5urUjHUkFMRDqFRp3kFZE2qJk/H7OhAWf37niGDwcgcf0cfl2Yw8dlPv4+9v/oEdsDw1GHJ+09Inrdyxsb3ub4u+dxxwfrqKr3dXAEIrIn0zQpe+IJABIvuxRbRATGJzOZlLeGJyu9vHLcLKb2nIrNsOGI3kBUr0coj36UP77zAaff/zmffFeEaaowJlL7+ecEKiuxpySTPGYkf1y7kP/mFTAxMhvTCOBOXkBM33tZX/05Zz/0Bf/6cD2NPn0Rl/CkgpiIdKhA0OTxz7fx12V2tpbUdXRzRKSLqHrnXQDizjoLwzDA74XP7gHAfcz1nDvoZ7x5zpvcMv4WUiJSsLkqiMh8DXv2LJ5c9j7H3zOf5xfvUM8SkU6i7rPPaNq4EVtkJAkXXQTr3oWvH7XuPHc2Q3pN5p7j7+G9ae9xbt9zsRt2HDHrier9ADscs7nqlTmcP3sR32wv79hARDpY1VtvARB31tkYn90JDRX0TujP7HPf5oETHyArOgsc1URkvYwr8ylmf/k1p93/OYu3lnVsw0U6wEEVxB5++GF69uyJx+Nh3LhxLFmy5Ae3r6ys5JprriE9PR23203//v2ZM2fOQTVYRA5NZ8tfmwGLtpbTEDD4y1trCergVOQHdbYc7gj+0lLqvvoKgLizzrRWrnwBqnIhOg3GXAGA0+bkggEX8P5573PdqOuIccZg9xQSmf0cTSkPMfPDOZzxgA4C5MhR/u5f2RPWgN/xP/sZdlsDvH2NdcfE38KA01q2y47N5u+T/s5b57zFab1Ow8DAGfstkb3/zVrvbC546l1++dw3bCyq6YgwJMR19hz2V1RQs2AhAHGTBsKyZ6w7Tr8bw+HkxO4n8ta0t/jNyN/gsrlwRG8ius8s8niHnz3xBTf9bzVVDepBLeGjzQWxV199lRkzZjBz5kyWL1/OiBEjmDp1KsXFxfvc3uv1cvLJJ7N9+3beeOMNNmzYwBNPPEFmZuYhN15E2qYz5q9hGNx2zmDcNpNlOZX8Z9H2dntukVDTGXO4I1TP+QACATzDh+Pq2RP8TS29wzh2BjgjWm0f4Yjgl8N+yQc/+YArhl6B2+7GEbmdqF6PsN0+m4ueeZ9rXlzOzor6Ix+MhA3l7/7VL19B/dKl4HSSeNml8N4MaKyC9JEweeY+H9Mzrid3HXcXb5z9Bidln4RhmDjjVxDV516+qLqf0x59jT+9sYr8yoYjG4yErK6Qw9UffAA+H+6BA/GsfwjMIAw5D3oe07KN2+7m6hFX879z/seE9Alg+HGnzCWq1yxeW/MpU//9GZ9tLDlsbRTpTNpcELvvvvu48sorueKKKxg8eDCzZ88mMjKSp59+ep/bP/3005SXl/PWW28xadIkevbsyfHHH8+IESMOufEi0jadNX8z4yM4q4c1082/PtxAbrkOSkX2pbPm8JFW9d57AMSd2dw7bPl/oDoPYjJg1PT9Pi7OHceM0TN479z3OKfPOS09S6L63McnxY8x+d9z+PfcjTR4NZaKtD/l7/6VPWn1Dos752ycpV/ChvfB5oRpj4Dd+YOP7Z/Qn/tPup+Xz3iZYzOPtQpjcauI7DWLdwr/yUkP/oc75qyjst57JEKRENYVcrjq7bcBiDs6C3IXgzMKTrltn9v2iO3BYyc/xl3H3UVyRDI2dymRPZ6kMup5Lnv2c25+61vqmvyHra0inYGjLRt7vV6WLVvGTTfd1LLOZrMxZcoUFi1atM/HvPPOO0yYMIFrrrmGt99+m5SUFC6++GL+/Oc/Y7fb9/mYpqYmmpqaWn6vrq4GwOfz4fPtuwvnrvX7uz+UhWvs4Ro3tI79QOPv7Pk7ILmYMYGBLM2p4s9vrOLZy0db4wKFOH2OFXuo5PCet4eTd8cOGlevBrudiJNPxtdQg+OzezCAwMTfE8QOP9KOJFcSM8fN5KL+F/HAygf4quArXIlfYcYt49GVJ/DqspP488lDOWNY2o/+H9LnOPxiV/62r6bNm6mdPx8Mg7ifnoU55yIrnyddTzCx/4/m8y4D4gZw//H3s758PU+vfZp5ufNwxqyDmHX8Z9uHvLT6ZK4aM5nLJnQn0mUdAnV07B1JsYdeDtdv2kTjqtVgtxHrs04cBY77I8HIbj+YR1OypjCu2zgeXvUwr296HWf8MuyR23lp5c/4bGMJ/zpvKGN6JPzAu9Nx9DkOv9gPJn9/SJsKYqWlpQQCAVJTU1utT01NZf369ft8zNatW5k/fz4///nPmTNnDps3b+Y3v/kNPp+PmTP33QX6jjvu4G9/+9te6z/++GMiIyN/sI1z5849wGhCT7jGHq5xgxV7ff2B9abqrPkbMAPMaZjDN95vODf+/7Eqtw9fbS3n1mc/ZEJq+IwnFu6f43AVCjn8/XgOt6S5c0kC6vr04eMlX9O7+EOG1RZS70xkXmESwTaOzXI6p9M/qj8fNXxEAQW4u31Ejf9L/jTveO7/cBzn97SRHf3jzxPun+NwpPxtH6mvvUYcUDNkCBWf3kpUfRlVnmwWVg/EPMixlk7gBIbEDOGzxs9Y6V2FI3ozRG/mkQ2f8PjiU5iaksGEbiaO5mtlwvUzDIo9lHL42wcfIgmwZUXgZCfVnkwWlHU/4DwaznBiomN4ve51ql1lRPV8lMLiqVz8ZC0nZhicnh3E2Umn5Av3z3E4akv+/pA2FcQORjAYpFu3bjz++OPY7XZGjx5NXl4ed999937/Edx0003MmDGj5ffq6mqys7M55ZRTiI2N3edjfD4fc+fO5eSTT8bp/OGu1aEmXGMP17ihdewNDYdvbIwjkb+mafLlF18SzA2ywP4mv578Lx78pJT38txc85OJpMV6Dlt8nYE+x4q9q+cwHLm/pWma5Dz8CD6g9+WXMzK9DPvKVwBwT/kLp44656Cf+1rzWj7c/iGPrp5NXt1OPKnvU+L7nAd2nsgZPc/mjycPJiXGvdfj9DkOv9iVv+2ncdUqdq5aDcDgS44neuX/YRp2Ii9+htPSRx7y809nOvm1+Tzz3TO8ufktHNGbIHoT71UP4cstZ/K7SRPxFH3L1FPC6zMM4Zu/EKI5/NFHdFv3HQEgLXMnAJE/nc1p3Se0ud2Xei/ltq9v45PcT3CnfoA9eiOf5l9IXiCDR38+kuyEHy7MHUn6HIdf7O2dv20qiCUnJ2O32ykqKmq1vqioiLS0tH0+Jj09HafT2apb6KBBgygsLMTr9eJyufZ6jNvtxu3e+0un0+n80T/2gWwTqsI19nCNG6zY/f4Du7a/M+fvzAkzWZW3iqLGIlZ6H2Z49i9ZnVvDX99dz5PTx4TFpZPh/jkO59hDIYfbss2haFi1Cl9ODkZEBPGRa7HNudu6Y+Ql2I/+f9ht+74E5UCd0/8cTu97Ou9sfodHVs6mmELcaW/zcc1C5j59MjPGX8z0iX2w2/b+nxTun+NwjF35e2hqP/+cvN9dB34/0cdNInrzAwAYk36Hs/vR7fY6PRJ68NdJf+UXw3/Bwyse5f1t7+GMXUuN+R1/WzKSuNopJA6s5viB+/47hLpwzV8IrRyO2LqVQGERNpdBTGYDjLgYR5/jDii270tyJnHfiffx5uY3uXPJnTREbSG69/1szv8J5z/m5fFLRzOmZ+JBPffhEu6f43CMvS35+0Pa1OnR5XIxevRo5s2b17IuGAwyb948JkzYd/V50qRJbN68mWAw2LJu48aNpKen7/OfgIgcHp05fyMcEVwUdRHRzmhWlqxg8JCFOO0G89YX886q/HZ7HZGurDPn8JFS9a41JkrMwHhsi5uLYcfeAOc8BIdYDNvFaXPyk/4/4YOfvM//jfs/4l3J2JyVGCmvc/fqP3Lu7A/ZVFTTLq8l4UP521rVe++Te/VvMBsaiDrmGDKn2KG2CJL6wfE3HpbXzI7J5s7jbufNs//HCVm7Z6Wsy7yPK9+9h6tfWEKeZqSU/ejsORy7fLl1m12LLSoOTv77IT2fYRic1+88Xj3zVQYlDgJ7HZFZz1PjWsjFT3zNmyt2tkezRTpcm68CnjFjBk888QTPPfcc69at4+qrr6auro4rrrgCgMsuu6zVYINXX3015eXlXHfddWzcuJH333+f22+/nWuuuab9ohCRA9KZ8zfZnszfJ1g77/d3vMbp4wsB+Os7aymtbfqhh4qEjc6cw4eb6fNRPed9AOJi1gAGnH4PTL4FDkMvUpfdxc8G/oy5P/2AP4y+AafhxhG1mS2u2zjj8eeZ9clGvP7gjz+RSLNwzt89lT//Avk33AB+P7FnnEH2jPOwffcKYMA5D4Pz8A6V0DehLw9Ovp9XzniFMd3GYhgB3N0+YmHtTCY/8CoPzd9Eo08zzcreOmsOB+vrifn2WwDiejbA5JkQndIuz90rrhcvnP4CFw64EAwTT9rbkPAx17+6kns+2kAwGD7j/UpoavMYYhdeeCElJSXceuutFBYWMnLkSD788MOWAQZzcnKw2XbX2bKzs/noo4+4/vrrGT58OJmZmVx33XX8+c9/br8oROSAdPb8PSHrBH457Jc8+e2TfFX1KH0z/8DmvBj++Poqnpx+9D4vUxIJJ509hw+nugUfEyivwO4OEJUJ/PQ/MPjsw/66HoeHy4dO59isY/jtvN+TW7sdV/ZjPLw8h/e/PZV/njPksLdBQkM45y9YYwCWPvggpY88CkDCBeeSekZvjA+utzYYfzV0H3fE2jMkeQiPTX6U29++nQ+8H1EfsRNb9iweWPodry6dyl/PGsrkQak//kQSNjprDtfOm4fN68MZ7Sdi+BAYfXm7Pr/L7uL/xv0fSZ4kHln1CO6UTzDs9Tz06ZlsLa3l3p+OJMLVPr20RY60gxpU/9prr+Xaa6/d530LFizYa92ECRNYvHjxwbyUiLSzzp6/1468ljWla1hcsJj41Odwl1zJpxtKuOfjDfz51IFHrB0inVVny+FgfT0N336LZ9t2GpYvx+doh/l6An6ozIGKbVC2Bcq3UrFwO+AgtlcQ4/K3oMfEQ3+dNugT34c3zn6VmV/N5MPtH+JJfZ/c6h1c+NT5TE51MTVoEn4jeEhbdbb8BfBu3da++bsfVW+/Q+VrrwGQPDGGZONhjA+a70zoBSfdfNhee38Mw+Ao11FcecqV/PObf/J53ue4Uz+grH4tV758PucMOYrbpg0lyn3Y5yGTLqIz5nDNa/8BrN5hxln/brchBPZkGAZXj7yaWHcsdy65E1fiV9gdjcz59ifsrGjgqelH73PiGZHOLiT+uzf5A7y4OIeNRQand3RjROSQ2G127jruLi5870IK6nYy4qgPWfL1WTy6YAsD02I4Z2RmRzdRRPbgXbOIvOnX0h3Imz37ML6S9ZUl7rp7jngxbJdIZyR3HXcXo1JHcdeSuyB2DXZ3IfPzLuHK55fz4MWjiI/s2mM7Sfip+Nu1dF+ee5jzdxeTtDFVJHRvHh80cwwMOhNGXgKuqCPw+vvWLbIbD09+mLe3vM2dS/5FXWQOkb0e4L1tZ7PqoUoevngUg9L3PcOfSEfy7cylYeUGAKLPPBMyjjqsr/fzQT8nzh3HzV/cDLHLiXU0sjrnIi54bBEv/HIcmfERh/X1RdpbSBTE3l9dwN/fX0+Uw8aNTX7iw3CWBZFQkuBJ4L4T7uOyDy5jXfUiJo7J5qulo/jTG6vpnRzNsKy4jm6iiDQzjACumEOf5WfvJ7aB3QUOt3VrdxMxdjyeE85p/9dqS7MMg4sGXsTQpKH8YeEfKKCAyJ6P8NXOn3P2Qw08ftloBqbpwFm6DofLe3hy+HsMu0nysHpij5sAA8+AAadDbPphf90DZRgG0/pOY3z6eP761V/5Mv9LPOn/I6+8gGkP1zLzrOFcNDY7LGa+lq4j8O1HRCR7MW12HD+57Yi85pm9zyTGGcMfFv6BpsjviO/1LNu2X8pPH/2KF345jt4p0UekHSLtISQKYmePyOD+Tzaxo7ye/yzO4XdTBnR0k0TkEA1NHspfxv2Fvy36G9/WvcbQgW7WrB/CVc8v5e1rJ9Et5vAOuisiB8Y9bDw9npvF0qVLGTNmDI62XHJl2ADDGhTfMJp/tkFCD4jvcVgGy28vw1KG8dqZr3H9gutZWrSUyOznKCis5LxHmrj3pyM4bVjnOdAX+SFJf7+H7Qveb3v+tpXNAZmjISL+8L1GO0iLSuPRKY/yxLdP8OCKB3ElLsLvLuL/3vk5i7aWcfu5Q4nx6OS7dA6e035J1oABLP30I7I8R+6E8fHZxzN7ymx+O/+31LKFhD5PUrD1ci54bBHP/2KcelRKlxESBTGH3cbvTurDH974lie/2M70Sb2Ji9COSqSrO7//+eTX5vPEt0+QY7xAZuYV5OX15+oXlvPSleNwOzSAp0iH88Ri9juFok1+zH6nQBj10o73xPPwCQ/z6//9mhW+FXjS38RbVsbVL/q49sT+XH9yf00GIp1f+giK4vLCLn9/iGEYXDX8KvrG9+Wmz2+iPmorkT0f5v31l/Htg5U8dPEohmaqt7p0Dmb2eIqSy4/4645JG8Mzpz7Dr+b+ivLGncT3eZyybZdz4WOLePb/jWVU94Qj3iaRtrL9+CZdwxnD0kiLMKlu9PPU51s7ujki0k5+e9RvOb//+ZiY1Mf9h5j4rSzbUcEtb63BNDXVs4h0LKfdyXmR53H1sKsBcCV9hifzZR5asI5fPvcNVfW+Dm6hiBysk7qfxIunv0hWdBY2VzlRPR9hp3cJ5z36FS8s3qHvIRL2BiYO5D+n/YeMqAz89mLiez9ObTCPS578mq82l3Z080R+VMgUxOw2g9OzgwA89cU2yuu8HdwiEWkPhmFw87ibObnHyfhNP67M/+CIyOW1pTt5+svtHd08EREMw+DKYVdy+zG347Q5ccZ+S1SPJ1iweRtnPfQF3+VXd3QTReQg9U3oy8tnvMy4tHFg8xKR9QIkzOHmt1fy25dXUNOooreEtx6xPfjPaf+hb3xf/LZKYns/TqNtG5c/+w0ffFvQ0c0T+UEhUxADGJ5oMjg9hjpvgMcWbuno5ohIO7Hb7Nx57J2MSx+HN9hIQu//YHMV84/3vmP2wi06QysincJZfc7isZMfI9YViy0ih5g+j7CzYR3nPfolb67Y2dHNE5GDFO+JZ/bJs/n5oJ8D4E5eQFSvh5iz8RvOevAL1uRVdXALRTpWalQqz576LMOThxMw6ojp9RQB9waufnE5sz7ZSDCo7+rSOYVUQcww4PopfQF4btF2iqsbO7hFItJeXHYX9594P0OShtAYrCGl33MYjkru/GA9f3v3O+1oRaRTODrtaF44/QWyY7Ix7eVE9XiMYNzHXP/qcma+vQavP9jRTRSRg+CwObhx7I3ce/y9JHoSsbkLier5MPm2/3Le7IW6hFLCXpw7jidOeYIJ6RMI0kRU92dxxC1j1icbufrFZdQ2Hf7ZbEXaKmQKYr6A1V35+H7JjOoeT6MvyCML1EtMJJREOaN4ZMoj9IztSX2wjIxBz2Dz5PLsV9v57SsraPIHOrqJIiL0iuvFa2e+xhm9zwAjiDvlEyJ6PMF/vlnFRU8spkgn7ES6rFN6nsJb57zFab1OA8PEnbwQR/Ysbv3ofa55ablOyEtYi3RG8tDkhzilxymYBIjIeJ3IzFf5aN0OfvLIV+SU1Xd0E0VaCYmCWL2vnl988gsWNC4A4IZTBgDw0tc55FU2dGDLRKS9JXoSefzkx8mMzqTaX0RMr9l4khfy/uo8pj+9hGqN5SEinUC0K5o7j72T24+5nShnFI7I7UT3nsWq8oWc8cDnvL0yT71JRLqoBE8Cdx13F/efeD/JEcnY3SVE9pjNvKInOem+j3j8sy3qDSphy2V3cddxd3HtyGuxG3bssSuJ7fMAm6rXcPbDX/ClBtuXTiQkCmJzd8xlTdkaPmn8hNu/uZ2xveOZ0DsJbyDIQ/M3d3TzRKSdpUen8+qZr3Jyj5MJEsCZ8gHRPZ7h65ztXDB7kXpfiEincVafs3j9zNcZnjwc7I1EZL1EbcyL/P6Nz7jw8cWsK9CA+yJd1UndT+Ktc97i7D5nYxgmrqQvMLPu4q7PX2Pq/Qv5bGNJRzdRpEPYbXZ+NeJXPHvqs2RGZ2I6rCEE6iM+5LKnF/PIgs34AioaS8cLiYLYOX3P4U+j/4SBwX83/5fff/p7rp2cDcDrS3PZUVbXwS0UkfYW547j3uPv5a8T/kqEIwIjchPRve9nU+0Szn34Sz75rki9L0SkU8iOzebZ057lymFXYmDgjF9G7m/hgQAA4g5JREFUVJ+7WNXwNGc++ja3vr2GynrNji3SFcW54/jnMf/kkcmPkBWdhc1ZTUTWSxR6HmT6C+/zq+eXkluuy8QkPI3sNpLXz3qd03udbg0h0G0uruzHuPuTxZx2/+d8vklFY+lYIVEQA/jZgJ9xUeRFuO1uFu5cyEPrbmDSABf+oMn98zZ1dPNE5DAwDIOf9P8Jr5z5CgMTB4K9jsjs5yjzvMKVLy7g8me+YXNxbUc3U0QEp83J70b9jmdOfYaRKSMxbH5cCYuJ6H0Pr22/ixNmvcpLX+fg1xlzkS7p2KxjefOcN7l6xNW4bC4c0ZuI6j2LT4v/w+R/z+VPb6xibb5mo5TwE+OKaRlCINIRaQ0h0Pdeco0Xuey5j7nqP0s1tph0mJApiAEMdg1m9kmziXfHs6ZsDYVR92C4Svjf8jz+/MZqKup09lUkFPWO682Lp7/IJYMuAcCVuJiovneyuPpxTnv4f9z23ncaW0xEOoXRqaP5z2n/4empTzMxYyKGEcQZvwJ/xt38fcmfmDjrKe79eIPGQBXpgjwOD78Z+RvePOdNjsk8BsMI4E7+FGePe3hz60uc+fBH/HT2V7y3Ol+Xi0lYMQyDs/qcxRtnvcHo1NFg+HElLiKq790sLH+UKQ++yb0fb6Deq5ko5cgKqYIYwIiUETx/2vNkRmdS3JBPUt/HsUXs4NWluZx07wJe/SaHYFCXUYmEGpfdxZ/H/pnHTn6MoUlDm3tffI271z28sO02TnjgOV79Rr0vRKTjGYbB0WlH89jJj/HKGa9wUvZkDMPEGbuWhuQHeGrbbzlh9h1c9sznfLy2UP+3RLqY7rHdeWTyI8w6YRZpkWnYnJV4UucQ1fd2vvU+ynVv/pdJ/5rHA/M26XJKCSvZsdk8M/UZnjrlKY5OOxrDCOBKWIKr5108se4Ojv33a9zz0Qb1GJMjxtHRDTgcesb15IXTX+Daedeytmwt0T0fw+0dTnnBWP78Xy+vfpPLbdOGMTgjtqObKiLtbGLGRCakT2Bp0VKeXfssn+38DGfst/hiv+Wv37zDXV+O49wBJzN93FCyEyM7urkiEuaGJA/h/pNmsaVyC0+veZY5W+eApwB7+pssD3zA1x+PJua94zhnyEhOGtiNo3sm4nKE3PlMkZBjGAaTe0xmQsYE3t/2Pq9veJ115etwxq3EGbeS2qYUHlw2ln9/OowBydmcMjiVKYNTGZYZh2EYHd18kcPGMAzGpo9lbPpYlhct57FVj/FVwVc445fhZRlPb8vk8dVDGZZwDNOPHsspg1PxOO0d3WwJUSFZEANIjkjm6alPc8uXt/Dxjo9pdK0kssdKzKZ0vi2byFkPl3LZ+L5ceWxvMuIjOrq5ItKOdvW+ODrtaDZVbGo5yHREbcMbtY1Xil7lxVd60t0zlkuGnc4FR43A7dCOVkQ6Tp/4PvzzmH/wp6Nv4K3Nb/HCdy9TWJ+HK/FLmviSl3dm8sKmHji8vRmTNopTBw3ghAEppMfpO4xIZxbpjOSn/X/KT/v/lLWla3l94+vM2TaHBkqwp74Pqe+T05TCY2v78siSviTZBzNlYA+O7ZfCiOw40mI9KpBJyBqVOorHTnmM1SWrmb3qMb7I+wJ7RB72iDw28hE3Lk7l5gXDOSl7MucPG8uYnokqjkm7CtmCGFg7oHtPuJfNFZt5af1LvLvlXRrdBXgy/kvQ/wEvbjya/6wYxNHpIzh/VE9OHZpGtDuk3xKRsNMvoR93HPtPrhv1W/678U3e2fQx+Q2bcURtI59t3PXdq9y1MpPe0cM5OmMIp/UfxdBu/XHb3R3ddBEJQ3HuOKYPmc6lgy/lq/yveGndy3yR93nLAQJ8xXJeYOnqeP62uAcJ9j70SejDUWn9GZvVh8EZsSRF6/+XSGc0JHkIQ5KHcMOYG5izbQ5vb3mbNSVrwF2C3V0CiYuoMw3eLMzm9a29CTZkE2/vy8iMbIZnxTM8K47hWfEkRrk6OhSRdjU8ZTiPTHmYsoYyPs39lPc2f8yKkm/AU4Tpmcu8mrnM/SwSPu5JVuQQjskaw7Qh4xiQHNPRTZcuLiyqP30T+nLrhFu5btR1vLnpTV5e/zL5dfm4kxdC8kLWBJ2s+roHty7sw9i0MVw66liO65eO065LEkRCRVpUGtccdTXXHHU1ebV5/G/9R7y98SOKvOvAlcdWbx5bt3/Aq9sB00aCK4OBiQMYmzGU4SnDGZI8hChnVEeHISJhwmbYOCbzGI7JPIaiuiKWFy9nedEKvs5fxvaazdicldjiKqllFat8sCoXntnuIujthttMI9XTnV7xvRmW0o/Rmf0YmBZPXISzo8MSESDaFc0FAy7gggEXUO2t5puCb1hUsIhF+YvJqdmBPTIHe2QOAE3AIl88X3yXTWBZd4KNmSS40hjULZtBaXEMTIthYFosfbpF7bO3u2ma6mEmXUZSRBLn9z+f8/ufT7W3mk9zFvDqd++ztmIpOOoh+jvy+Y7X8l/n1Z0ObN7uxAbS+fiDnYzLGszkPsPIjEvu6DCkCwmLgtguce44Lh96OZcMvoQFuQuYs20OSwqWUuWtwBG1GaI2s8z3EUsXOWBhOkmu7gxI7MvE7kOZ3Gc4WTHp2qGIhIDM6Ex+O+b/8dsx/4/iulKeWfEhi3JXkVO7Ba8tD8NRT4VvJ4uKdrKoaF7zowwyI3syOn0EI7sNZ0jSEHrG9iTSqXHIROTwSo1K5bRep3Far//P3n3Hx1Hf+R9/zfZdrXq3LHdswDYGbGxMLwYTEkoupJJASI5cEkjBvxzlAiFckoOEC0eOkJBGcpcGCRc6ARzTwTRjMDbYuMlFva+2t/n9MauVhGUj2bJV9v18POYxq9mZ3e9Xu5+dmc98v9/5EADhRJi3295m9e7Xeb1xAzt7ttOVbAR7HLt3N0l2U8/r1AfghQCYW2yk46U401WUOGuo9lczpbCSWSWTOLKyhnmVkynw6LdMZDQUuAo4c+qZnDn1TAAag4283Pgyb7W+xVst69janUmAO7twFrwNWEmytaadN+qLSNcVk44XY6QKyPcl8Xkj2J0hTFuQmBkglAxQ469hSfVillQvYXHVYko8JaNYY5GhKXAVcMGs87lg1vkkUgneaX+HJ7e9zIu7XmNHaANJWxDTs41utvFc54s81wm3vg22dD6FjslM9k9hetFkjqyYwuySWqr91VT6KnHadXFI+uRUQqyXw+Zg2dRlLJu6DNM02da9jdeaXmPl9pd4q3UNMVsAPLvoYBeru15kdRf8eB3YTC8FzhJ8Ljd+lxuv04XT5sRpc+J1eCn3lVOVV0Wlr9Ka8iop95bjdXiVSBMZoyryyrjmpM8CnwWgri3IY+9u4qltb/Fu+yZSzl3YvTuxObupD2+nfut2Htr6QHb7Mk8F04umMq1gGlMLrHm1v5qqvCrynfmK/XEomozisruwGWolLGOTz+ljSfUSllQvyS5LpBPsCuzinbbNvFa/kY3tW2gI7yCQbCBtxLC7W0nTShtv0xaFt6NAM/Cutb2R9uI0/HjseeQ5/RS4/BR58in3FVLhL6LUW0yRp4gidxHF7mKK3EXk2fMwTd25W2QkVfur+ehhH+Wjh30UgFAixIa2DaxrW8e61nW817GZpnAjKVIYrnZsrnbINGCPZiaSA19zV89OdvXs5L737gOgxDGNmfkL8HX5yKur4bjawyn0+A9ZHUWGy2l3sqBiAQsqFvCvx/8LpmnyXuc2HnznBZ7ZuJoeZzfdyXpMRydpWw+d6XfpDLzL2wF4aGf/VzLwO4qp9E1iWkEts0qmUOOvYXL+ZCb5J1HmLdOwKTkmJxNi/RmGwcyimcwsmsmnDv8UpmmyvbuOZ+vWsXrXBt7r2EJ7fCems5W0EaErWU9XEhjGnWBthg2P3YPH4cHr8OJ1ePHYrQEyk+kkKTNFKp0iZaZIppM47U4qvBWU+8op95VnH5d6SvG7/OQ58vA5fficPjx2z0H73+yvRDpBR6SDSDJCtb96nz8qpmnSGGrkrda3WNe6zvqxK1vAUeVHUe4rH9EyRZNRoskokWSEcDJMOBEe8DiWimE37DhsDuw2Ow7DmjttTgrdhZR4SijxlOB3+vdIcvTEe2gKNdEUaqIx1EhbpI2uWBddsS66Y93W42gX4WSYMm8ZVXlVVOdVU51XnX1sYtIT7yGYCFrzeDD7+NtLvq2rGYfItDI/Xz15IV89eSGxZIr19QHW7Ojgpe3beav1bULGNuzeXdg9DRj2CG3RFtqaWnit6bU9Xsvn8GU/46q8Koo9xfgcVuzmOfPwOXy4DTe7krvY2bOTCn/FoN8vGVwynaQ13EpjqJGmUBMF7gLmlc6jyFM07Neq667j6V1P8/Sup3mz5U3yXfnML5/PgvIFLChfwFFlR+F3+bPvuzOwk/c632NT5ybe63yP5lAzbocbn8OX/Z33Oa3HC8oXsHza8hGuvchATpuTGUUzmFE0g4/M6vu+maZJc7iZDa1bWNOwkY3t22gONdMZ6yCc6iRpdGPYkpi2CHEixNOtBGLQGAN6Pvh97Tj4yd9+SrmvlHJfGSWeEko9pRR7rKRZkbuIQnehlUjzFJPnzMNhy/nDT5Ehy3PmZe/I1yuVTtEaaaU+WG9NPfXs7G4mlfQQj/sIhT10BV20dDpp6IS0sxGHbwv2vK3YPU10JOvo6KwD4NmX/gyAkcrHY1RQ5Kym0ltNibeI8rwCKv3FTCooZnJBCfkeH+2Rdnb37KYh1EBDsIHdPbtpDDVS6C5kYeVCFlUu4tjKY/e7FVoilcBhc+hYSPbJMAzmlMzkqiVTmNNexLnnnovT6WRnZwertr7Na/Xvsr1rF62RZkLpNmyObgxnF4YtSTDZQTDQwdbAelbt3vO13XYvRe4iyrylFHuKKPGUUOgupMBVsMe8d5/msDmy55G9DWbUi2R80BHJ+xiGwYyi6cw4ejqXHX0BAOm0yYbGDh7ftJ63mxrY1tpNYyCEYaQgMxm2GIazG7e7B68viM3RTYwOkmaMtJm2ki7JoWfRtndvH9J6dsOO1+GFJNz54J247W5cdhcumwuX3YXb7s4uc9vduB3u7DKPw4PXnknQOfoSdr3PZyeHG5fNRTgZpiPaQUekg46YNe+MddIeaac92p6dd8e6+/6fGEzyT2JawTSmFVotaGr8NWzv3s5brW/xZsubtEZaB63bpLxJHFV+FEeVH8X0wunEU3ErqZXKJLXiYdZF1rHh9Q2EUqEBCaRgIkgkGckmwZJmctD32B8um4sSr5UciyVjNIWbCCVCQ96+K9bFlq4tw3rPrx3zNUq9pcMtqhwgt8POwqnFLJxazJdOmYlpnsn2thCv7+hk7c4u1jXUs6WzjpSjBZurrW9ydGM4rJjf2r2Vrd1bP/C9fvHwLwDrpLbYXUyxx5oKXAXku/IHTH6nH6/Di9Pm7Nvx2p3ZHbDT7sRls1qwuuzWbwFAd6ybzlgnXdGubMK2J95DubecKQVTqM2vpcJXMeyWUaZp0h3rJhAPZA8SRvJANpaKsbFjI+ta1/Fu+7vUB+tpDDXSEm4hZab2WL/GX8O8snnMK53H3DKra6uJSdpMkzJTpNPWvD3azrO7n+XpnU9TF6gb8BqBeIAX61/kxfoXAeu3bFbxLFw2F1u6thBLxYZc/vBhYSXEZNQYhpFNyp857aQ9nk+n02zvaOetxl3UdbbSEOiiOdhFWyhAZzRAINZDyghj2PtNjhCGPYRhS5AiSVu0mbZoM+92DLFMGHv8brnsLvxOP36Xn3xn5rfO5cfv9OO0OTEMA7thxzAMbIYNGzbsNnvfhSzDPuDv3t/G/icndpsd0zSt3wEzTTKdJG2mSZtpnHYnHrt1HORz+PA6+y5g2m26o5mMLXabPRvXCysX7nPdVNqkORClvitCfWeELe2NvN3+BjvCb9IRryPtbMewhzHtPUToIZLaSmMQCAKDH6IPqjHUyMaOjfzx3T8CMKNwBosqF3FY8WHZ/W8yncxO8XSczmindW7RbwolQpR4SphbOpf5ZfOZWzaXeWXz1M1ThmRKcQmXLTqVyxadml0WiafY0hJkY1OAt5vq2di6g93BetpjTeDowObswObqsBJmRopYKkJzOEJzuPGAyuJz+KjwVVDmLRvQyMXn9A04Tu/dHzoMKxFsYO3neh/bDfvAc3i7B5fdhd2c2PumUCLEe53vcUzFMQf1fZQQGwKbzWB+TSnza/oCKxBNsL6+m7d3d7Ouvpt3GgLsaAsRN/tfUDXBFsOwxXE6ElQV2qkqtlNRYKM0HyoK3FQX5FFZkIfL3ncwF01GaY200hpupSXckn3cHm0nlAgRSoSIJCMApMwUwUQQgGAoeGj/MftgN+y47C4iyUj26tWLDS/udd05JXNYUL6AeCrOurZ1bOncYl15CjXweN3j+36z94Zert7WennOvGwLjt4WHS67C9M0SZiJbIu9VDpFPBWnO95Ne6SdcDJMPB3Ptgbrr9BdSJXPOjgp95VT7C6m0F2YvUpe6C7E6/DSFmmjMdhIY6gx27KlKdSEzbBR4CrIngD0Jj78Lr9ah40RhmEwo9zPjHI/n1hUC8wnnkzzXnOP9XtQ382GhgBbGoL0xMMYzm5sji5r7uzCsEfAFsPrSuL1JHE5k9jsMSKxLlKOKNFUhEQ6QUukhZZIy6jU0WVzUZtfS21BLYWuQuw2OzbDht3om8dTcVojrbRF2rLzZLov6ewwHFYrEW8pJV6rtYjP4etL1GVOgu3Y2RzbTHhzGI/TM+DkOJQI8Xbb27zd+jYbOzcOeP3+HDZHNu7aIm3UBeqyvzlP1D0x5Ho7DAfHVR3H6VNO5+Sak+mOdfNm65vZ1qv1wXo2d27Oru91eDms6DBml8xmdvFsavw1JFIJwkmr5Wlv69NIMsL8svn7/4GIHGQ2m42ZZeXMLBu8VbZpmrQF4zR2R2joitLQFbGm7gg7O7uo72wgRJiUEcBmD2E4ghiOnoEJNHsoM7cSySYm8XSceDp+KKu63x796KNMKZgy2sUQ2S92m8GkIi+TirwcNw2gBlhEIpHgscce45xzPkR9sJu1jVt5t20727t20BxuIpgIEk4GiaVDJM0w2KIYtjhm0k86UUw6UYyZKMk8LsLm6Mbu244jbzs2dxPburexrXvbfpW5I9rB8/XP83z989llk/ImMTl/Mgb9LrhlHtqwZY8h+h9nuOwu5pfN57yZ5+3vv08mAK/LzvzJhcyfXMjHqQWOByCRSrOrI8z2thDb20JsbQ1S19lOfaCVpmA7KSOIYQ9hc4TAFsnsxyKZKYxhi2CzxzFsaQzSmEYKk74LteFkmLpA3R4XXUeSGzd3PngnRe4iClwFFLgLKHAV4HP6rEYx/RrJ9CbfBpvbDBvRZLTvODbRdxwbTAQJJazGJ6FEKPu32+6mxl9DTX4Nk/2TmeyfTE1+DeXe8ux5dNJMZnvEpdPpAb0p+l9siiQjbOrYxIb2DWxo28CG9g1s796OiclTH39qRHuOvd9+JcTuvPNObr31VpqamliwYAF33HEHixcv/sDt7rnnHj796U9zwQUX8MADD+zPW48ZBR4nJ8ws44SZfXexiCVTbG8Lsbk5yJYWa9rc0kNde5h4NM3OKOxsfv8rxXDZE9SWeJlelse0Ug9Ty4qYXDSdOeVeaoq9+Fx7fkxpM00kGSGUCBGIBFj17CoWL11M2pYmloqRSCWIpWLE03FiyZj1OBUnmooST8WJJCPEUrFsK6pIyvri9z4fTUYHrB9LxfA5fRS7i7Oto/pPpZ5SSr2l2XmhuxADg/ZoO3XddewI7LB+ELrrqA/VU+OvYUH5Ao4uP5q5ZXOtVm79hBIh1retZ13rOt5qfYvGUGO2RVtvazaXzUXL7haOnHUkhZ7CAQmkfFc+PofPWrdfd9Xeq8z7K5KMZFvJtUfbcdld1hU6X9WQm8XOLp693+8/UhTDI8flsDGvppB5NYV8KrPMNE2aAlE2NwfZ3BJkS0sPm5uDbGsL0RGKEwO6Bnktuz1JdUmS6uIUJQVxCvxx8jwJXK4Yhj1KNBWiJ95DT7yHeCpOIp2wplQi+ziesk4yk+kk8VR8QAsql81Fkadv/J8iTxF5zjxawi3s6tlFfU898XR8yK3a3s/r8BJJRkiayWEl9R597dEPXKfEU8L8svnMK5uXHaetOq+aMm/ZgBZtgXgguyNd37ae9W3raQ43D0jo2QyblRx3eDiu0kqCnVRzEvmuvlt3T86fzNyyuVx8xMUAtEXaeKv1LUzTZHbxbCbnTx61McYUv3IoGYZBeb6b8nw3R00e+FzvCfWHPvRJIimD1p4YrT0xWnqitAfjtIditAfjtPU+DoVpCwWIJBKZFvbJfq3tkxj2KIYtimGPWiff9giGLQZGCpfdwO20fnNdDgOXA5x2cNhNHHYTm83EbjOx2dIYhjWlsQ7EE+lEdv7+34Hex4l0IpvM7j02MrHGR/M4RnZ4CsWwjCU2m8GM0nJmlJbTmyh4v3TapCuSoKUnSlN3lOZAlKbuGE2BCE3dUZoCMVoCUdqbjyIGYA/h8NZh923HcHWAaQfTBqYdE1vmbztmKg8j5SfPUUShq9g6p/AV4XB1ELXXEUhvoy2xhfb47uyF8uHqmdEzogkxxe/E4bTbshe636+3ZeWujjC7OiPZi0H1mamhK0I0kR7kVU0gDbYkhr0HmzOA4ejB6wni9YZwuoI4nUkc9jQORwq7LY1hJDM9ztLYDOs8H6y5iUkynSSWimWn/heJY8SyjSxGw4b2Dfu9rcvmyibu2iJtg/b6qM6rpiXcMrYSYvfeey8rVqzgrrvuYsmSJdx+++0sX76cTZs2UVFRsdft6urq+Na3vsXJJ598QAUey9wOO4dXFXB4VcGA5em0SWMgSl0m+1zXFqKu3Xq8qyNCPJVma2uIra2Dd7sryXMxudjL5GIvtSU+ppbkMbXUx5QSH5OKyil2FlNlr2Je2TyczoPTkmh/b9lc5i2jzFvGoqpFw9ouz5m3x4DB79d7IH7u0ecetHq/n9fhtTLh/ppD8n4Hg2L44DMMg+pCL9WFXk6ZPfAHvCscZ1tbiO2tIba1BdnaEmTd9iY6E3YiCQe7Wx3sboXsCLn9lPldTC72UVviY1axl5pSK2leW+ylpsiH17Vn0+lUOkUincDEzI5duDfJdJLGUCO7AtaYZsFEMNudKNvd0EzjsDko95Zn47vcW06ptxSX3UU8Facj2rFHV+poMko8HR+QvIsmouys30l5ZTlJM9mX4EsncBgOjiw9kqPKj2J+2Xxq/DVD+g0qcBWwdNJSlk5a+oHrDkeZt4wzp5w5oq+5PxS/MhYZhkGh10mh18msig8emDsUS9IWjGUTaK2Zx+2hOB3BOB0hK4HWEYrTFUlgmtZd9YYwpNkAboeNMr+bUr+LsjwXpX43xT4nRT4XRT4nRV4XxT4nhT4nJXkuSvJcuB3W76hpmtkhGgpdhcP/p+yFYljGI5vNyMbI+89z+kuk0rQFY7QEYrRkkuNtPXE6w71Tgq6wFeOdoTihuHUCHAM6AGvAmCDgAmZnJsAWxe7ZjeGwzpUMTPLcDgo8Dgq8TvweGz6Xgcdt4nWauJwmbmcapyPNURVHjNj/QfGbO/q3rBzsbNQ0TTrDCRq6IrT2xGgORGkOxGjuidKSedwWLKQtGCMRNukJDG0f5rQbVOR7KM93U53vpqLATUWhh5I8F2V+FyV5bop8NvxesBHl0X88ytFLjyacCtMd7yYQC9Ad7842bult2NJ7wTyWimUvpvd2XU6kEqTMVLYBSf/xcL0OL3muPPxOP3lOa+53+vE5fUSSEXb37O4byzAz9fZkA2uIhN5hDAwMYqlYNvEVT8eJx/paipd6SplXZg13Mrd0LkeWHkmZt2yP/9FIG3ZC7LbbbuPyyy/nsssuA+Cuu+7i0Ucf5e677+baa68ddJtUKsXFF1/MTTfdxPPPP09XV9cBFXq8sdkMaoq81BR5OXHWwA81lTZp6IpQ1x7KJMzC7OwIU98VYXdnmJ5oko6QteNYt7t7j9d22q3XdidtvBDfQE2xj0mZ97KC2JM9uDsQGthy4lAMj64in4tjp7g4dkox0JvYredDHzqbjki677egPcSOtjC7OsPs6ggTiCZpy7S0eHNX16Cv3Zs8ry32WUn0Et+Avz8ojh02h9VdMr+WEzhhv+qXbTWZV/WB62aT2qccuqT2eKf4lYkgz+0gz+1gaumeif/3S6bSdEcS2ZPp3hPpjnCc7nCC7og1dfV73BmOE46niCXT2av5Qy6by05J5qSjxOekJM/N1ef4qCwYmbFaFMMykTnttuwFwaGIJlJ0huO0ZxLhVjI8TiCSIBBNEIgkM/ME3ZFyOsPWcVAybdLF4K3t3++cuRWcN+sAKtWP4ld6GUZfknhfTNMkEEnSGowNuBDUmzBu7elNIEfpDCdIpMwh77ccNoM8RyW1u8NUFngozy+kItOie3q+O3NByE2Z34XffWhuVNF7Man35nTv701hmiaJdGLAze0iyQhl3jIqfZWjknMYVkIsHo+zZs0arrvuuuwym83GsmXLWL169V63+/d//3cqKir44he/yPPPP7/X9XrFYjFisb4BiwOBAGCdPCUSiUG36V2+t+fHsqp8J1X5RRw/rWiP5wKRBPWZMTt2dUXY2RFhZ0c423wzkTKpaw8DNjatqd9je8OAynw3tSU+aou9TMnMa0u8TC3xUew7sC6Eo2k8f+YHqn/dh1P/QxHDuRa/B6q3zslkklKfk1JfAQtr97z62h1JsLszwq7OCLszTbd3d1lj+tR3RQnG9p08B6uFWU2Rl8lFXmqKPdbjbAszLy7Hoe0CqM99eDGsffDYpLof/LoXuG0UuD1MLR5618VwPElHKEF7KE5b0Gpt1h60Wpx1RRJ0h615V795Mm0SiqcIdUTY1dF3MvKNM2aQSPQlxLQPnjhU99Gtux0o8zko8zmAoQ09kk6bdEYStPXEaA1a8d0ajGXjPZtYC1rJtSKfY486ah88cYyHuvucMLXYzdRi9z7XiyXTtAd7k2W9ibO+fVhHOGElj8NxeqJJkmmT7rhBd0OA9Q2Bfb621WLaRZnfTWWBm8oCD5X5bqoKPVQVuKkqsOZu54Ff/HHgANPqpZJiz26QBgZ59jzy7HnQ71+STA7tJnj7uw/ee3mHoa2tjVQqRWVl5YDllZWVbNy4cdBtXnjhBX7zm9/w5ptvDvl9br75Zm666aY9lj/55JP4fPv+sVy5cuWQ32e8qQAqDFhUCpRC2oSuOLRHDTpj0BmHzljvY2seTxs0BWI0BWK8Vte5x2t67SZlHijzmJRn5iVuKHKZFLnBOTpD5AzLRP7MP8jKlSsJh4d+99JDEcOK3/0znLpPAibZYFEJkLnpUjgJHTHrN6A9Bh3RzDzzdyxlZFuYvTVIwszApNgNpW7rN6HcM3A+SG/MEZPrn/tQY1j74LFNdR/b8jLTFLAOwN1Acd/zpgmRFAQTEEpCMGEQTEAwCa89/xSDXS/QPnjiUN3HLxfWbQJqADyZKXNjdtOENHU89ljdoNtqHzxxTMS6F2emOS6sL3q/fVYybe2vAgkIxI3MHAIJg0AcehIGPQnoSVj5AKvFtHURfV/ynSbFLih2W+cFxW6TQqe1PN8F+U7w2q1GN6NtuPvgvTmod5ns6enhc5/7HL/61a8oKxt6/8/rrruOFStWZP8OBALU1tZy9tlnU1AweL/1RCLBypUrOeuss3Ku683e6m6aJh3hRLY12a4Oq3XJrs4wO9rDNAViRFIGu0KwKzT4t7o0z8WkIg/VhR4mF1kty3pbmk0q8uI+xC1K+tNnbtU9Ehl6V5Dh2p8YVvwOz6Gou2lag+Farcki1HdF2d0ZyXTNtlqdRhJpOjIJtM2DXGSqLvQwrdTH1FKfNS+xptoSL579vJqkz/3gxrD2wYeG6p57ddc+eOJQ3VV37YPHN9V9JWedtWyfdQ/Hk5nW0vHMeGfW1BSIZsc+awpEiSTS2UTazr3kBsC6uU1ZnovKAjeTCq0hmqzJy6RCDzVFHvI9B++zGOn4HVZCrKysDLvdTnPzwFslNjc3U1W153gxW7dupa6ujvPO67uzRzpt3TXB4XCwadMmZs6cucd2brcbt3vPJoVOp/MDv+hDWWeiGqzuVS4XVUV5HDfI+tFEip0dYeraQuxoD1PXHsqOX9Z754z2TF/+t+v3PEM2DKgu8FgD/WcG+Z9SmmedKJf6KPQemu6Yuf6ZD7V5KRyaGFb87p+DXfcKl4uKwjyOnrrnc6Zp0hqMsbPdSpbv6Aizoz1EXXuY7a1BAtEkjd1RGrujrN7Wscf2VQWeTKIsj5kVecws9zOrws/kYh922wf/BuT65z7UGNY+eGxT3XOv7toHTxyqe+7WXfvgiUF133vdC51OCvO8zNj7fR+si+fhRDYP0NAVoaHbupDe2hPLdFGO0RNNEk+maeiO0tAdZe2uwYdp8bsdVBd6qM4kyaozibPevEFlvgfbEM4RPqjew9kH782wEmIul4uFCxeyatUqLrzwQsAK7FWrVnHllVfusf7hhx/O22+/PWDZ9ddfT09PDz/5yU+ora3d/5LLAfM47cyuzGd2Zf4ez/UPisbuKPWd4WxLkt4pHE9lg+GV7XueJOd7HNmbCdQU9w30X1NsjV9Wkucat+OXjVeKYRmMYVh3tKnI97BoWsmA53rvotN7h9ztmQH/d2aS6D3RJE2BKE2BPX8HXA4bM8rymFnhZ2ZZHtPL85he5md6WR6F3tw8aDkQil+R8U0xLDJ+KX5lIjMMg+I8F8V5LubV7P3OytFEyrqTbE+M5u5o9gYA9ZmeJw1dETrDCYKxJJtbgmxuCQ76Om6HjSnZRjV5TCnxUltiNbCZXOzDezDHanmfYXeZXLFiBZdeeimLFi1i8eLF3H777YRCoezdNi655BJqamq4+eab8Xg8zJs3b8D2RUVFAHssl7Hlg4LCNE06QnF2ZAb435FpWbKzw2pt1tJjZZA3NvWwsWnwm8wWeBxML8tjWlke0zNTbYmPyUVeyvzuA84ay+AUwzIc/e+is3Bq8YDnepNlO9qtuN/WFmJra5CtLUG2tYWIJ9N7/Q0ozXMxrdSHK2qj89VdLKgt5vCqgkO6AxyPFL8i45tiWGT8UvxKrvM47UwutpJWexOOZ3qWdEVp6I7Q2BWlsdtKmO3ssBrZxJLpfSbMyvzubJLsqmWzmVb2wXel3l/DToh98pOfpLW1le985zs0NTVx9NFH8/jjj2cHGNy5cyc22zgYiV0OiGEYlGZu5XrslOI9no/EU+zuDGfugmdljRu6+sYsauyOEogmeWt396ADfDvtBtWFA1uVTS7uvSOej+rCod9pSgZSDMtI6Z8sO+Z9vwOptEl9Z4StrUG2ZBJk29uCbG8L0RyIZbtjg43VD78LgM2AmeV+5tUUcmR1AbOr8jmswk91oUetSTMUvyLjm2JYZPxS/Ip8MJ/LwcxyPzPL/YM+n0ylaeiKsiPTkGZnR5id7WF2dVqPe6JJ2oIx2oIx3tjZxTeXzT6o5d2vQfWvvPLKQZuGAjzzzDP73PZ3v/vd/ryljDNel53DKvM5bJDumGA1t9zRHs6cIIezXbF2d4ZpCkRJpMxs18zB2G0GVQVuvGk7L8Q3MKM8n2mlPqaV5TG11IfPdVDvFzHuKYblYLPbDKaU+phS6uP0wwcOWhCMJalrC/FeUzePvfQWcV857zT20BaMZ68W3b+2Pru+3+1gVoWfwyr8zK7MZ25NAfNrCg/qgJ1jmeJXZHxTDIuMX4pfkQPjsNuy5wgnH7bn893hBDs7+hJkk4oObkMYZQ1kVHicduZU5TOnas+EWTKVprkntkerMmtuNbOMZ24dCwZb1tTv8RqVBW6mZgb4n1aWx5QSa8DvKZnB/kVk9PjdDubVFDKnwod991rOPXchDoeDlp4YGxq6WV8f4N3GAJtbgtS1hQjGkry5q4s3d3VlX8PItCZbMLmIBbWFLJhcxOHV+bgd6nIpIiIiIjIeFfqczPcVMn/y3scyG0lKiMmY47DbsoPxDyadNmkLxqhr7eHhp1dTXDubXV1Ra9Dv9hBd4UT2drKvDjLYf7HPmRmzzM+M8jymleZlxjJTyzKR0WIYBpUFHioLPJxxeGV2eTyZpq49xHvNPWxuDrKpqYe367up74qwpcXqjvl/b+wGwGEzrBZkkwqYV1PIvJoCjqguUFyLiIiIiMgedJYg447NZlBR4KHYa6ex3OTcM2YOuNVsVzhOXXs4O9B3XfaOeGHagjE6wwk6d3bxxs6uPV67PN/N1BKrCee00rzMnS+sx0U+p8YxEjnEXA7boHfDbe2JsW53F2/t6uKt3d2s291FZzjBO40B3mkM8Nc1VpLMMGBGWR7zagqZX1PI3EmFHDmpQC1FRURERERynBJiMuEU+Vwc7XNxdG3RHs+FYknq2kPUtVnjl23LjF1W1xaiM5ygtSdGa0+M13d07rFtgcdhdcPslyybUe7nsEo/BTk6lpHIaCnPd3PmEZWceYTVmsw0Teq7ImxoCLChvpv1DQE2NHTTHIixtTXE1tYQD77ZkN1+aqmPeZMKOWZKEYumlXBkdQEuhwbCFRERERHJFUqISU7JczuYO8lqJfJ+XeE4O9rD7OgIszPTumxHh9XSrDkQIxBN8nZ9N2/X73lXzKoCD4dV+jMtWfzMqvAzvcxPsVqViRwShmFkbwO9fG5VdnlrT4z1Dd1Wkqw+wPqGbnZ3Rqz4bg/z6NuNALgdNhbUFrFwajGLphZzzJRiSvJco1UdERERERE5yJQQE8ko8rko8rlYMEjLskg8xc4Oq/vljvZQtkvmlpYgzYEYTYEoTYEoz29uG7BdgceRGZ/MGqtsRnmeumCKHELl+W5On1PB6XP67nTZGYqzoSHAW7u7eGNHJ2t2dtIVTvDq9o4B4w5OK/VxzJRijq4t4pgpRRxepVZkIiIiIiIThRJiIkPgde39rpjd4QRbWnt4rznIe8092YG+G7ujBKJJ3trdzVu792xVlu9xMLXUx9QSq/vl9LI8DqvMZ2Z5Hvnqgily0BTnuTjpsDJOOqwMsLpbbm0NWcmxHZ28vqODra1W4ruuPcz9a6072bodNhZMLmLx9BIWTy9h4dRi8tzajYqIiIiIjEc6khc5QIU+JwunlrBwasmA5ZF4ih0d1vhk29vC1jwzwH9TIEpPNGl14aoP7PGa1YUeZlX4mZkZo+wj8ydR6FOSTORgMAyDWRVWV+dPHFcLWInut3Z3sXZnF2t3dbJ2ZxfdkQSv1nXwal0HPA12m8G8mkKO75cgK/Kpm6WIiIiIyHighJjIQeJ12Tm8qoDDqwr2eC6asLpg7uh3N8ytrVbLspaeGI3dURq7+7pgnj6nQgkxkUOo0OfklNnlnDK7HLBakW1rC/F6XQevbO/glW0d1HdFrLtc7uriF89tA2B2pZ+FU0s4bloxi6aWUFviVddoEREREZExSAkxkVHgcdozA/DvrQtmkC0tVvfLHe1hqgs9o1BKEellGAYzy61Wm588bgoAuzvDvFZnjTv2yvYOtrWGMl2ng/z51Z0AVOS7+cSiWr61fM5oFl9ERERERN5HCTGRMcbqglnMwqnFo10UEdmH3rtafvSYyQC0B2OZMcg6eb2ug7fru2npiRGOp0a5pCIiIiIi8n5KiImIiIyAUr+bs+dWcfbcKsDqGv3Wri5K/RpXTERERERkrFFCTERE5CDwOO0smVE62sUQEREREZFB2Ea7ACIiIiIiIiIiIoeSEmIiIiIiIiIiIpJTlBATEREREREREZGcooSYiIiIiIiIiIjkFCXEREREREREREQkpyghJiIiIiIiIiIiOUUJMRERERERERERySlKiImIiIiIiIiISE5RQkxERERERERERHKKEmIiIiIiIiIiIpJT9ishdueddzJt2jQ8Hg9Llizh1Vdf3eu6v/rVrzj55JMpLi6muLiYZcuW7XN9ETn4FMMi45fiV2R8UwyLjF+KX5GJZdgJsXvvvZcVK1Zw44038sYbb7BgwQKWL19OS0vLoOs/88wzfPrTn+bpp59m9erV1NbWcvbZZ1NfX3/AhReR4VMMi4xfil+R8U0xLDJ+KX5FJp5hJ8Ruu+02Lr/8ci677DKOPPJI7rrrLnw+H3ffffeg6//xj3/kq1/9KkcffTSHH344v/71r0mn06xateqACy8iw6cYFhm/FL8i45tiWGT8UvyKTDzDSojF43HWrFnDsmXL+l7AZmPZsmWsXr16SK8RDodJJBKUlJQMr6QicsAUwyLjl+JXZHxTDIuMX4pfkYnJMZyV29raSKVSVFZWDlheWVnJxo0bh/Qa11xzDZMmTRrwY/J+sViMWCyW/TsQCACQSCRIJBKDbtO7fG/PT2S5WvdcrTcMrPtw6n8oYljxOzyqu+o+1PprHzw2qe65V3ftgycO1V111z54fFPdc6/u+7sP3pthJcQO1C233MI999zDM888g8fj2et6N998MzfddNMey5988kl8Pt8+32PlypUHXM7xKlfrnqv1Bqvu4XD4kL3fUGJY8bt/VPfcdChjWPvgg0t1zz3aB08cqntu0j544lDdc89Ixe+wEmJlZWXY7Xaam5sHLG9ubqaqqmqf2/7nf/4nt9xyC//4xz846qij9rnuddddx4oVK7J/BwKB7CCEBQUFg26TSCRYuXIlZ511Fk6nc4g1mhhyte65Wm8YWPdIJDLk7Q5FDCt+h0d1V92HGsPaB49Nqnvu1V374IlDdVfdtQ8e31T33Kv7/u6D92ZYCTGXy8XChQtZtWoVF154IUB2YMArr7xyr9v96Ec/4gc/+AFPPPEEixYt+sD3cbvduN3uPZY7nc4P/LCHss5Elat1z9V6g1X3ZDI55PUPRQwrfveP6p67dR9qDGsfPLap7rlXd+2DJw7VPXfrrn3wxKC6517dh7sP3pthd5lcsWIFl156KYsWLWLx4sXcfvvthEIhLrvsMgAuueQSampquPnmmwH44Q9/yHe+8x3+9Kc/MW3aNJqamgDw+/34/f4DroCIDI9iWGT8UvyKjG+KYZHxS/ErMvEMOyH2yU9+ktbWVr7zne/Q1NTE0UcfzeOPP54dYHDnzp3YbH03r/z5z39OPB7noosuGvA6N954I9/97ncPrPQiMmyKYZHxS/ErMr4phkXGL8WvyMSzX4PqX3nllXttGvrMM88M+Luurm5/3kJEDiLFsMj4pfgVGd8UwyLjl+JXZGKxffAqIiIiIiIiIiIiE4cSYiIiIiIiIiIiklOUEBMRERERERERkZyihJiIiIiIiIiIiOQUJcRERERERERERCSnKCEmIiIiIiIiIiI5RQkxERERERERERHJKUqIiYiIiIiIiIhITlFCTEREREREREREcooSYiIiIiIiIiIiklOUEBMRERERERERkZyihJiIiIiIiIiIiOQUJcRERERERERERCSnKCEmIiIiIiIiIiI5RQkxERERERERERHJKUqIiYiIiIiIiIhITlFCTEREREREREREcooSYiIiIiIiIiIiklOUEBMRERERERERkZyihJiIiIiIiIiIiOQUJcRERERERERERCSnKCEmIiIiIiIiIiI5RQkxERERERERERHJKUqIiYiIiIiIiIhITtmvhNidd97JtGnT8Hg8LFmyhFdffXWf6//1r3/l8MMPx+PxMH/+fB577LH9KqyIjAzFsMj4pfgVGd8UwyLjl+JXZGIZdkLs3nvvZcWKFdx444288cYbLFiwgOXLl9PS0jLo+i+99BKf/vSn+eIXv8jatWu58MILufDCC1m/fv0BF15Ehk8xLDJ+KX5FxjfFsMj4pfgVmXiGnRC77bbbuPzyy7nssss48sgjueuuu/D5fNx9992Drv+Tn/yEc845h3/913/liCOO4Hvf+x7HHnssP/3pTw+48CIyfIphkfFL8SsyvimGRcYvxa/IxOMYzsrxeJw1a9Zw3XXXZZfZbDaWLVvG6tWrB91m9erVrFixYsCy5cuX88ADD+z1fWKxGLFYLPt3d3c3AB0dHSQSiUG3SSQShMNh2tvbcTqdQ63ShJCrdc/VesPAukejUQBM0/zA7Q5FDCt+h0d1V92HGsPaB49Nqnvu1V374IlDdVfdtQ8e31T33Kv7/u6D92ZYCbG2tjZSqRSVlZUDlldWVrJx48ZBt2lqahp0/aampr2+z80338xNN920x/Lp06cPp7giOaWnp4fCwsJ9rnMoYljxK7J/PiiGtQ8WGbu0DxYZ37QPFhm/hrIP3pthJcQOleuuu25ANj2dTtPR0UFpaSmGYQy6TSAQoLa2ll27dlFQUHCoijom5Grdc7XeMLDu+fn59PT0MGnSpNEuFqD4HS7VXXVXDI9vqnvu1V3xO3Go7qq7Ynh8U91zr+4jHb/DSoiVlZVht9tpbm4esLy5uZmqqqpBt6mqqhrW+gButxu32z1gWVFR0ZDKWFBQkFNfiP5yte65Wm/oq/tQM+KHIoYVv/tHdc/tug8lhrUPHttU99yru/bBE4fqntt11z54/FPdc6/uw90H782wBtV3uVwsXLiQVatWZZel02lWrVrF0qVLB91m6dKlA9YHWLly5V7XF5GDRzEsMn4pfkXGN8WwyPil+BWZmIbdZXLFihVceumlLFq0iMWLF3P77bcTCoW47LLLALjkkkuoqanh5ptvBuAb3/gGp556Kj/+8Y/58Ic/zD333MPrr7/OL3/5y5GtiYgMiWJYZPxS/IqMb4phkfFL8SsyAZn74Y477jCnTJliulwuc/HixebLL7+cfe7UU081L7300gHr/+UvfzFnz55tulwuc+7cueajjz66P2+7T9Fo1LzxxhvNaDQ64q891uVq3XO13qZ54HUfazGsz1J1zzUHUvexFr+mqc9Sdc+tumsfPHGo7qr7cI21+DVNfZaqe27VfaTrbZjmAdyjUkREREREREREZJwZ1hhiIiIiIiIiIiIi450SYiIiIiIiIiIiklOUEBMRERERERERkZyihJiIiIiIiIiIiOSUCZEQu/POO5k2bRoej4clS5bw6quvjnaRRtxzzz3Heeedx6RJkzAMgwceeGDA86Zp8p3vfIfq6mq8Xi/Lli1j8+bNo1PYEXbzzTdz3HHHkZ+fT0VFBRdeeCGbNm0asE40GuWKK66gtLQUv9/Pxz72MZqbm0epxCPn5z//OUcddRQFBQUUFBSwdOlS/v73v2efnyj1VgxP3BhW/Cp+J4JcjV9QDCuGJ4ZcjWHFr+J3IsjV+AXF8KGI4XGfELv33ntZsWIFN954I2+88QYLFixg+fLltLS0jHbRRlQoFGLBggXceeedgz7/ox/9iP/+7//mrrvu4pVXXiEvL4/ly5cTjUYPcUlH3rPPPssVV1zByy+/zMqVK0kkEpx99tmEQqHsOldddRUPP/wwf/3rX3n22WdpaGjgn/7pn0ax1CNj8uTJ3HLLLaxZs4bXX3+dM844gwsuuIANGzYAE6PeimHLRI1hxa/idyLI1fgFxbBieGLI1RhW/Cp+J4JcjV9QDB+SGDbHucWLF5tXXHFF9u9UKmVOmjTJvPnmm0exVAcXYN5///3Zv9PptFlVVWXeeuut2WVdXV2m2+02//znP49CCQ+ulpYWEzCfffZZ0zStujqdTvOvf/1rdp13333XBMzVq1ePVjEPmuLiYvPXv/71hKm3Yji3Yljxq/gd73I5fk1TMawYHv9yOYYVv4rf8S6X49c0FcMHI4bHdQuxeDzOmjVrWLZsWXaZzWZj2bJlrF69ehRLdmht376dpqamAf+HwsJClixZMiH/D93d3QCUlJQAsGbNGhKJxID6H3744UyZMmVC1T+VSnHPPfcQCoVYunTphKi3YtiSSzGs+FX8TjS5FL+gGFYMTzy5FMOKX8XvRJNL8QuK4YMRw46RLuyh1NbWRiqVorKycsDyyspKNm7cOEqlOvSampoABv0/9D43UaTTab75zW9y4oknMm/ePMCqv8vloqioaMC6E6X+b7/9NkuXLiUajeL3+7n//vs58sgjefPNN8d9vRXDllyJYcWv4nciypX4BcWwYnhiypUYVvwqfieiXIlfUAwfrBge1wkxyT1XXHEF69ev54UXXhjtohwyc+bM4c0336S7u5v77ruPSy+9lGeffXa0iyUybIpfxa+Mb4phxbCMX4pfxa+Mb4rhgxPD47rLZFlZGXa7fY+7CTQ3N1NVVTVKpTr0eus60f8PV155JY888ghPP/00kydPzi6vqqoiHo/T1dU1YP2JUn+Xy8WsWbNYuHAhN998MwsWLOAnP/nJhKi3YtiSCzGs+FX8TlS5EL+gGFYMT1y5EMOKX8XvRJUL8QuK4YMZw+M6IeZyuVi4cCGrVq3KLkun06xatYqlS5eOYskOrenTp1NVVTXg/xAIBHjllVcmxP/BNE2uvPJK7r//fp566immT58+4PmFCxfidDoH1H/Tpk3s3LlzQtT//dLpNLFYbELUWzFsmcgxrPgdSPE78Uzk+AXF8PsphieeiRzDit+BFL8Tz0SOX1AMv99BieERHPR/VNxzzz2m2+02f/e735nvvPOO+aUvfcksKioym5qaRrtoI6qnp8dcu3atuXbtWhMwb7vtNnPt2rXmjh07TNM0zVtuucUsKioyH3zwQXPdunXmBRdcYE6fPt2MRCKjXPID95WvfMUsLCw0n3nmGbOxsTE7hcPh7Dpf/vKXzSlTpphPPfWU+frrr5tLly41ly5dOoqlHhnXXnut+eyzz5rbt283161bZ1577bWmYRjmk08+aZrmxKi3Ynhix7DiV/E7EeRq/JqmYlgxPDHkagwrfhW/E0Guxq9pKoYPRQyP+4SYaZrmHXfcYU6ZMsV0uVzm4sWLzZdffnm0izTinn76aRPYY7r00ktN07RuOXvDDTeYlZWVptvtNs8880xz06ZNo1voETJYvQHzt7/9bXadSCRifvWrXzWLi4tNn89nfvSjHzUbGxtHr9Aj5Atf+II5depU0+VymeXl5eaZZ56Z/REwzYlTb8XwxI1hxa/idyLI1fg1TcWwYnhiyNUYVvwqfieCXI1f01QMH4oYNkzTNIfXpkxERERERERERGT8GtdjiImIiIiIiIiIiAyXEmIiIiIiIiIiIpJTlBATEREREREREZGcooSYiIiIiIiIiIjkFCXEREREREREREQkpyghJiIiIiIiIiIiOUUJMRERERERERERySlKiImIiIiIiIiISE5RQkxERERERERERHKKEmIiIiIiIiIiIpJTlBATEREREREREZGcooSYiIiIiIiIiIjkFCXEREREREREREQkpyghJiIiIiIiIiIiOUUJMRERERERERERySlKiImIiIiIiIiISE5RQkxERERERERERHKKEmIiIiIiIiIiIpJTlBATEREREREREZGcooSYiIiIiIiIiIjkFCXEREREREREREQkpyghJiIiIiIiIiIiOUUJMRERERERERERySlKiImIiIiIiIiISE5RQkxERERERERERHKKEmIiIiIiIiIiIpJTlBATEREREREREZGcooSYiIiIiIiIiIjkFCXEREREREREREQkpyghJiIiIiIiIiIiOUUJMRERERERERERySlKiImIiIiIiIiISE5RQkxERERERERERHKKEmIiIiIiIiIiIpJTlBATEREREREREZGcooSYiIiIiIiIiIjkFCXEREREREREREQkpyghJiIiIiIiIiIiOUUJMRERERERERERySlKiImIiIiIiIiISE5RQkxERERERERERHKKEmIiIiIiIiIiIpJTlBATEREREREREZGcooSYDEldXR2GYfC73/1u2Ns+88wzGIbBM888M+LlEpEPpvgVGd8UwyLjm2JYZPxS/E5sSojJqNi0aRNXXXUVJ5xwAh6PB8MwqKurG3Tde++9l89+9rMcdthhGIbBaaeddkjLKiIDDTV+29vbufXWWznllFMoLy+nqKiI448/nnvvvffQF1pEsoazD77qqqs49thjKSkpwefzccQRR/Dd736XYDB4aAstIlnDieH+tm7dml3/9ddfP/gFFZE9DCd+p02bhmEYe0xf/vKXD22hJzAlxGRUrF69mv/+7/+mp6eHI444Yp/r/vznP+fBBx+ktraW4uLiQ1RCEdmbocbv6tWr+fa3v01JSQnXX389P/jBD/D5fHzqU5/ixhtvPIQlFpH+hrMPfu211zj55JO56aab+MlPfsLpp5/OLbfcwjnnnEM6nT5EJRaR/oYTw/1dddVVOByOg1gyEfkgw43fo48+mt///vcDpi984QuHoKS5Qb+IMirOP/98urq6yM/P5z//8z95880397ru73//e2pqarDZbMybN+/QFVJEBjXU+J07dy6bN29m6tSp2WVf/epXWbZsGT/84Q+5+uqrycvLO0SlFpFew9kHv/DCC3ssmzlzJt/61rd49dVXOf744w9iSUVkMMOJ4V5PPPEETzzxBFdffTXf//73D34hRWRQw43fmpoaPvvZzx6awuUgtRAbR7773e9iGAbvvfcen/3sZyksLKS8vJwbbrgB0zTZtWsXF1xwAQUFBVRVVfHjH/94wPYtLS188YtfpLKyEo/Hw4IFC/if//mfPd6nq6uLz3/+8xQWFlJUVMSll15KV1fXoGXauHEjF110ESUlJXg8HhYtWsRDDz30gXUpKSkhPz9/SPWura3FZtNXVca3XIzf6dOnD0iGARiGwYUXXkgsFmPbtm0f+BoiY0UuxvDeTJs2LVtWkfEil2M4kUjwjW98g2984xvMnDlzyNuJjBW5HL8A8XicUCg0rG1kaJRlGIc++clPkk6nueWWW1iyZAnf//73uf322znrrLOoqanhhz/8IbNmzeJb3/oWzz33HACRSITTTjuN3//+91x88cXceuutFBYW8vnPf56f/OQn2dc2TZMLLriA3//+93z2s5/l+9//Prt37+bSSy/doxwbNmzg+OOP59133+Xaa6/lxz/+MXl5eVx44YXcf//9h+z/ITKeKH6hqakJgLKysoP6PiIHQy7GcDKZpK2tjYaGBp588kmuv/568vPzWbx48Yi+j8ihkIsxfPvtt9PZ2cn1118/oq8rcqjlYvw+9dRT+Hw+/H4/06ZNG1BmGQGmjBs33nijCZhf+tKXssuSyaQ5efJk0zAM85Zbbsku7+zsNL1er3nppZeapmmat99+uwmYf/jDH7LrxONxc+nSpabf7zcDgYBpmqb5wAMPmID5ox/9aMB7nHzyySZg/va3v80uP/PMM8358+eb0Wg0uyydTpsnnHCCedhhh2WXPf300yZgPv3004PW69ZbbzUBc/v27R/4P5g7d6556qmnfuB6ImON4tfS3t5uVlRUmCeffPKQ1hcZK3I5hlevXm0C2WnOnDl7fT2RsSpXY7ixsdHMz883f/GLX5imaZq//e1vTcB87bXX9v0PExlDcjV+zzvvPPOHP/yh+cADD5i/+c1vsmW5+uqrP/B/JkOjFmLj0D//8z9nH9vtdhYtWoRpmnzxi1/MLi8qKmLOnDnZLkmPPfYYVVVVfPrTn86u43Q6+frXv04wGOTZZ5/NrudwOPjKV74y4D2+9rWvDShDR0cHTz31FJ/4xCfo6emhra2NtrY22tvbWb58OZs3b6a+vv6g1F9kPMvl+E2n01x88cV0dXVxxx13jPjrixwKuRjDRx55JCtXruSBBx7Ijv2nu0zKeJVrMXzNNdcwY8aMAfUWGa9yLX4feughrr76ai644AK+8IUv8Oyzz7J8+XJuu+02du/ePSLvkes0qP44NGXKlAF/FxYW4vF49uh+VFhYSHt7OwA7duzgsMMO22Msrt47W+zYsSM7r66uxu/3D1hvzpw5A/7esmULpmlyww03cMMNNwxazpaWFmpqaoZZO5GJLZfj92tf+xqPP/44//u//8uCBQtG9LVFDpVcjOGCggKWLVsGwAUXXMCf/vQnLrjgAt544w3Fsow7uRTDL7/8Mr///e9ZtWqVxuOVCSGX4ncwhmFw1VVX8cQTT/DMM89osP0RoITYOGS324e0DKy+0AdD763Wv/Wtb7F8+fJB15k1a9ZBeW+R8SxX4/emm27iZz/7Gbfccguf+9znRvS1RQ6lXI3h/v7pn/6Jz33uc9xzzz1KiMm4k0sxfPXVV3PyySczffp06urqAGhrawOgsbGRnTt37pFgEBnLcil+96a2thawWqrJgVNCLEdMnTqVdevWkU6nB2THN27cmH2+d75q1SqCweCA7PimTZsGvN6MGTMAq7lp71VjETk4xnv83nnnnXz3u9/lm9/8Jtdcc81Bfz+RsWa8x/D7xWIx0uk03d3dh/y9RUbDeI3hnTt3smPHDqZPn77Hc+effz6FhYW6W6xMeOM1fvemtytoeXn5IX/viUhtZ3PEueeeS1NTE/fee292WTKZ5I477sDv93Pqqadm10smk/z85z/PrpdKpfYY76eiooLTTjuNX/ziFzQ2Nu7xfq2trQepJiK5ZzzH77333svXv/51Lr74Ym677bYRe12R8WS8xnBXVxeJRGKP5b/+9a8BWLRo0Yi8j8hYN15j+Je//CX333//gKl3PKT//M//5I9//OOIvI/IWDZe47ejo4NUKjVgWSKR4JZbbsHlcnH66aePyPvkOrUQyxFf+tKX+MUvfsHnP/951qxZw7Rp07jvvvt48cUXuf3228nPzwfgvPPO48QTT+Taa6+lrq6OI488kr/97W+DXgW+8847Oemkk5g/fz6XX345M2bMoLm5mdWrV7N7927eeuutvZanu7s7++Py4osvAvDTn/6UoqIiioqKuPLKK7PrPvfcc9nb5ra2thIKhfj+978PwCmnnMIpp5wyMv8kkTFqvMbvq6++yiWXXEJpaSlnnnnmHgfeJ5xwQvYqm8hENl5j+JlnnuHrX/86F110EYcddhjxeJznn3+ev/3tbyxatEhjl0jOGK8xfPbZZ++xbW+LsFNPPVVJbckJ4zV+H3roIb7//e9z0UUXMX36dDo6OvjTn/7E+vXr+Y//+A+qqqpG+l+Vm0bhzpayn3pvN9va2jpg+aWXXmrm5eXtsf6pp55qzp07N/t3c3Ozedlll5llZWWmy+Uy58+fP+D2sb3a29vNz33uc2ZBQYFZWFhofu5znzPXrl27x+1mTdM0t27dal5yySVmVVWV6XQ6zZqaGvMjH/mIed9992XXGex2s9u3bx9wC/f+09SpUwet92DTjTfeOOT/n8hoysX47b21+96mwcovMlblYgxv2bLFvOSSS8wZM2aYXq/X9Hg85ty5c80bb7zRDAaDw/sHioyyXIzhwfTum1977bV9ricyluRi/L7++uvmeeedZ9bU1Jgul8v0+/3mSSedZP7lL38Z3j9P9skwzYM02pyIiIiIiIiIiMgYpDHEREREREREREQkpyghJiIiIiIiIiIiOUUJMRERERERERERySnDTog999xznHfeeUyaNAnDMHjggQc+cJtnnnmGY489FrfbzaxZs/jd7363H0UVkQOl+BUZ3xTDIuOX4ldkfFMMi0w8w06IhUIhFixYwJ133jmk9bdv386HP/xhTj/9dN58802++c1v8s///M888cQTwy6siBwYxa/I+KYYFhm/FL8i45tiWGTiOaC7TBqGwf3338+FF16413WuueYaHn30UdavX59d9qlPfYquri4ef/zx/X1rETlAil+R8U0xLDJ+KX5FxjfFsMjE4DjYb7B69WqWLVs2YNny5cv55je/uddtYrEYsVgs+3c6naajo4PS0lIMwzhYRRUZl0zTpKenh0mTJmGzjeywgIpfkYNPMSwyfil+RcY3xbDI+DUS8XvQE2JNTU1UVlYOWFZZWUkgECASieD1evfY5uabb+amm2462EUTmVB27drF5MmTR/Q1Fb8ih45iWGT8UvyKjG+KYZHx60Di96AnxPbHddddx4oVK7J/d3d3M2XKFLZv305+fv6g2yQSCZ5++mlOP/10nE7noSrqmJCrdc/VesPAukejUaZPn77X2DjUFL/Do7qr7orh8U11z726K34nDtVddVcMj2+qe+7VfaTj96AnxKqqqmhubh6wrLm5mYKCgkGz4gButxu3273H8pKSEgoKCgbdJpFI4PP5KC0tzakvBORu3XO13jCw7pFIBOCgNKNW/B58qrvqrhge31T33Ku74nfiUN1Vd8Xw+Ka6517dRzp+R7aj9CCWLl3KqlWrBixbuXIlS5cuPdhvLSIHSPErMr4phkXGL8WvyPimGBYZ+4adEAsGg7z55pu8+eabgHU72TfffJOdO3cCVjPPSy65JLv+l7/8ZbZt28bVV1/Nxo0b+dnPfsZf/vIXrrrqqpGpgYgMmeJXZHxTDIuMX4pfkfFNMSwy8Qw7Ifb6669zzDHHcMwxxwCwYsUKjjnmGL7zne8A0NjYmP1RAJg+fTqPPvooK1euZMGCBfz4xz/m17/+NcuXLx+hKojIUCl+RcY3xbDI+KX4FRnfFMMiE8+wxxA77bTTME1zr8//7ne/G3SbtWvXDvetRGSEKX5FxjfFsMj4pfgVGd8UwyITz0EfQ0xERERERERERGQsUUJMRERERERERERyihJiIiIiIiIiIiKSU5QQExERERERERGRnKKEmIiIiIiIiIiI5BQlxEREREREREREJKcoISYiIiIiIiIiIjlFCTEREREREREREckpSoiJiIiIiIiIiEhOUUJMRERERERERETGjngYTPOgvoXjoL66iIiIiIiIiIhIf4kIdO6Arp3Q1TvPTN27INQK39oM/oqDVgQlxERERERERGRiiAWhpxECDeArgar5o10ikdxlmlaCq+ENaN8KnduhIzP1NHzw9l27lBATERERERERIRmHjm3Qtgna3rNOrAP1EGi0EmGxQN+6x3wOLvjp6JVVJNck49C0Dna+DLtegV2vQrBp7+u78qFkGhROgaJBJm/RQS2uEmIiIiIiIsm4dRW7Y5s19V7F/tQfwe4c7dKJ5JZEtK8bVWedNW/f2pcAM1P73t6VDwXVkFd+SIorkjPS6b64DNRDdz0Edmfm9VZ8pmIDt7E5rJaaZXOgZAaUTIfi6dbcVwqGMSpVASXERERERCRXRLqsg/jO7Zl5nXXw3rkduneDmd5zm66dUDrz0JZTZKIxTUjFIR6yplgPBJuhp8lq1RVstuY9TVbM9TTu+/Vc+VB2GJTPseKzYLKVAMufZM3d+YemXiITWU8TNG+Alncz0zvQuhES4X1v5yuF2iVQuxgmL4ZJx4DLd2jKPExKiImIiIjI+Gea1kl1547M1er+0y5rHJJo175fw+nru3pdMsO6gu0tPiTFFxnXTNM6eW59F1o29s27d0MikwRLJ4f3mi4/FE2F4qlQPM2Kx/LZUDYb8qtHtVWJyIQTaoeGtdZYXw1rof6NvXd1tLut/WRBDRTWWAnpwhrr7+KpVqyOk/hUQkxERERExhbThEgnBFusK9HJmNUFIxnPzGPWc72tvHq7VCWjH/zaeRWZk+t+U8kMa/JXjJuDeJFDKp22xuYK1FvJ5e5dmTvBZRLObe9BtHtor2V3WckufyXkV/VN/irIr7TGEiqeZg2Ir3gUGVm9g9w3r4emtzPTOmvZ+xk2KJ0FFUdAxZF98+LpYJ8YqaSJUQuR8S7SZd0JJ9BgHWj0NA4cHPRLz2j8EpHxIBmHUEumC0iTdWWtbDZMP2W0SyYyNqQSViIr2GTNe5qsVl3BZuhp7lsebLa6Vw2XYbOuVBfVQuFkayqogcLM38VTwZU38vUSGU/SaejeTXFwM8amxyDWCaFWCLVZU7jd6tLYf4r3fPDrGnYrsVxxOJQfYc2Lp1vdF115VgtMV56OaUUOlVgw09Vxg9X1sXkDNK2H2F6S16WzrO6Nk46FmmOh6qgx29VxpCghJnKwmabVRaP/1bTeqXOHNd/bj1KvYLN1IC8ih14iYg0U2r3TOlEPd0Cko9+83WpmHmyyHr/fwsuUEJPcEA9lTqhbrQs8/bsr9j4OtQzvNT1FVksSh8vqopGdu63WI8XTB7b0Kpysk23JXaZp7bOi3VZrrmi3NXXtsMbKa9+auWFEHc5UjFMANg/zPbzFVoK5aEom6VxrJaBLZlpjejncB6FiIrJXqTgE+p1fdu2wuiu3bLBaTw/G5oTyw6FqnjXYfeU8qF5w0O/oOBYpISYyHMm4dWDf2z0j1mONh5BOWXe7SSetKdaTSYBlTgTiwQ9+bW+xdRW7YJI1LkLv44Jq8JYc7JqJTFzptHVlO9oN0UDmJCFgxWUibN3JKhmxTiJ6p57GvpP4UOvw3s/mzHQDqbS6f1TNPzj1EjkYTDOT2Grtm8IdmRYiQSt+YkGI9WCPdnNKw1Yc266HcNsHD7Lby+awYsRfYcWIv2JgzOT3W6aTa8k1pmldXImHANO60YNpZp5LW3GYvcja72JroMG6ADvEcbpMm4Owowhv2VRs/nLIK7PuyJhXbg2I7S6wWnZlp8zfTs9Bq7qI7IVpWsekbZug9T1o3Yi9dRNnN72HY20nYO59W38VVM6FyiOtxFflPKv3gsN1yIo/likhJrkrGujrohhosA76U3FrSsasbh2puDUeSffuvlvLDnYHqqHwlVlX0oqmWF02iqZaj4umWlfW1IVDZGh6xw7q7VYVyjwOt7+v9Van9TgaYJ8HCkPhzLPiNL/KSlD7Sq3WKd4Sa+4rsRLZ/ioruW2zjUhVRfZLKmklrgaTTlmtGbt3951M91686Wm29oXJyJDexgbsMdy83W2dUBdU93VZLHxf90VviWJEctP7ew107+47Du1/TLo/3YX7M2xWAstTAO5Ca7Drkpl9N4somUEyr4p/PP4k5557LjanWlWKjIreVp3xoNXCOtjUN+xG79AbXTuhbfMeDSxsgLf3D4c3c345xZpKZ1lJsIq5kFd6qGs1righJuNPOm2d6HbVU9bzDsZmB5C0TpKT0Uxrj2jmts7Bfle1e6yr2uF262BjKGMhDMbhzXTNmJo5qLdbV7uzk90aI6GwdwyTWusEYIL3vxYZslTC2vlHevDFWqzBPFORfmOVZLp5DEhwtfd1TfygLsZ7Y3f1O0HovdLtA6fXmhyevnl+1cATeW+xBvaVQy+dsg6Qexqtk+gBY/oErHmkKxMbbVYrrXC7tY88UA4v+Pu3Fsm0EnH5M/HjJ+nwsebdOhaecg6OgkprXZdfsSITW6TLOlHtvRgTbMk8bu13wtrboisz77242rVr6MefDq8VS4YNyMyNzPL+x5hFUzL7qhprX+UpHFocJhLDr7uI7Mk0rRbSvceq4XYIZy7KRjr7pt6Ltdlz06D1ezDUxhY2h5XoKpsN5YeTLJnJi+80cMK5n8JZqLuu7i8lxGT09F7B7h3foP/jAVPA+mEJNvcddKSTOIETAbYcQBk8RX1dE/0V1omw3ZUZo6TfVDCpb3ySvHL94Ij03gEuUJ8ZX2uXdYKQjeV+XRNj3ZmuiFHrgMFMAeAEzgJ4Zz/ev7dbor/CmvIy3T16W2z1n3uLrBN4dfOQQ623NUjvYPG980hnpqt9euCUilsn1T2NfYPNZ+JlRPlK+5K9/ccByq/uS4INodWymUjQ1PAYZs0iUAsTGY9ME1s6biW5oum+O5gmY9aF1c46a8yt7LR1ZBLO2V4DtdZNIAomZaZ+Q2eoO5PI2GCambsab7fG4uvcnvk92G41sgi3W78dB8SwjlfzqzNDCFRbwwjkV1u/CWVzrBae/cbINBMJunY8pnPTA7RfCbE777yTW2+9laamJhYsWMAdd9zB4sWL97r+7bffzs9//nN27txJWVkZF110ETfffDMej05OJozeVluhln7jjrS9L1Oe6cYUbrdOmhOhA3pL01tC0PSQV1yBrbdVh8NjjTfi8FgH824/uPIzc7819xZnDj6qc7KbouJX9qn3DnC9J+P9xxHqnXqarCTYAcYwQNLmxu4rxvAU9Gt9km9d4fb1dk0sHdhN0V9hJbNzdOevGB4DYj3Z5JbR3cCMlmexPb0Wou1WQqt3XxhssVqGHAjDtmcrrQFj+hRY3SF8ZVZSuHfuKcq0LBmEuiuOGsXvKEglrCRzZ12/k1nrhNbRuZ3zYj3w1jBf01OUuRhTMfDCjLtgz32TYVgXcQproDCTgM6xXgNmIkEqECDV3U2qu5t0IEA6FsNzxBE4J0/GGEf7c8XwBBAP9fUc6m1tHQ9aF3GDzZnuio2Zx43W/n4oQwnYXdY+2FdinW/6Sq25t7hvmafI6qnQe7zbe+zr9A1732z2tkAd4rqxTZtINjfjnj0bR1XVuIq7g2nYCbF7772XFStWcNddd7FkyRJuv/12li9fzqZNm6ioqNhj/T/96U9ce+213H333Zxwwgm89957fP7zn8cwDG677bYRqYSMoHTK+mGIdPVroZV5nG3q2W98nt4EV7ht/8fWcvr6ujF5iqwT4fdP3qKBA+/mlZM0DZ567LF9jn1gmiak05jJJCSTmKkUZjJp/d0ewEx1YiYSkEphptIYDjuGwwF2h/XYbgeHA8PhwLBnnnM4MDI/WOlQiERjozXVN2QeN5Dq7sawZ7Zx9r5eZnK7MdwubG4PhseDze3CcLtJR6KkAt2ku7tJdQeyBw7p7m6mP3A/Nq930DoOh+I3R5mmFavvT1j3nrD37vh7mjIDyJt7bG4mDVJJg3TCIJ20ZeZu0rYC0vYi0vZC0rY8DJcPXF4MtxfD7QOPD8Ptt/52ecDtxXB5MVw+Ug4nr619kyUnn4zTl4fN48bweDBcbgyXc0DMkkxiJlOYbXFSWzaSbO8g1dFBsqOdVHsHyc4O7PkFuA87DPdhs3AfdhiOysoJt7NXDB8CyTgEdu95N+Du3ZkD5JYByWAHMB+gfh+v6SkEfxVpTzkpo4S0owBHYR42nxvDZs90hbJbXe7zyjNXhqsgvxrTV4YZi2OmUtY+yem05jbbfn2/TdMk1dlJco99VyNmPN63f3K7rZh0ezCczkET0GnTpKCpkXBREZ7aKTirq4a1r0qHwyQ7Oki1t5PqCWK4nNjcvb8DLmyeTDl8PmvfuZ/xbKbTmLEYZjwOdvvA/fkh/I1Q/B4kiUi/WN0x8K6mvXG7l2NU4/1/Odx9dzF1eqwEVumM7LhblMy0egu4/YegYgfGTKetBFRnFzZ/Ho6ysuzx6z63S6VIBQKkg0HSoVDfPBQiHQ5jJhLW/jjVb9+cSpIOhUl1d5EOBKzj2O7u7LGsGd77DTccFRV4Fx6Lb+EifIsW4j7sMOs3bj+kw2FiW7cR27KF2ObNxLZsxn/iiZRceul+vd77KYbHmXio726LLe9C8wZoeWf4N0sCUgkbSdskElSSSBaSiHlI9JjYCkoo/vQn8cxfaDW02J/9cjpNOhyB5ODdmNOhELHtdcS3b7emuu3EtteRbG5myqRJdOzcReFZy3DPmbPHPi2+ezeBRx6h++FHiG/dml1uLyzEffjheA4/HPcRh+M58kgr9ibYcfNQDDshdtttt3H55Zdz2WWXAXDXXXfx6KOPcvfdd3Pttdfusf5LL73EiSeeyGc+8xkApk2bxqc//WleeeWVAyy67Jf3H+gPmHZBT8MeBw1WLw5rB2rYTWw2E2x7iXdvcd8davLK+lp3DGjl0ZsdL7KSYJmmn6ZpWjvZaBQzFiMdi2FGo6RjMdI9QZLvtZBsWUuypYVESwuJ5mam7dxF3U/+e5ATZ+tvkkO7086wGQY4HIds/IVUIDAiCTHF7wQWD2fugLrDuvrdeyfU3ukD7v6WihtEu5zEOn1Eu11Eu72kojbSCUgn0h8wJn0oMw3fZKD+N7/Zr20/iC0/H/esWTirqw9+ixjDyCTQ7VYy3GEl1bE78C5YQMHys0fkbRTDIygRhfbNmYPldzCb3yW1+x3SbQ2YSZN0ysBMGdYNhFMGmAY2Zxq7K43dZcfm92IrKsf0V9LQlaSsfDbpuJdE0CDRkybRFSMZiJDqDpHs7CLV3k46vA3Yli2C4fXiqCjHWV6Bo6ICe0kJ6eAWkh2vkOrozCZ8zdheumI4ndbB6zAOYM10ekT3XVVAw//9Lfu3vaQEZ3U1Nt/gLWDS0Sip9naSHR2Y0WG0nnM4sOXlYcvzYc/Lw+bLs/bD/ff5qSRmwvo7HYtiRq3jCHNf9bXZMDKvbS8owFZYiL2gAHthIfbCAmwFBZRccgmOkgO/27Pidz+k0xBuJ9W4mdjbbxB99x1iW3cQb2qHZBQjHcVIx8AwrbxyZm4NuWVaoWHzY9htGJ58yCvG8BVj5Jdi+MtI+UrYtKuFI446Grvba/12Ox1W4tThxObzZb53mcntw2a4SLe3k2xpyR6TWo9bSQW6re9dLEo6Fs8cx0YhlcaWn299rzLfL1th5ntWYH3Xst+/zDpmKk060J1pVRUglXmcDoYyx8mZ73jv40iEZGendZGoo4NUZyek+rpcG04njupqnJnJVlVJybZttLzxBum2vvok29oGbDeSbPn52fpjsxHdtIlkSws9f3+cnr8/nl3HVVuLvbQUR0mJNS8twV5cguF09iXnQiHSoSCpUIhUewexLVtI7N7dN25b73u63SOWEFMMjzHd9RjbX2BW8ypsq16xGm0EWzADLUR2tJFs78KwpTO/A32/D2baRSLsIBHzkYi4SIbtJEIGyWAKM21kMuW9+1Zr/2rGE0AaaMxMfboefZr8s8+m7KtfwXP44YMWNdnZSc8TTxJ8+mmSbW0Dv8eRyB7f26Hy7N5Nx5130nHnnTgnTcJ/xhn4Tz2VxO5ddD/8CJE33siua7hcOGtridfVkeruJvzKK4T7fRdd06dT+NGPUnjB+TgrK4dcBjORsH57OjutC1zBYLYxCQ6HdVzsdGC43LjnzMbmGlvdwYeVEIvH46xZs4brrrsuu8xms7Fs2TJWr1496DYnnHACf/jDH3j11VdZvHgx27Zt47HHHuNzn/vcgZVcBpdKWmP6ZJNcOwZe4e5psLLQcYNkzE4qaiMZs5GM2kjFbKSi+SRjNlIxJ8m49XwqOkiAGgaGy4HN7QKHs+8Kd1YwM9XtsamJCak9W23tz87XBexXyitzAEz/ll82W195esu0t4No08w+Z8vPtw4uJk3COcma24uLMwfnKevgPJXCTCYgmbQSfbG4dbDU70DG5vFmDob6HSAVZQ6cior2p5YDKH7HuUS0L6Y76/piPHO7dTPYSipmIxGyk4zYSUZsJDLzZNRDKubLtFh0gtOF4XRjON2YNifxliCJ1sEGqn/fFXXDGHhiMGDyYfP6si0yB1w5zv498HE6kSDQ0Y7f5bZab0SjpOPWCQTpzHtnWsNkd6xOJ/aiQhwlpdhLSjIHyyXYi4tJdXRmrghvIV5XR7qnh8jatUTWrj3Yn84+FX384yOSEFMMD5FpWmN6tLwLbe9ZLZgjXSTbWojtaCa6u4toU4hUIEoqbpCK20jFbaQTvfuw8qG/lyOFLc9qBdFjNgxpE8PptFoFB4OYkQiJHTtJ7Ng5/HoCJBL7ff9Ue2lp376ruhpnzSQMr9c6wY7HSEetk+10bO8JpXQ8TsOGDZQkUyQbG0mHQqQ6rNabQ2W43ThKS7Hl51u/D5kLYb2/Cdn3TiZJZ1pNj+ilrnQaMx4nFY9bCYRBFH/84wf8NorfwZnpNMnt75Dcvp5U43bSLTtJtTWR6mgl1dVFoiNMtNNOIri3UxYDGGrXsxTQlpk2Z5eWAa2PPH4g1RjTbH5/tmVXYudOEjv7fm/KgL3cjxbD68Xmz8Pu67ev9/kwXC7r4o/DOeBCkM3nyyaRB030FRTs0fIrHY0SWbeOyJo1hF9fQ2TtWtI9PUTf2Z/BRS32khKrtfgsq7W4Z968/X6t/hTDY0B3Pex4EbY/B3UvQOd2HMCRaYi+7STU4ibc7CLc6sJMDXof5L3ofw66972qraCgb585aRLO6ioi6zfQ88QT9Dz5JD1PPon/zDMp+8pX8M6bS6q7m55//IPAY38n9PLL+59odjpx1dbimj4d9/RpuKZPxzV9OhQV8cpv7mZmezvhl18m0dBA5x/+QOcf/tC3rWHgO34JhR85j/yzz8Ken086FrNaUW7cRHTjRmLvvktk/Xri27fTettttP7Xf5F3wgkUXngh+cvOxHC7STY2Wq3Utm3LtFDbTrKp2drndw/9Zlc2vx//aaeRf/ZZ+E8+edAGH2YqRXzbNiIbNhB7910qrr56v1uNDsWwEmJtbW2kUikq35cxrKysZOPGjYNu85nPfIa2tjZOOukkTNMkmUzy5S9/mX/7t3/b6/vEYjFi/a6GBgLWT3UikSCxl4Oy3uV7e35CSSehsw6jfbM1tW7mhO1vYv/ptzEDDRiDDMBrmhBtdxLY7adnt5dEcKhfqr38KJgmZixBKnaQ/t+GgdHbVcPlwpaXh6OiHEd5BfbychwV5VBSwtpt2zjuxBNxejyZq3l9XRqtx85+3SD7zYfRWiSb2Ortatnvsc3vx56ff3D+B/2kgFS/73b/7/tQv/OK37Fpj7oHWzCa12O0rMdo3YjZXofZthMCLZgpwxqHO2UQDzqI9ziIBxzEehzEA1X9Tuj3JQ1EM9NAjkmTcM+Zg+vwObjnzMFRVY3N3+8g2Osd0abUiUSCt1eu5KyzzsLZr9tzb1fnA9n5mfE48bo64lu2kGprH4ni7vv9zHSm63WqX+LParHimT9/j++2YniEmCa0vINt52pofRejdSNG67sYsQDRTgc9u71EO51EO50kI+//PrkHfUnD5bK+62631X0vM2G3W12HMl2ASCSySRoDwOnEWVWFo7oKR/Uka15Rib03aVtiJW5tfj+GYZCOREi1tZFsbibZ2mq1LunsxO73Z5O89pKS7GQ4nVYr6n77JJJJq8XXcBiGVY4RGL8mkUjw+sqVzD3rLBwOB+meHpKNjSQbGzFj8cHf3u0aWK8P+F0xUynMSCRzJT1MOhzKPiad6UaaaZWJo687pJHpbjngc3S5rP9X5mIVqb6Lcr2fbW93r3TAGrogHQiQ9vsHfLcVv/sp0EjqvVeIvfEysXfeJbqtkWhjhFR0X/uVvjh1+G24q/24p1bgqq3B9JeDuwjTXYxpc2MmU5mY6I2P/t36kpipzGefzAyVkUyRjsdpqq+nsrwco/eCaG9rw3iCdDhMOhTCDFvfuWxrTcOwLspUlGMvr8BRXo69ohx7YRGGx53pduyyjmM9bgzDRjrY0/fdyoyjlZ0HukkHerLfueyJs8NhtSbrbVVWUIDN7+/rzuxxW8MMeNzYPB7sRb2/G8XZ3xzD6cRMJq3WX42NJBubSDQ2EN9dT/3OnUw55mhcVVWZOmTqUlJixdQIMYFkOt13sauX3Y7rmGNwHXMMhf/8z5jJJPGtW0k2N5PKDI2Q6swMkdDeAakktjy/dRHOl4fR22q0oADnjBm4Zs7EUVq6x/trHzxOpVMYu1/B2PQots1PYrZuJxFyEA9aSfJ4qJBYrIhwYxLiA89Z7YX5OKdMwcTI/Bb0a4BhGDiqqrItJh3V1TgmVeOoqLASvoOwZ2Lv/QqAon/5Ep2//BXBxx8nuGoVwVWrcB1+OPEtWwb0VnIfcQT+5ctxHTYr2/rUyLR4tuX59vreGMag566JRILA4uMoO+ss7MkkkVdeIfTMM4RfWo29qAj/h88l/5xzcGS+s2kgnUiAzYZj9mwcs2eTd/551nPBIMGVKwk8+BDRNWsIvfgioRdfxPB6rfP+D2rRbbNZDTlKSrD58zHTqez/nczF8FRXN+muLgKPPELgkUcwPB58J52I/4wzwWYQ3fAOsQ3rib27ETPSN2ab/5/+CdeMGQPq3Tsfie/8Qb/L5DPPPMN//Md/8LOf/YwlS5awZcsWvvGNb/C9732PG264YdBtbr75Zm666aY9lj/55JP49tIEv9fKlStHpNxjiSsRYFL365QH1pMfayAv1oztfUmv/tezU4aDiKuUkKOMYFsesR0pzK2d2HoGfpFTHg8pv5+UP49knp9UXh4pfx4pv5+kv/dvvzV5vVarqmQSI5HASCaxJRIYiSRGevjZbtNmw7TZwG63HmfGQzHtDtKZpupD6gIyYwbPNTZ+8HoT1MqVKwnvY1yGA6X4PYjMNHmxZooiOzgyvIOen/4QT2MD6dYY0Q4nkU4n8W6n1XQbG1bHpA94ScMglZ9PsqCAZGGBNS8oIJlfQCrPB6aJkUpjpNPWQUYqDaZJorSEWHU16f6fTywGO+oOVu0HOOife9meB8eHVDIJjz026FOK4eEz0knKghup6n6Dqu61+BJ9Cc9k1EZgh5eu7eXEuvYcWzJdnEeqsoR4VTmR0mpi+WWkfD5SXi9pn4+Ux2N1w/sgpomRSGCPRLBFoqR8XlJ+/+Bdc2NRaGiwpn0pL7OmXuGwNe3e/cHlGWXD+tzDybFfL5fT+t3o/e145plBV1P87pstFKJ42zpKt72BZ9cukm2pQRLTBhgmdi/gtmN6XaS9XpK+PBJ5hUQLywjVziA6aTLpvIN3I6QhH0mmUtjicdIul3Wsui+JhDUFe/qWvf+7NRjTxBaLWcfHexm/b5+6Oq1p27bBn7cZUFNjTUsW09y7PBKBHTusaSxwu6C6ypqGoq3NmoZBMTz2GOkk5cF3qO56neruNdgCIdo3+Qns9JKMTBpkCyshkvJ6iEyfQXjmDMIzZxGvrBjecBn78f0Z4LRTcR55BKVPP03+2jeJZ5KksaoqehYcRc9RR5Eoy+zjg0FrGiEDPvfFi62p15o1Q38htxs+8XGcZ55BwZo3KHjjDZyZltOm3U68tJREeRnx8nLi5eUkioutPEFeHinfEG4KkE7j2bkL//q3yV+/AWdnJ6F/rCL0j1V7rupyEa2pITq5hm0vvURykKTzSMWvYQ7j9gTxeByfz8d9993HhRdemF1+6aWX0tXVxYMPPrjHNieffDLHH388t956a3bZH/7wB770pS8RDAaxDfKPGywzXltbS1tbGwUFBYOWLZFIsHKQlgbjVqTLyoa/cz9G3fMYZgrTtA72k2E78ZiPRLqcRLKARNhBoCuC15WHGUuTjsYyV7MGfkEMn4+8U0/Bv2wZvhNPxHYQDywOhQn3mQ9D/7pHIhHKysro7u7ea3yA4nfUddZh7H4Vo+ktjMa3SO96m8juFKEWF5E2F7Gu3uTX3hku6wYMhseDo7IS17RpOKdNy86dU6eMSKuPQyUnPve9UAwPUzqJsekxbO8+iLF1FUY8iGlCOmmQSnuJ2ObRvSlN6N0mSPV1t8077VR8ixfjOvxw3IcddlD2e/oe517dFb+DS7a2EnrqKcLPP0Xs7XUkOwYZW9IAV5kHz/Rq3EcejvvYpbiOOw2bv2i/3/dA5Op3GFR3xfAYE+nC9twPsb19D0ash2iXg46Nfrp3eMHsOz428vJw1tbirJ2Mc/JkbNWTWBvs4eTPfQ7XGDkGju/YQfSNN/AsWDCgZdNIO9ifu5lOE3/vPQyfD+ekSSPbatQ0ib37LqF//IPQ8y9guFx45s3DPfdIPHPn4pw2ba89RfYnfvdlWLVyuVwsXLiQVatWZX8I0uk0q1at4sorrxx0m3A4vEew2zOV21suzu1243bv2ZXB6XR+4Ic9lHXGrGQcNj4M6/4CW1aRiiQJtbkIt+YR6S4i2mpazcGzwpkJ7ECcPbsF2QsL8Z95Jvlnn0Xe0qXYBvm/jnfj+jM/QE6nk+QQbxyg+B0FsSC88wCs/QOprS8TaXVlxzeIdhbw/vtb2fw+vPPm4TnqaDzz5uI54gjs+fnZO64Np6vveDLhPvdhUAzvW6qtkejDdxB95kEiDSESYTvpuI9UIt+62Uu6tw59rY08Rx1F0UcvpOBDHxqR8ReHKte/x7lYd8UvxHfX07NyJT0rV1rjNb6vXK6CJJ4pJXiPWYzn1I/iOWbJmLwgm6vfYVDdcz2GR106DWt/D6tuwgy1E25x0b65mtDuvmNk33HHUXLZ5/EefbTVDbhfq8lEIkHsscdweTxjpu7OWbPImzXr0L3fQfzcXfPnH5TXBXAtWED+ggXw//7ffm0/nPjdl2Gn+VasWMGll17KokWLWLx4MbfffjuhUCh7t41LLrmEmpoabr75ZgDOO+88brvtNo455phsU9EbbriB8847L/uDkPM6d8Ca35J+/Q+EtvQQbHITaS0i1t3/i535sG02HBUV/Qb0q8ZWUcG6bds59qQTcRUUDBjo2l5cfFAHoZPxRfF7CJgm7HqV5HO/Jvz8k4Qb00RaXUS7qgZc4QJwTZuGZ/FxbLLbOf5zn8M7fXpO3u5Yhm6ix3A6Hqf7b38j/PKLRN94hXhLv65GvH/gVetkwnA6cVRWUvChcyi88ELcM2cesvKKDMdEiV8zlaLzT3+m+/779xj83Fsaxz85jnf+kXhO+xj2Yy8C34HfoVNkLJgoMTxWmHWvEP2fFUQ2bifS7iTSWUOiJ5MotNnIP+ssSr/4BbxHHTW6BZUJbdgJsU9+8pO0trbyne98h6amJo4++mgef/zx7ACDO3fuHJAJv/766zEMg+uvv576+nrKy8s577zz+MEPfjBytRiP0inYvBLztV8Tfuk5AnUeAru8pBMDDxpc06fjW7QQ78KF+I4+GmdNjXWXuH4SiQQ9jz1G3imnjJnMuIxNit+RZSYSJJqbSTQ0kKhvIPn2M8TfWEWkPkq8xwEMHOvBWVuLb8li8pYswbd4Cc7KCmtQ6scew1lbq2SYfKCJHMOxrVupX3EVsU2bByx35ht4jjgMzwnn4Jo5C0dREbZ+d+E1PB7FjowLEyF+E/X11F99DZHecWkM8JXHyJ8cJb82hnPpp+C0a6GodtTKKHKwTIQYHm3pcJj2X/yM0OP3Ed3VlRkupDDzrInhdlP0sX+i5POfxzVlymgWVXLEfnUEvfLKK/faNPSZ9w086nA4uPHGG7nxxhv3560mnnSK9Gt/IPbgrfS820X3Di/JcN/Amo7KCvLPXo7vuEX4Fi4c9E4pIgdC8Xtg0vE4bT//Od0PPEiyqWmP7iEWBxjgnlqDb+kpeBctxLdwIc6qIQ4MK7IPEy2GTdOk6957ab75ZsxYHLs7RfFhIbyHz8Jz/hU4Fl00vIFxRcaw8Ry/3Y88StNNN5Hu6cHmcVA+t5uC2h4cnjQc/hE44waoOHy0iylyUI3nGB5toVdfpfHaq0k09N7KwcDuc+A9dhHeRUvwLliAZ/5R2P1jr1u1TFwH/S6Tucw0TeLb64ht2kjsvc3E1j5PbOMG4t3pTNepfABseT7yzzmHwvPOx3fcInVxFBmjIuvW0fBv/0Z8y9bsMsNhw+mN4/ClcPpNnHOOw3PO5/EtORF7YeE+Xk1Ekh0dNH77eoJPPw1AXlWU6nOKcV78B6hd/AFbi8ihkAoGafr3fyfw0MMAeCe5mXTsTlz+FEw9CZZ9F2qPG91CisiYlQ6FaPnxbXT+6U8AOHxJyo/34/vsjTiXXqBW3jKqlBA7SOK7dtH8/R8QfPbZQZ41sPnc5C09gYLzL8R/2qkTcrB7kYkiHY3SescddPz2d5BOYy8tpfJzy8hruxd7Yrd1R/TDzoZzboFSjV8kMhTBF16k4dprSLW1Y9hMKhYEKL7wbIwL7wB3/mgXT0SA8Btrabj6ahK7d4PNoOwYKJu5HcOTDxfeCUecDzqZFZG9CK1eTeP1N5CorwegaGaIitNLsX/lH5CnnlAy+pQQG2HpeJyO3/yGtrt+gRmLgQ28xXHchQncJTZcSz+M+/wVOCbPUDZcZBwIv7GWxm9/m/j27QAUnHYclXN342j6L2uF4qnwoR/C7HN0UiAyBGY6Tesdd9D+87sAcBUkqDkpiOdT34Pj/llxJDJGdD/4IA3/9m1IpXBWFDPpmJ34inugZAZ86s/qHikie5WORGi+5Yd03XsvAM5CB9XHNJE3swi+8Dclw2TMUEJsBIVeeommf/8e8bo6AHyVMaoWduEutsOiL8DJ/w/8FaNbSBEZknQkQuvtP6Hjf/8XTBNHSQFVpzjI9zwI7YDDAyddBSd+A5zvv/udiAwmHY3ScO119Dz+OADFs0JUnFaA7dN/gZpjR7l0ItKr+8EHabj2OjBNChZNpWrKy9hdJsw8Ay66G7zFo11EERmjzHSahquvpmflPwAoXlJN+eQ3sOflwcV/hZLpo1xCkT5KiI2AZGsrzTffQuCxxwCwe00qj+6kYEoUY/7H4MwbrVYkIjIuhF9/nYZvf5vEjp0AFM71Ujlnk3Uy4PDAoi/CiV+HfA2SLzJUydZWdl1xJdF168BmUn1cF0XnnA4X/kwn1yJjSP9kWNHCUqpmrrYabi69EpbdBHadPojI3rXecQc9K/+B4XQy+fKl+DvuAZsDPvE/MOno0S6eyADaox2g6Kb32HX55SRbWsCA4sOClM/rwV47Fz70I5h24mgXUUSGKB0O03Lbf9H5xz9arcL8NqqObSV/UgwcXjjui3DC1yG/crSLKjKuRDe9x64vf5lkYyN2V5rJJ3XgO/9yOPv7uoOkyBgyIBl20iyqap7DcLjhvJ/A0Z8e7eKJyBjX/cij2SERqj5/Ov6O31lPnH8HzFo2egUT2QslxA5A+LXX2PWVr5AOhnAVJJh0fBfeSXlwxq2w8DJdQRMZR0KvvErj9deT2LULgMIZISqPDmD3eeC4K62ukeryLDJswWefpf6qFaTDYVz5SWpPacd14bfhpBUaL0xkDOl5+BGav/1tKxn20Q9T5f1fjDTwsV/DkeePdvFEZIyLrFtH47e/DUDJR5ZQ1PM/1hNnXA9Hf2YUSyayd8rY7KfAY4/QcPU1mMk03rIYtad0YT/h81bA+0pGu3giMkSpYJDW226j809/BsDhS1F9XBf+SUkrsX3qtWoRJrKfOu+5h6Z//x6k0/gqYkw+sRP7x26DRZeNdtFEpJ/8N9bS/Je/WMmwT36Sqrk7Md6JwbST4YjzRrt4IjLGJZqb2X3FlZixGP55k6jw3W89seiLcPK3RrdwIvughNhwmSadP76Gpl8/DIC/JkLNJ4/Adt4PofqoUS6ciAxHYOVKmv/9JpKt7UDmVtBHB7Af9RFr7L+yw0a5hCLjV/eDD9L03ZsAq8Vl9XFhjE/cDXM/OsolE5H+eh5+hKr+ybAvfAjjt2cDBiz/D7XkFJF9Skci7P7qFSRbW3FX+Jg0Zw2GDTjlajj93/QbImOaEmJDZZqYu16j9cav0766G4CiIwyqbvoxxvx/UqCLjCOJLetp+s41BN/YBoDTn6R6URd5xx0LZ/07TFkyyiUUGd+Czz1Hw7evB6BkTpCK41IYn/6LdYc6ERkzzFSK7r/+FcM0Kfj4x6n6zg0Yv11uPXnMxbrYKyL7ZJomDf/2b0Q3bMDutTF58Xbsbrs17uAxnx3t4ol8oAmTENvQECCZPggv3LoJ1v8fqdfvo3lVO911PgDKzjuGsh/8GsPlOwhvKiIjLhnDXP8AnXffRetTDaSTNjBMSo8IUfaRY7Gd8C8w50NKboscoMhbb7H7G9+EZJKCqWErGfb5h2DyotEumoi8j2G3M+lnd/LK977PzOu/jfHO/bD7NXDmwenXj3bxRGQMMxMJmn/4I3r+/jjYYPLSFlylefCJ/4WZp4928USGZEIkxDY39/DZu1+n3GXnxNNiVBU7D+wFO7bDhr/B+r9hNq6na5uP1nX5pOI+MKDqmm9S/Pl/GZnCi8jBlUrCunsJ33Mzzc9HiHa4ABveSU6qr/gE7rMv1xhhIiMkvm079f/yZcxIhLyaNJOWdGGc/u9KhomMYTa/n85TT8FIxeAf37UWnvRNKKgezWKJyBgW37WL+v/3LaLr1gFQtbAL36wKuPivUHnkKJdOZOgmREKsPRTHZsD2HoOP/eIVfvP54zi8qmB4L5JKwnuPw2u/gm3PABBqdtG8toJYl/Vvcs2YTtV3biTveHWnEhlJW1qC1PVYza5HjGnCuw8R/ctNtD7XSbDBA7iweZ1UXHE5RV+4AsNmG7n3E8lxjq5uGv7lX0h1deGpLWTy4o0YlYfD8V8d7aKJyBDYXvsldO+CghpYeuVoF0dEhqAjHGHZb67Hkyzigb8kmFM6kxmlZUwu8VJb7KOq0IPTPrLHu92PPErTd24gHY5gc6apXtxFweI58Ol7lUiXcWdCJMSOn1HKX7+0hM/+8gXqu6J87Gcv8d+fPoYzjxhCq4+eZnjjf2HNbyFQD0A86KBl83R6NoUAsBUWUv61r1H8qU9iOCbEv0xkTPnZs5t5eL2Dx1pX85klU7nwmBoKvfvZ0tM0YetTxP/vO7Q+tZvADi/gAZtB0UcvpOwb38RZUTGi5RfJdanuADV3302yuRlXbTW1i9Zic5rw4R+D/QBbbYvIQedOdGN78b+sP868ETQkiMi4sLZhG4mCJ0kAryfh9WZI1+eTjpWRjpdjJCqZ5J3DvLIjmFtdyuHVBRxRlU95vhtjmMOEpEMhmv79RroffBQAb1mMmhO6cZ5yqTUGr9t/EGoocnBNmOxOY+JNrpwb4e8dNby8vZN//t/X+fa5R/DFk6YPHuyBRnji3zDfeYhEwCTc5iLSXUkkWEqsIQDpENjtFH/qU5RdeQWO4uJDXymRHGCaJrt5mLwZL7E9sIDvPn4UN/+9kg/Pn8RnltRy7JTiYe2wE3+8krY/P0zXNh+Y1gF9/tlnUv7N/4d7xvSDVQ2RnJWORmn82tdwNzdjLy9nytlxHKE0HPVJmHbSaBdPRIbg8Ma/YcSDMOkYmP/x0S6OiAzRtNJ8Tqn6MO80biBk7yKS7sLm6MHm6IG87QC08jBPRW38491qUmtrSUVqKWAmHzr8KD6xqJajJhd+4LF2dP3b1H/tX4g3doJhUnZkkLILFmOc8wOoOOJQVFXkoJgQCbEdgR187Zmv4cHDh+d+hJKSY3hsjZ3vP/oum5uDfO/CebgcfU1Fk+3t9Hzv0wTX7SDSVkoqbu/3al0A5J2wlIprr8Uze/ahrYxIjjEMA/LWY0u04C5fibt8JanoJB7ecRR/e/soDiuZwscX1nL+0ZOoLPAM+hqmaRJ5/XU6fvMLep59Acw8APJOWELFt67Gc6TGMhA5WIJPP0107VpSHg9Tv74c54YfgbsAzvreaBdNRIai5R2mtj9jPV5+M2g4AZFxY2bxFG4/43s89thjnHvuuUTMCDu6d1AXqGN713bWtW5kQ/vbBJNd2L312L31UPwyCeBvDYfx519/iFlFs/nEolouPKaGMr97wOuno1Ha7vwp7b/5DaTB4U0x6UP55F32Uzhs2ehUWmQETYiEWFOoiUl5k2gINfB/W+8D7mPGguns3nkU974R5r2WHq5aXMn8rW8QePzvhF95FdJpwDq5NlwuPHPn4j36aLwLFuA9egHOqqpRrZNILvnNst/wk8d+QnNhM680vQKeBuyeBtwVj7M7UsuPVi/g5pVHccLUGVx4TA3L51aS73GSDofpfuQROv/4J2KbNmVezcA3zU/593+Ob5EG8hY52Ao+9CHiXV2sq9/G3K2/sBaecYNuViEyHpgm9n/cgIFJ+vDzsU1dOtolEpEDUOAqYH75fOaXz88uM02TxlAjb7e9zdutb7Ou9W3Wta0D/2bseVvY2X00P3jibG75ewlnHF7BV0+fxdG1RQRffJGm795EYtcuAPKnJKm69us4Tv0K2CdEGkFkYiTEllQv4aHzH+LOh+6koayBp3Y9RWt8O+6q7cyLP8zHHvBSfEcPTWY6u42nJE7BMVPwffm/8cyZg+FyjWINRHJbviufY13Hcu7p5xJKhfjHzn/w+PbHea35NfDuwu7dhWk+yprwdF5ZuYDrH5zPv7a/w/EvP4ItFATA8HgonNxF8awAnm/+GqYpGSZyqBRedBGzfn4hRrAbqo6C47442kUSkSFKH/Vpwg0bcZ/xHdQ2TGTiMQyDSf5JTPJPYvm05QDs6tnFHWvv4O/b/46zaC2uwreJdZzAkxtPY82bW/lJxzOUvvwMAA5fmqpju8j/yo9g4aWjWBORkTchEmIANsPGTOdMvnbi1wilQjy6/VEe2vBXrr5vE75YHIBt5U5eqp3D12peoiovSOv5t+OdP/8DXllEDqUiTxEXzb6Ii2ZfRFukjSfrnuTxusdZ27IWR942HHnbOGzX/ZywKglAs7+ExtPO4/Tjeqh696fW+CdTTxjlWojkFmPXy0zpeMH648O3gc2+7w1EZGwwDMx5F7Fqh4dzi6eNdmlE5BCpza/lR6f8iEuPvJTb1tzGq02v4ip9jnPqV3PxP1Lkx+OYhkHx0slUVL+KvXY+HPPZ0S62yIibMAmx/oo8RVx8xMV8eHM+jbFrCJb5+O5FaXYWJ4GNPJsq5MxAAX98oINzNr7BV06bydxJhaNdbBF5nzJvGZ854jN85ojP0Bhs5Im6J3hs+2Oc9Ph6AF46wuAnH4mQDG6gdNsLVABPF3+C+T0xKvYy3piIjLBUEtvfrwYgffRnsdUeN8oFEpFhM9Q2TCQXzS2by6/P/jUv1L/Aw3/6dy57dDcA20oKePios/lZ1R3YMOFDP9LFLpmQJvTeL/DgQwBM+9QX+MOXn+KqY7/JpLRBt93O34odeGb8mH+0/5jzfvEXLvvtq7xW1zHKJRaRvan2V/P5eZ/nnuV/4Kyt1qD565ZWYjoS2Ive5P9N8rOsdjJX7HyHE358L//y+9d5fnMr6bQ5yiUXmdhCb/4fttZ36DH8pE7/zmgXR0RERIbBMAxOnnwyV9ZZN5N7dp7Bv10eouiIRzAwedw4kZdTutGcTEwTsoUYQKK5hdDq1QAUnn8eLk8xXyiaz6U7dvC8v4A/zzuLl5pfw1mwDmfBOl4OzuG5/zmNYyuP5aunzeK0OeUfePtZETn0gs88A4EgjspK/mvFSta1rePBhy/jCXuSVocNZ9mzOMue5bnAbP5xz4lM9izg4iXT+PjCWorzNFagyEhb7TmVh+JXYgLn7kjyoaNGu0QiIiIyHImWFkLPPgtA4T9/gXTz//BoURK3rYwn6j9B669f4YYPH8HnT5w+yiUVGVkTtoVY4JFHIJ3Ge+yxuKZMsRa+9mvswGmzzuMX59zN/53/f5w7/Vxs2HD4N+Gb9gvWmzfzz3/9PRfc+QKrt7aPah1EZE/dD1ktPwvP+wg2h4Oju1u4sb6Op5t7uPWE73FyzckYGDj87+Gb8ltaC3/ArS/9jiW3/J0V977Ju42BUa6ByMSybG4VJUs+xcPpE7jmb+vZ1REe7SKJyDDEk2leajbUolokh3Xf/wCkUniPPZZPn/FVvhtMY5gmfyvwkTf3BVLpBN99+B1+/fy20S6qyIiakAkx0zTpfuABAAovuMBaGGyFDfdbj4/7ZwBmF8/mh6f8kEc++ggXzb4Ip82Jw1eHb8rv2OK4mYv/cC+f/+2rOoEWGSOSnZ0En30OgILzz7cWrv4pAO6Fl3LOYRfys2U/49F/epTPHvFZfI487O5WPNUP4Jr+fR6t/xXn/vQxvvz7NbzToLgWGSn/evZspvlNAtEkX/3jG8SSqdEukogMgWmafPbu17h3m50/vrprtIsjIqPATKfpuu8+AIo+/nF48XY+1rqbW4MGDpuDlvQrHHH0/4ER5/uPvssfXt4xyiUWGTn7lRC78847mTZtGh6PhyVLlvDqq6/uc/2uri6uuOIKqqurcbvdzJ49m8cee2y/CjwUsY0biW3ejOF0UnCOdWtZ1v4eUnGYdCzUHDtg/dqCWm5ceiOPf+xxLj3yUjx2L3bvLvKm/ZyXe37Ch3/+ICvufZPdnbrqLePfWI/ffel5/HFIJHAfcQSe2bOhYS3UPQ82Byz5cna92vxarll8DU99YhXXLr6W2vxaDHsUV+lz5M26laeaf8+5P/0H//L719nQ0D0qdRHZX2MthpPpJD9c8wOOmfEyRV4nb9d384NH3x2x1xeZSMZa/BqGwfkLqgG49cn32NEeGrHXFpmIxloMj4TwK6+Q2LULm99PwfFHwos/AWD56d/jjjPuwGP3sDu2lpnz/wy2GNc/sJ7/W7N7lEstMjKGnRC79957WbFiBTfeeCNvvPEGCxYsYPny5bS0tAy6fjwe56yzzqKuro777ruPTZs28atf/YqampoDLvzedGcG0/efcQb2wkJIp+D131pPLr58r9tV+Cr41nHf4rF/epSPHfYxDAychevwTb+NR3b/mjNue5yb//4ukbiufMv4NB7id196Y7uwt3XYS1brMOZ9DAr3LFOeM4+Lj7iYRz76CD8946fML5uPYYvjLl9F3sxbearhAT7838/ypf99nU1NPYeqGiL7bSzG8ON1j3P/1vtZlXiIS8+0Wl7+7+odPPxWw4i9h8hEMBbjF+Azx9UyqyBNJJHmX+9bp66TInsxVmP4QHX91WodVnDeR7A9/wNIRmHqSXDkBZxUcxK/PPuX5DvzaUm8y/S5fwYjxr/e9xaPvd04yiUXOXDDTojddtttXH755Vx22WUceeSR3HXXXfh8Pu6+++5B17/77rvp6OjggQce4MQTT2TatGmceuqpLFiw4IALPxgzmaT7kUeAft0lNz8J3TvBWwxzP/qBr1HuK+e7J3yXv573V5ZULcGwJXGXPYtz2o+4+617+NB/P6c7Usq4NNbjd1/idXVE3nwTbDYKPnwudO3q6wa99Mp9bmszbJxaeyp/PPeP/Oep/8mU/CnYHEE8VQ+SN/O/eGrXP/jwfz/HzX9/l3A8efArI7KfxmIMf3j6h7lw5oWYmPxh+81cdGIcgGv/bx1bW4Mj9j4i491YjF8Am83gMzPT+Fx2Xt3ewf+urhvR1xeZKMZqDB+IZGcnPStXAlC0ZCq88wAYNvjQLZC5wdwxFcdkk2JtyY1MPfLPpInz9T+v5amNzaNYepEDN6y7TMbjcdasWcN1112XXWaz2Vi2bBmrM3d0fL+HHnqIpUuXcsUVV/Dggw9SXl7OZz7zGa655hrsdvug28RiMWKxWPbvQMC64pxIJEgkEoNu07u854UXSLW1YSsuxn38EhKJBPZXfokNSC24mDQO2MtrvN+M/Bn87PSf8XzD8/zXG//Fjp4deKr/RlPPRj7xq49xyeIjWLFsFj7X6N6ss7fue/vfTFS5Wm8YWPeh1n88xO++6tKRGRfQt/R4KC4m9Y8bsJsp0tNOIVV2xJDj+oyaMzi5+mT+tuVv/PLtX9JJG97JfyQZmsEvX7qIR95q4LvnHcFps8uH9HoHSt9j1X0ixPC/Hv2vbNyxkY3JjbzUcysLZlzFW9t8fPUPa/jrl5bgdQ3+XhOBvse5V/eJFr+JRIKUs4X/d+ZpfO/v7/HDxzdy0swSppb6hlS38SxXv8OguvfOJ0oM958PR9f992MmErjnzMaz/j8ASC38IunSwwccW88pnMOdp9/JV5/+Kh2JjUw+4k/sfvczfPkPb/Crzx7DCTNLh/3eI0Hf49yr+/7E774MK5Pz/9u78/ioyquB4787+5KZ7JksJCRh35Edl6ICYt1rW61tlVprWyu+tnRR26q17Vuqtr5ape6KWxVtFeuCiijIjrIrEAgEErLvk8y+3PePSQYiAQkkJJk5389nPpPczJ37nGRO7r3nPvd56urqCIVCOByODssdDge7d+/udJ39+/fz0Ucf8b3vfY93332X4uJifvaznxEIBLj77rs7XWfBggXcc889Ry3/4IMPsFiOv3Mufvpp7ED9iBHsXrYMq6+aWfs/QkXhI2c+7pO8Z/uHmh+yzrSOD7zL0Nt2ojUd4sVtV/P25oN8d1CIwYkn9bbdallbdT/exGvcEInd7T6xse36Q/4e82+pquS/+hoGYF9uLkVvPMd5u59FC2zQTKbmJPLaho15pnmsZjWrfavBup+Ewgepqb6IG1/wMD5F5cqCMImGLr/1SYn3z3G8iqUcvsp6FYtaF1EaKEU1/R82800UVcONjy3ju4PDJxRjfxbvn+N4FAv5G1bDvO99n3W+dXw31MgQ+wj2OuEnT69i3qgQGuWEwuv34vUzDBJ7f8/hL8fTJarKwEXPYQSUjGqU1mpajFmsDEwhdIxj6+8Zv8eiwCKa1d2kFyyituQH3Pj8Z9wyKkReQtc2353i/XMcj7qSv8fT412bwuEwGRkZPPHEE2i1WiZOnEh5eTn333//Mf8R3HHHHcyfPz/6vdPpJDc3lwsuuAC73d7pOoFAgOVvvUXirt2owJj/uQXTqFFoPrwTAHXQTM79xg9OKZZLuZTrGq7jt2t/ywHnASx5T9FSfy4P75zFtVPz+c2coZj0p/8qeCAQYNmyZcyePRu9Xn/at99b4jVu6Bi7x+Ppse2czvw93t/Ss2UL5Q0NKGYzZ910PYZXr0QJewlnncGk79we7dJ9Mr7BNzjUeog/rP8Dm2s2Y8pagt7+Bdsqvsnez1P51ewhfG9KLsopbON45HMsscdSDj91yVP8dMVP2d+8H8fwl3Ht+AEbaq3MnjyCudMH9kiMvU0+x/EXeyzlr6qqbFi7gfDBMP/x/Zs/f/thfv5CI/taQtSljOIHMZq37eL1MwwSe6zkMJz839KzdSvlNTUoRj156btRNTpM33uBOVnjj7vetNpp3PzxzbjZT9bQl6nc813+VWrjjZ9OJTXBeMLb7w7yOY6/2Ls7f7tUEEtLS0Or1VJd3fFe4erqajIzMztdJysrC71e36Fb6IgRI6iqqsLv92MwHN39wmg0YjQenUx6vf64f+yEHTtQfT4MgwaRMG4cSnMZbHkRAM3UH6Pphg/KGMcYFl+ymHs/vZfX976OMe1jdJZ9vLj5O2w95OSxayeSk2Q+5e2cjK/6/cSqeI0bIrEHgyc25lVfz9/jvabunchVKvvsmRjf/jHUF4N9AJpr/oWmkzZ0VUFyAc9e+Cwv7XqJhzY/hM+6F/vgB3FVXsI9bwdZVdzA/d8a26M7+Xj/HMdz7LGUw2nWNB6f/Tjff/f7VLvLKBy9mOJt3+cvS4soSLcxc4TjuOv3Z/H+OY7H2GMlf++adhe7y3ezL7iPv2y+jZ/Nvo+/vVPL35ftZdbILArSrCcUY38Wr59hkNhjIYe78poj1b6xBAD7ABdagwrn/RZ93uSvXG9S9iQem/0YP1n2E1qDu0gpfJHK/d/n1ld38OKPpqLXdnmY8lMW75/jeIy9K/l7PF36tBoMBiZOnMjy5cujy8LhMMuXL2f69OmdrnPWWWdRXFxMOHz4dok9e/aQlZXV6T+BU2HfvAWIzECnAPz3FvC3QO40GDy727Zj0Vu458x7uH/G/dj0NrSWUhIK/8HO5vVc+vBq1hbXddu2hOgufT1/jyXs9+NcuhSAxKQ9ULYejInw/X+DPbvbtqNRNFw78lpeu/Q1xqaPJax4MWf/G0vu83y8dz8X/WMV6/bVd9v2hOiq/pLDmdZMHp/9OHaDnWrfHgaNep2wGuKWl7fwRUVzj2xTiL6uL+evXqvnGus1DEkaQr23ng/q/syUQSa8gTC/+fc2mXVSCPp2Dp+MUGtr9Pg6Kd8JedPhrJ+f8PpnZJzBo7MexawzEzAUkZD5IRtKGljwbue3jwrRV3W5fDt//nyefPJJnnvuOXbt2sVNN92Ey+Xi+uuvB+C6667rMNjgTTfdRENDA7feeit79uzhnXfe4S9/+Qs333xz90UBBCoqsOzfD4pC4qWXwKZnYf8K0Jnhin+Cpvsr1RfmX8i/L/s349PHg8aLZcDztBqX8f2n1/PUqv2oqhxAiL6lr+bv8bR+vIKw04ku0YTFuwK0BvjOS5Axoke2V5BYwPMXPs/PJ/wcvUaPNmEX9kEPUxfcxXefWs8DHxQRDMX+eEiib+ovOTwoaRALZy7EpDVRE9pK/rAPcPuD3LDoM6qavT26bSH6qr6cvybFxMPnPozD4qDEWYI28zmsBpVPDzTyxKr93b49IfqjvpzDXeV8+x1UjweDPYA52wjfeBw0XRv6Z6JjIveecy8AmqRVaMwHeWZNCW9sOdQTTRaiR3R5DLGrr76a2tpa7rrrLqqqqhg/fjzvvfdedIDB0tJSNEcUn3Jzc3n//ff5xS9+wdixY8nJyeHWW2/ltttu674ogJa33wbAPGUyerMf3v995Aez7obUQd26rSNlJ2TzzJxnWLBxAa/teQ2jYykaYxV/fvdKth1q5t5vjun1WSiFaNdX8/d4mv/7XwASs2pRNMAVj0LBOT26Ta1Gyw1jbuDsnLP59Se/pqS5BMvAJ/HVzuQfH4VZt7+eh75zBtm9dHu0iF/9KYfHZ4zn3q/dy88//jn1mpVk5yVTUTqNG577lFd/Mh2rUfaNIr709fzNsGTwz1n/ZO7SuXzesIVR421s3Hgh9763m+wkM5eN675e2UL0R309h7ui6V/PAZBU6Ea55AFIPrnxAs/LO49LCy/lrf1vkT3ovxz64qfc/p8dDMmwMTqnD8w6J8RXOKmj0Xnz5jFv3rxOf7ZixYqjlk2fPp3169efzKZOiKqqtLz1FgC2Sy6GN+dBwAV5Z8KUn/TYdtvptXrunHYnQ5KHcO/GeyFpC1pjHW9/cS17q1t4/NqJDEyN/fEXRP/Q1/IXwP3pp9g2b6ElFEarO3x1Sg2GaF0ZaZM93wOz/wRjvtWjbTnSsJRhvHLxK/xlw194c9+bGNM/xJBQwmeHrubrD7Vy37fGMmdU5+NGCNFT+mIOH8v5eefz68m/5r5P76PFuoTktES+qBjBra9s4fFrJ6GNlynshGjT1/N3aPJQHjzvQX764U/Z1fIJE8bb2bz1bH756laSzHq+NjT9tLVFiL6or+VwqNVFywcfYNu27ajj6ChVhVAAgl4IegnV1eDdUwIalcQLz4OxV59SG26bchvrKtdR5ylnyLC17N09g5+8sIm3bjmbFGvv3hoqxFeJicuz3h07CBw4SFivx55aBV+sAr0FrljYI7dKdkZRFK4Zfg0FiQX8csUvcVJGQsFC9pRdy+ULvSz87gTOGpx2WtoiRH/jvO/XZO1uoHrx4k5/bkwKYLrgBjjzltPcssiYgX8++89MzZrKn9b/CY95H/ZB/6D10Lf5yQsBrp02kN9dPKJXZpgVoj/4/ojvU+os5ZWiV1AcL2Py/JgPd8H/vrOLuy4d2dvNE0J8ydSsqfzxzD/y29W/Za/vbcaPSmTrF2P46YubeOlHUzkjL7m3myiEaBOqPEj1b39LFhzzOPpYbPkKuqsePqXZ2gESjYncNe0u/ufj/6FGeZ8cx0jKq9O55eXNPHf9FHS9MMi+ECcqJj6disGAdfYsPGOGolu3ILJw9h8hpfC0t2Va1jRevvhlChMLQddMQv7jtOo2ct0zG3l2TYmMKyZEJ4zpOqwOb+ePLC+OK8fBhQtOeYd9Ki4ddCmvXvIqw1OGE9a0Ysl7FmPGW7ywoZgrFq6huKal19omRF+mKAq3TbmNc3LOIRD2k1z4Ioq+gWfWlPCUjE0kRJ906aBLueWMyEWofeGXGDl0N25/iOsXfSr7OyH6EMVXd+xj6KMePqxZQaw5KgmDjKT//l6wpHRLO87LO4+LCy8mTBh77utYjGHWFNfzwLI93fL+QvSUmOghZho+nKy//w3zg2ejuN2Qfw5MuqHX2pNnz+PFi17ktk9uY1X5Ksw5i/E3lHLPWwF2VTr50xWjMXbWnVWIOJW8YBGrPnyXc772NfS6L/1b0hp6dBzArshPzOfFi17k75/9nZd3v4whdQ1G2z72HLqaSx9284fLRnLVpFyUXizcCdEX6TQ67p9xP3OXzqWosYjcES9T+vkP+fM7u7AadVwzJa+3myiE+JIbx9xIs6+Z53c+zyHtcwwq+CH7SoZw7dMb+c9NZ8o4mkL0AfrC0eRelUGtV0da/ig09iywZUKCI/JsSQOjDYwJoLf26N1Tt0++nfUV6znkKmHm9G28teIMHlu5j5kjMpg4sHsKb0J0t5joIQag+fRJ0t17UPVWuPyR03ar5LHYDDYePv9hfjI2MoaZIWUdlvwneG3rF1zzxHpqWmSWLSGiEgfQYh4A6cMjs0ce+egjxbB2Rq2R3079LQtnLiTFlIJqqCKhYCFB2wpu+882bnl5C05voLebKUSfY9VbeWTmI2SYM2gMlDF49OtAiN++sYM3t5b3dvOEEF+iKAq/mvQrrhp6FSoq9eZF5OTspbLZy7VPb6DB5e/tJgohLCkEf7yadYN/Q+iyhTD7Hph2E4y+EgaeCelDwZ4VKYr18PlxkimJO6ffCcAnNa8xc5yPsArzX92Gyxfs0W0LcbJioyBWV4zm4z8DEJ75B0jO79XmtNNqtMw7Yx6PnP8INoMNrbmUhMJ/sK1uE5c9vIZtZU293UQhxEn62oCv8fplr3PugHNRlSAmxztY8p7mnZ27mfN/n/BxUU1vN1GIPifTmskjMx/BrDNTHdjBkDFvoBJg/qvbeP+Lqt5unhDiSxRF4XfTfsdlgy4jpIZwJz5HesZ+9tW6mPvMRupbfb3dRCFEHzIzbyZfz/86YTVMrel5MhN1HKx3s2Dprt5umhCdio2CWHMZ6M3U2EYRnvCD3m7NUWbkzmDxJYsZljwMtC4seU/RoHufbz22hic+2Uc4LOOKCdEfpZpT+cf5/+Cu6Xdh1pnRWvdhG/Qgtazh+mc38qvXttHslt5iQhxpROoIHjj3AQwaA1XBzxg48hVCqpdb/rWFT/bU9nbzhBBfolE0/PHMP3Jh/oUE1SCh9EUkpRxgR3kz33psHaX17t5uohCiD7lj6h2kmFIoce5j+qRPAXhxfSkrZR8v+qDYKIgNOo/gj1ezJe/GXh10+3hybbm8eNGLXDboMlBUjI6l6LIWseCDDcx9diM1TrmFUoj+SFEUvj3027x6yauMSh2FqvFgzn4Ny8AneH3HJmb/30o+3Fnd280Uok85O+ds/jnrn5h1ZhrCX5A9/Hn8ais/fuEzNpY09HbzhBBfotVo+cs5f+G83PMIhP3oshfhSK+gpM7FlY+uYceh5t5uohCij0g2JXPXtLsA+LBiMTMnVgDwm3/LhWLR98RGQQwgIQOvoW8P1mfSmfjzWX/mzml3otfo0dl2Yy38P9bXvsuchz5h+S45aRaiv8pPzOeFi17g1gm3YtKa0FpKsBY+RLP5DX70whp+sXgrTW4Zb0WIdlOzpvLUBU9hN9hpYR8ZQ5/BF27mh4s+ZXNpY283TwjxJXqNnr/N+BtnZp+JL+Ql5HicvLxd1LX6+c4T66SHpxAiaubAmVw/6noAtvueINfRSLXTx93//byXWyZER7FTEOsnFEXhqmFX8eolrzI2bSyK1osp63W8qQv50b/e5w///QJvINTbzRRCnAS9Rs+PxvyIN694k/NzzwcljCH1E6yDHuCt4veZ8bePeXp1Cb6g5LgQAGPTx7LowkWkmdPwKIdIGfwkrlAt33liPa9sLEVVZUgBIfoSg9bAg+c9yNk5Z+ML+Wi0PsfAoUtxBXz8cNGn/GfTod5uohCij7h1wq2cmX0m3pAXffbzaLQulmyt4N0dlb3dNCGipCDWSwYnD+b5rz/Pbyb/BpPWhM66H2vhg7y0+wUuefgTVu2Vq2xC9FfZCdk8dP5DPHL+I+Qk5KDRN2Me8CL+tMf4y/J3mPXASt7aViHjBwoBDEkewvMXPk9OQg5+TQ0pg58gqKnk9td38KvXtuPxSwFZiL7ErDPzyPmPcNO4m1BQaNCuJHvE04Q0DfzytW0s/LhYitlCCLQaLfd97T4GJAyg1lvJ4NFvAiF+98YOalpkuCDRN0hBrBdpNVquHXktr1/+OlOzpqJoApgc71BhuZcfvPICc5/dwJ7qlt5uphDiJM3IncEbl7/Bj8f+OHKbtLUYS/7j1CU8yM/ffI3L/7maDTJekhDk2nN57sLnKEwsxK80Yh+8EEPqJ/xncynf+Oca9te29nYThRBH0Gq0/Gz8z/jnrH+SaEykRS0hZehCtNYi7n+/iGueXM8+yVsh4l6iMZGHzn8Is85MpX87WQUf0+gOMH/xNrkrSvQJUhDrA3JtuTw5+0nuOfMeEvQJaM3lWPKe5VPfPVz85BPc8fp2altkWmsh+iOzzswtZ9zCW994i28P/TY6jQ6dtQTLwKfYp/0rcxe/yKO7FNbsq5cr6iKuOawOFl24iOlZ0wmpfowZ72IvfIw9DcVc9sgaucVCiD7o7Jyzo5PK+NVWLHmLsDiWsb6kmq8/uIqHPtwrwwQIEeeGJg/lT2f9CYBW04eYk7axuriO7z21gUaXjK8repcUxPoIRVG4csiVvPWNt5g7ci4GjRGtuQxT7iLerLmNcxf+k4eX76HZIzNzCNEf5STkcNf0u1h65VK+O/y7kRy3lGLJW0Rp8iPc+OZDnPt//2XRmhKcXslzEZ+STck8Pvvx6AUi1VhKQuHD+BM+4GcvfcqdSz6nQQ6ehehTshOyef7rz3PV0KsAFW3KclKGPYBqW8v/fbiTix5axYb99b3dTCFEL5qTP4cbRt8AgCXndWz2ajYdbOSbj62lrMHdy60T8UwKYn1MmjmNX03+Fe9/6z1+MOoHGDQmtOZDaLKe4dG9/8P0hX/gllc/ZPuhpt5uqhDiJGRaM7lj6h3RHDdqTWhNlZgy36Y+5U7u3Taf6Q8v4Devr6eoSm6ZFvGn/QLRksuXMGPADFQliDHjAywFj/DS1tV87b6PeWDZHikcC9GHGLQG7px+J/eecy8Oi4OA0ogpawm2IX+nNPAxVz+xhtv+vZ2qZhk3SIh4dcsZt3BWzln4wz4sA58kLXs9+2ubufLRtXxe3tzbzRNxSgpifVSaOY1fTvolH3zrPX4w8gfoNUa05nK06f9lhecXfOedb3POE7/h/z5ZjssnJwVC9DftOb70ine5xHwJo1PHoigqOmsxmozXeLf5p1z+7x9xzj8X8Melq9hZ4ZRbKkVccVgdPHz+wyw4ZwGJxkS0pkqsBQsJZz3Io5te4Oz73+WfK4px+4O93VQhRJuLCi/inSvf4Y4pd5BuTgddI6as17EO+jv/2fsGZ933AT97aRPr98swAULEG61Gy73n3Mvo1NG4g634EpeQPPQfNKhbufrxtTKpXBxq8Dbwnz3/4a19b1Hq7J3ZxXWnfYuiS1LNqfxy8i+5fsz1vL3vbf67dxlFzdvQmqpoYinPlCzlmb2JJAYH8dnKOr4z9lxGpheiKEpvN10IcQKSjElMM07jj3P+SLW3mqUlS/l30X+pcB9Ab9tJEzt5reZfLH4nBVNwOJMck7l69PnMGFyAViN5LmKboihcUngJ07Km8bfP/sb7Je+D+RBa8yHC4bf5x/bRPPXpNH427UKunJBLitXQ200WIu4ZtUa+O+K7XDnkSl7b8xpP7XiKBhowZ/8bNfQWH9WN4v1/jaXQOp650wfzjTNysBrllESIeJBoTOTFi17kzX1v8tDmh2jw1mDJfY5g6xB++FIl/3vJbL49cYCcy8awUDjEmoo1LClewsdlHxMMH76wmWJKYWzaWMZljGNc+jhGpY7Corf0aHtk79NPpJhSuG7UdVw36jqavE0s3fcRi3e+x77WTaBrplm3mSXlm1lS/iBa1U6+dQwz8qZwwaCpDEkegkErJwlC9HUDbAO4ceyN/GjMj9jTuIe3iz9g+cHVHHIXoTE04DesZW3LWtauewhWOsgwDGd8+nguHnomMwqGo9VKp18Rm9LMafz1nL/ym8m/4e19b/NG8RsUNxWjT9xKgK38X9Er/O2zMYy0n81VY85kzqhskqU4JkSvMulMXDvyWr455Ju8WvQqL+x8gRpPDfqkzeiTNlMZMvHnDaO4d8V4Lhx8Nl8fncuZg9Iw6bW93XQhRA/SarRcOeRKLhh4AU/seIIXd74ICXvRWh/kztWrWbhuOjdMmsk3J+RJsTyGlDpLWVK8hDf3vUmNuya6fETKCAxaAzvrd9LgbWDFoRWsOLQCAK2i5Zk5zzDBMaHH2iWfsH4oyZTENaOu5JpRV+IJeHlhy4f8e8v71GlL8WsPEtI42edew77da3hmNyhoSdXnMSxlONMGjGVcxiiGJQ/r8WqrEOLkKIrCsJRhDJsyjF9OuQVXwMWaQxtZsnsFW2o/pVUtA0M1NVTzQe1KPqh9CD6xkaIdwoiU0UzOGcG5BWMoSMpFo0iRTMSO9otD1468lp31O/nP3tf5b/E7+PRNaFJWsZdV/Gm7nXvWjma4/WyuHn0O5w/PJMNu6u2mCxG3LHoLPxj9A64bdR1ba7bywcEPeK/kfeq9deiTNkHSJpa2Pss7KzNRPshlaNIIZg+eyNVjp5CaIMeqQsSqBEMC8yfO59tDvs3fPvs7H5Utx5D8KQ18yn07n+L+TSM4M+tcfnHWJQzPTOvt5oo2u+p38ecNf0ZVVX4w6gfMGjjruOcbexr38OjWR/mw9MPosiRjEpcUXsIVg69gWMowAPwhP7sadrGtZhvbaiOPanc1g5IG9Wg8UhDr58x6E9efMQdHZYiLLrqIg00tLN6xllWlGynzfI5iPARaD3WBEuqqS1hTvTS6brI+i0FJgxnvGMGI1GEMTR5Kri0XrUauzAnRl1j1Vi4oOI8LCs4DoMZVy3+L1rHy4Kfsbd5BKwdQtC00sJk1DZtZ0wAP7gBF1ZOoG0C+vZDR6YMpTHGQYkohyZREsjGZRGMiicZEdBrZFYj+RVEURqWNYlTaKH4z+desKV/DG3veZW3lKgJ6J5rktRSzlj/t+Cd/WF9Iim4Ykx1ncOGwCZw5KINEs763QxAi7mgUDRMcE5jgmMBvJv+GLTVbeK/kfZaWLKPZX4fWVAGmCorVDRTvXcQ/i3SYySXfOpzJ2eO5eOhUGRZEiBiUa8/lofMf5NOqT3mt6A0+Ll2BV9cCtk2sbd3EmqUPkaiMZELGeC4YPJGz8saTYkrp7WZ3KhAK8Pb+t1lXuY7vDPtOj/ZsOt0CoQBP7niSJ7c/SVCN3Ob4y5W/pDCxkBvH3siF+Rd2OKcobizm0W2P8sHBDwBQUDgr5yy+MfgbnJt77lF3sBm0BsalR26VbFfnqSPRmNijcclZUIwZnJ7C786/BLgEbyDE5+VNrNi3hw3lOyhuLsKrlKIxVaDRO2kMVPJZbSWf1a6Krq9VDKSbssiz55CfOIAcWw7ZCdnkWHPItGaSYkqRgpkQvSzDms6PJlzGjyZcBkCr38Nbuzay/MAG9jYW0RAoQ9XVgCZAU6iErY0lbG1c3ul7KShkJ2Qz0D6QfHs++Yn55NvzKUgsIN2cLvku+jyTzsTMgTOZOXAmvpCP9RXreb3oXVZXrMSva0WTuJ0WtvNR62ss32gg/MlA0nRDGZU2isk5w5hROIzCNLucZAtxGmkUDRMdE5nomMhvp95BlauKHXU7WHFgM59VbqfKWwwaD15K2O0pYfe+pbywD5SwhTT9YIYnj2S0YyAjHXlkWjPIsGSQbEyWPBaiH5ucOZnJmZMJhoNsrt7Ci9vfYU3lSvyaOpxsZ0XtdlbUPg/rwKJJZUjSMCZnjSEQ8NIaaCVZn9xrbXcH3Ly+93UWfbGIanc1AEtLlvLNId/kFxN/0eNFnZ5W1FDE79f8nt0NuwGYPXA2hYmF/GvXv9jfvJ87Vt3Bo1sf5UdjfsSotFE8teMp3it5D5XIIPlz8udw07ibutzbK83c8z0DpSAWw0x6LZPyU5mUPx2YjqqqlDd52FzaxMaDpeyo3UWJcx8+TTlaYxUaYxUhjZ8qz0GqPAfZWH30e2oULWnmVDLMGaRb0smwZJBqTiXJmESiITHybEzEbrRjN9ix6CzoNDo5QBGiByUYzFwzbgbXjJsBgKqqlNQ5+Xj/btaX7WRPQzG13gpUTSuK1h156FwoWg8qKuWt5ZS3lrO2Ym2H91VQsBvt0d5kScYkkoxJJJuSOzynmFKiP7PoLeg1esl50SuMWiMzcmcwI3cGgVCALTVbWFv+KavKPmO/8wuCWg9a614a2cvqlndYvRse2KVBCaZi12YzICGPEemFjHUUMMYxkBxbtgwvIEQPUxSFrIQsshKyuCD/AiCyH1tXupulez9lS/U2yj17CGjLQOOmNrSd2rrtrKoDvjj8PlpFT6opjZyETDKtkYfD6iDTEvk6zZxGiikFvVZ6iArRl+k0OqZkTWZK1mRUVWVlyXae37aMXfU7cYYPoBjqcIfr2dawlm0NkWPX5197nhzLIKZmT2Ra9iTOyDgDh9XR421t9jXzyu5XeGnXSzT6GgFIN6czLn0cH5Z+yH/2/oePyz7mN5N/w0UFF3V6fBxWwxxoPoCiKOTb8/vUMXQgHODpHU/z+LbHCapBkoxJ/G7q75iTPwdFUZg7ai6v7H6F53c+T2lLKXetvavD+rMHzuan437K0OShvRTBV5OCWBxRFIUByRYGJFu4bFw2MA1VValyetlZ4eTz8ka2VO5nX2Mp1Z4q0DWg0Tei6Bsjz7oWwoSocddEBsKrP7HtahUtJp0Jo9aIWWfGqDUCkeQPqaHDz+EwRp2RZFMyKca227qO+NpmsGE32KMPs8YsU3YL0QlFUShMT6QwfSo3TJ0KQCAUpqTOxa5KJ7sqW9hV6WTnoUbq3I1oDHVojLWRZ0MtGkMtiqEBlDDNvmaafc1d2r5G0WDSmjDpTJh1Zsw6Mxa9BZveRoIhgQR9QiSHtWYOeA/g2uvCrDej1+oxaAzoNXqMWiNGnRGTzhR9L6PWiEVnwawz96mDBdE36bV6pmRNYUrWFH4+KTKrUXFTMSsObmTlwY0cbCmhJVQBSgD0tTipZad7GzsPwn8OHvE+JJBszCDLmkmmLYU0SyJ2g50EfQI2gw2L1sKB4AFKmktw2BzYDDYZu0+IU6QoCmcOHMGZA0dEl1U5W3l79ybWlG2muGkvDb46VG0Tis6JRucipAao8VRS46mE2mO/d4I+gWRTcuSijiGJFncLX2z6gkRTYjSvE/SRfZVOo0Or0aJVtJGvFS1ajRaLzoLdGPk/IPne/Vr9rZQ0l1DiLKGkuYT9TfspcZbg8rswaA0Ytcbos1FnxKqzUphUyJCkIQxJHkJ+Yj56jRQ+Y4GiKJxbOI5zCyO30TW6/HxYVMrSok1srv4cr+YgWvNBNIYGDrmLOVRczH+KFwNg1Fix6q3YjQnYDQlY9JbI9wY7GZaMaMHcYXXgsDiwGw73FldVlWA4SCAcIKgGafQ2UuOuodpdTa27Nvr12oq1uAIuAAYkDOCHY37IZYMuw6g1srl6M39c90f2Ne/j9lW382bxm9w57U4cVgdf1H/B5urNbKnZwpaaLTj9TgAcFgfTs6czPWs607KnndStof6QP/q/qitC4RBV7ioONh/kgPMAB50H2Vi1keKmYgBm5s3k99N+36HXls1g48axN/K9Ed/jtT2vseiLRdR56jg/93xuGn8Tw1OGd7n9p5sUxOKcoihkJZrJSjQzc4QDiHxovYEQ+2td7Kluoai6hT1VLeyvc1LWXEtY24xG14yia0HRN6NoXYd7nWjdaHUeFK0bVQkAEFJDuAKu6D+Lr1LWUnbC7deg4e//+Ts2gy36aD9RAfCFfPhD/g7PWo2WFFMKKaYUUk2ppJhSSDYlYzPY8IV8eINePEFP9OEL+dBr9JET87aTc7POjElnQkEhpIYi/yzDQYLhICE1hIKCVW+NHFC1FQASDAlYdJbI60MBAuEjHqEAJp2JRGPkYExO9kV302s1DHXYGOqwcfn4w8sbXH721bayr6Y18lzrYl9tK2UNLaiaI3uTtee4C0XrQqf3YDZ50endoHURUFvxq24gUux2B924g+4Tatu7n77btVg0epJNyaSaUiNF87YcVlAi2w1Etu0JeHAH3YTVcGS8NEOk92p7T9YEfQKBcODw/4iwP/r1sYrteq2eBH0CVr01muMWvSXaG/bIEyadEvneqrf2+67ysUCr0UYmq0gZxk/OuBaIfFYPOatYfXAnn5XvYU/DPqo9FbjDdSi6JhStlwCt1PhaqfHtZ1vDsd//qXeeimxH0UZPtlOMKR17UpoO96y06qzRz45Fb4n2rhRCdC7TnsCPpszgR1MivaGDoTD7al1sO9TE1rI6tlSUsq+hnLCmGUXfFDlW1Tej0Tej6JrQ6FyghGkNtNIaaO1wvLmlaMtJtUlBiRbR7EY7Bq0hciwYDhFSQx2ODUPhEEE1GLkQfMTXGkWDTtGh0WgihTclUoQzaA3RC0LRZ50Ji85y+CKx0d7h2FdFjW4/qAaj23cH3bgCLlr8LdHnFl8Lh1yHWL1mNUadMXpRyqA1oNPo0CiayANN9GtFUTBpTZELVm3Hw0bt4YtX0SJVW8Gq/WLWscYqDYVDlLaUUtRYRFFD26OxqMMMdCfqo7KPol/rNDoKEgsYkjSE6dnTuWLwFSf19xV9T7LVwLcnDObbEwYTDl/F54caeWHpalr0CWyr20pDaA9a8wE0pgp8YRc+n4sG34l9nkxaE4qiEAgFomNknYjBSYO5ccyNXJB/QYfP+gTHBF679DWe/eJZHt/2OOsq13HFm1cA4A/7O7yHWWcmFA5R7a5mSfESlhQvAWB4ynCmZE5hcNJgChILyLfnk2RK6rBuo7eRHZU72Fy9mc3Vm9nVsAuD1sDQ5KGMSBnBiNQRjEgZweCkwei1epq8TRxwRi7ktRe+DjQfoLSllEA4cFR8doOd30797TF7uEFk8pS5o+by3eHfxRPyYDfYT/j319ukICY6ZdJrGZltZ2R2xw9zMBSmoslLSb2LA3UuSupcHGp0c6jRQ3mdhxbfEf88lCAoARRNIPqs0fhJtWlITzCSYTOTYTfjsJlx2C1kJ1owG0O0Bppp8DXQ5G2iwdtAo6+RJl8TLf4WnD5n5NnvJBAOECZMk6+JJl/T6f0F9SCtoo0e5LSfwP/prD+dlnuoRfxJsRpIsaYwOb/jFShvIMShRjclde5Irrfl/IE6F5UNXnwqHF3iDoEmgKLxYzOrZCVpyUhUSLFBoiWEyRhEr/ei1fkI4cHpc7KvdB/pmekE1SD+UKQgdWSRqr0o7Q168Ya8QKT7drSnaj/wzSHf5A9n/qG3myE6oVE05CVm892x2Xx37Kzo8mAozIF6F1sOVbG1ooTd9Qcpc1bR5HWCxoui9aBovChaL4rG01Y0dqFovYTUEHWeOuo8dV1uj06jQ6/Ro1W0kZPktpNSraKNXtVunwyj/WuLzhLtwdL+2vZ1O5xIH9HT0hvydjg5bg200upvxaA1RG8vc1gjk3Ccjt4voXAIX8jXZ3p/qqqK0++k3ltPvaeeCRkTZDzFPkin1TAs08awTBtXTcoFzsAfjPSG3l3lZHdVC0VVLeyudFLR7AXCkfzVudBoXSi6yDACGq2LRGsIqzmIyRhAp/ehaLyEFS8aJYxK+KiiljvgxhvyoqLSEmihJdBChauit38lJ2XnwZ09vg2dRhft4d3+UBSFkuYSPEFPp+ukmdMoSCygMLGQgsQCCuwFJJmSoscKR17sbvQ1UtxUzN7GvRQ3FeMKuNjbuJe9jXtRFEUKYjFKo1EYkWXj7EyViy46B73+fOpafWwpbWJ9SQVf1JRxoKGBWlczisYHGj+KxhfZX+udaHTNaA1OtIZmwoorepzZGbPOTIYlo8PDYXEwKGkQUzKnHHNfqdfq+fHYH3Nh/oX8cf0f2VC5AYjMmj0hYwJnZJzBBMcEhqUMIxQOsblmM+sr1rO2Yi1FjUXsbtgdHberXbIxOTrW72bnZn7/+u+P2q4n6InO1Niu/SLt8e780Gv05NnyGGgfyMDEyPjCMwbMINWcety/xZHx9rfb0k+qILZw4ULuv/9+qqqqGDduHA8//DBTpkz5yvVeeeUVrrnmGi6//HKWLFlyMpsWvUyn1ZCXaiEv1cKMoelH/bzZE+BQo5vyRg9ljR7KGtyRR6Ob0gY3Xl+Yag9UdziP9bc9mgBItujJsDlIt+WRYTOSbjMyxG4iy2EiM9FEVqKJ9AQjHr+LJe8tYco5U/CEPTj9kWJZ+0NRlA5XqQyayFUrf9hPg7chUmzzNka/bvG3RK526c0deoGZtCaCahBP0BM5KW87MfcGIwdC7VfydBpdtEdIWA0fPsloO9H4cm8ZraJFr9Gj1+jRaXSR9w9FTqYafY3R+9ABdEr31q4lh8VXMem1DM6wMTjDdtTPfMEQFU1eDjW6KWvwRIvipQ1uDjW6qWv142wBZwsUHaPDp0GnIdNuRB+YSoqaRU6yhQybkcxEE5l2E462h0F3+ABDVVU8QQ/NvuZo3h6ZxyhEetu097jRRbrGAzT7m6O3fzb5miLF9UBL9Gr4kVe19Vo9Gjo/sPGH/dEer62BVtwBN62BVjwBT7Q3wJd7BXT3LJ6Svz1Pp9VEP//fnjAkury993SkN2UrxTWRx/4yJ/6wAkqwrTDWekSRzIWic2E0eDCbPOgNHtC6URU/QdVDIOwlqEauyLZ/bvoKvUZPhiWDdHM6Fn3Hk1mzzoxe0bPbs5vNGzfjDUV6V7f3ztQomuht09FnrYmQGuqQu43eyEUvFZUEfQLZCdlkW7MjzwnZZFmz0Gq00Z7Y7T2so7eytP3Ojvy6veDX6m+lJdBCqz+yL/YEPdFbr616K2a9Gasu8uwKuKj31EeLmUdeJf/4qo+79aKU5HDPMegOF8kuP2J5syfAvtpW9te62N/+XNdKSZ0LX0il5jjDgKRYDeSmWMhLsZCXYiY32UJuigWHXYvVHMQbbo0eg/pD/g7Hg0febtle4G4/bmwvYLcPHdLeq6x9H+IP+Tscc0ZzLOCObs/pd+L0OXH6nbQGWjvc2tm+fZ2iw6w3Y9PbOty9YNaYKdpVxJARQwgTxh/2d7iDIayGOzzae58FQgE8ocgx8ZF3Vny5SHVkD5hgOBhpa9ttYUcyaU0MTR7K0JShDEuO9OIdlDTopHuYqKpKhasiWhAbkjzkq1fqAsnfvi0twcjskQ5mj3QAZwDg9gfZX+uK7rP31rRQXNPKgRo3oXDbHQFKAEXXEvla1aKgxZFgYWCqnYEpdgam2MhJNjMg2UxOUuSYVaM58Qs4efY8npz9JLsadmHRWRhoH3jUBSC9Rs+Z2WdyZvaZzGc+dZ46NlRuYHvt9miPrkpXZeQ8saaxw7qDEgcxwXG4wOYL+dhVv4vdDbvZVb+LnQ07afG3RIthmdbMyGRaR0yolZ+YT6YlM+4uAHX5KH3x4sXMnz+fxx57jKlTp/Lggw8yZ84cioqKyMjIOOZ6Bw4c4Fe/+hXnnHPOKTVY9G2JZj2J5kRGZR99e5CqqtS2+iitd1Pe5OFQ4+ET6UONHsobPfhDYRrdARrdAYqqW465Ha1GIT3BgCmczOoWJ1lJFhz2HDITjeTZTDhSIyfVVmPf6QQZCofwhrzRA6XO/tl4g97owc2RJ/A2w9FFiZMlOSxOlVGnpSDNSkGatdOfu3xBytqKZaVtRfGKJg9VTi8VTV7qWn34g2FKGzyAwr4dVcfcVlqCkazEw8XwzEQTA5It5CZnMyJlMKlWQ5/oUXK6SP72rs56TwcCAd55512mfG0m5U4/B+pcHKx3U1Lv4lBDZB9X3+jHDxx7rxZE0fpJtUG6TU+6TUeazUBago6UBD0pVi0J5hAanQdXoCW6f3D6nbgD7g4n1O1fB8PBTntZeoIeTFpTh9v520+SfSEfVa4qqlxV0aJQ+6Qbx1XcPb/f1kArexr3sKdxT/e84SmyGWykmlJxB9xg7p73lBzuHYlmPRPykpmQ13EWOq/Pz7+WLGXI+GlUOH2UNrgpbdt3lda7aHQHaHD5aXD52VbWdNT7Kgo4bKbISXKylQHJaWQnmclJMpPRduJsNvTNk8tAIMC7+9/louEXodd3f4+OsBomEA5EC2buoDta0PMEPYTCIfIT88mz5XXrCbiiKOQk5JCTkMO5ued22/uC5G9/ZTHoGJ2TyOicjuen/mCYg/Uu9ta0sre6leLa1ujdEC2+IJVNUNnUyvp9rUe9p14bGXYoL8XCEEdCdFiSoY4EbKbO80lRFEamjjzhdqeZ07i48GIuLrw4uswdcHPQeZCS5hLKW8qp31vPD+f8kAzb0Z+/wsTC6LqqGplEyxVwkWvLlQmDjtDlasEDDzzAjTfeyPXXXw/AY489xjvvvMMzzzzD7bff3uk6oVCI733ve9xzzz2sWrWKpqamU2q06J8URSHDZiLDZmJSJz8Ph1WaPAFqWrzUtviobfFR0/Zc5fRS3eylstlLtdNLMKxS5fQBCgd2Hvu2KZtRh+OIHieZiUYyE81k2U1kJZnITjSTZDk9M+JpNVqsms4LCO3ax4fIsBx7p3qqJIdFT7MadQzPtDM8s/Oru/5gmGqnl7L6Vt7/ZD1Zg0ZQ2xqI5nmV00uN04c/FKau1Uddq48d5Z1377YYtG1X681kJ5lx2E1k2Ixt+W7CYTNhN8fOTLeSv32TokC6zUh2SsJRtx9DpEgcuRAUKRSXN3moavZS1eyl0umhutmHP6SjrgnqmmAXAIG2x+HbiTQKOOxJ5CRlkZ0U+cwXJpnISTZHv7cf40C8qwLhALXuWqpcVdR766O9pI88sfX4PZQfLGf00NEkGA+Pp2fWmQkTPqpntScY6TmWbDw89l/7s1lnptpVTXlrOZWuSspby6loraDKVYWKGu1NfWTPar1WH+2J0+HnWv3hSTwMCdGvzToz/lCkl6c74MYVdEVPzs06M2nmtOgj1ZwanQSoO0kO9y1ajUKqCaYVpnRaFGrxBjpc3CltexxqjFzc9QbCVDkj+63PDjZ2soVID7OcJDNZiSayk8zRCzzZbcsy7SZ02tgbmF+jaKI9r2NlHE3J39hi0GkY4rAxxGGDMYeXq6pKg8vPgfrIsCEH6l2RzhtNkQ4cVU4vgZAa/X+wurjjEAnZiSaGOGzkppjbJrSLFMkHJFtISzi1C7kWvSUyJljqiEhR+8C7JJuSv3I9RVEYYBtw0tuNZV0qiPn9fjZt2sQdd9wRXabRaJg1axbr1q075np//OMfycjI4IYbbmDVqlVfuR2fz4fP54t+73RGutcGAgECgaMHemv/2ZHP8SSWYrcZFGypZgalHvtSbCisUu/yU1bfygerNpJZOJx6V5Bqp5fqFl/k2enD5Q/R4gvS0tY99lhMeg1ZbSfP6QlG0m0G0m1G0hKMZNgMpLf1UOlLvc2O/Jt35e9+OnJY8rdr4jF2Bci06Uk1JVCbpjJ7Ss5RJyKqqtLgDkSKBm05XeWMFBDK2nqVVrf4cPtDFLVN/nEsJr2G7EQTWYlmcpIiJyI5SWayk0zRWzSNutN7MnIyOSz74L7pRGI3aKAgxURBigkGHf3zcFil0e2nyumLfuYrm33RE+3KtgtCgZAa/ZpjnHzbTDqyE9s/28ZogTjD1v618YR7VqYb00k3Hj08wpGxL6tZxuzhs7ulh0muNZdca+4pv0+3CNPp4MIg++BY8lWxm7QwJN3MkHQz0HEMnfaT5kNNXiqaPBxq8lDR5KU8+uyl1ReM9jA71oUdnUYhO8kUvbiTm9z+iJxIJ/bQRR35u8s+OBb0VOx2o4ax2QmMzU446mfBUJiaFh/lTV4O1LvbbsNsZU9NK9VOHxXN3rZxC49m0mvIT7UyJMPK0IwEhjgSGJKRwIAkc5duwYT4/buf7D74WLp0hl9XV0coFMLhcHRY7nA42L17d6frrF69mqeffpqtW7ee8HYWLFjAPffcc9TyDz74AIvl+N37li1bdsLbiTXxGPu4VKB5Fw5gpAWwAG0fT28Imv3Q5Fdo9ke+bvYpNPmh0a/Q5IPWoII3EKak3k1J/fFnxLPoVFKMkGJUSW5/NkSek4yQoIv0Ejidli1bhtt9YjP5wenJYcnfkyOxH19S22O4mcitS9kQDEODD+p9CvVeaD4y1/0KzQFwt+X4/jo3++uOnSsJ+kg+JxtVkgyQalJJN0GaSSXVCD1VL+tKDss+uG/rztiT2x7R/VomhFVoDUCjL7IPa/BBo0+Jft/oA1dQocUbpMjbSlH1sS8EGTQqaSZIb/ucp5tV0kwqaUawGUDbxX1ZvP7dZR8cO7oj9hwgRwOTU4C2jqLuYCRnG9qOP5t8Co1tz01+aPJH9mWR2zQ9sO/o9zVpI/uhFKNKqglSjSopJkgzRo5LT/WOzHj/u8s+ODb0VuxWYBwwLh1Ij+R8lRuqPQoNvsi+uv252Q/eQJjdVS3srup4IdegUck0Q7ZVJceikm1RybKA9QSuNcXr372r++Bj6dEuLy0tLVx77bU8+eSTpKWd+GCkd9xxB/Pnz49+73Q6yc3N5YILLsBu7/wWnEAgwLJly5g9u3uuUvYn8Rp7d8TtC4SocvqobLsiX9vqo67FT01L5DatmravW31B3EEFdxAOuTo/UzDqNGTaTWQnmQ5f6Us2k5sSub88pRtvzTwydo+n89l5usPJ5LDkb9dI7D0b+5E5Xt7kiVy1a/JS0Ry5gl/Z7MUXDNMaUGgNQFkn+a1RIDvJzMC2AZXzUizRr3NTzFgMXd+Vno4cln3w6dGXYnf7g9HPdUVz5Nbj6hYfNS2RXpY1LT7qXX78YYUKN1S4O/+8pycYcSQaybS3DzkQ6WXmaOth5rAbsRh0fSr200n2wbGjt2MPh1WqW3zRcTcjE1J5KG0bY7eu1Y83pFDuhvJO8hUgLcFAbttg30funwamWo7bG7S3Y+9Nsg+OHf0pdn8wTEWzh301rmiPsr01kYl6/CEodUHpl45DM+1GRmTZmJiXzJSCZEZn29G33WLdn2LvTt2dv106ik9LS0Or1VJdXd1heXV1NZmZmUe9ft++fRw4cIBLL700uiwcDkc2rNNRVFTEoEFH3ztgNBoxGo8et0Gv13/lH/tEXhOr4jX2U4lbr9cz2GJicObxxzZwegOUtw383z4OTHmTh/ImL5VNHmpbffiCYQ42uDnY0Hml2mrQkptiIT/VysC0yHN+qpX8NAsOm6nL3WTb2x8MnviMZKcjhyV/T47E3jOxf1WOq6pKoztARZOn7Va0SJ6XNrg5UO/mYL0Ltz8UnfxjTSdX7zNsRgamtuV022QD7bn9VcWyruSw7IP7tr4Qe6JeT6LVzIicY7/GHwxzqNHNgXoXJXWRz3hJ2xgplU2RMTqrWyKFtO0cPSNcO5tRh8NuxBTUsF2zn0EZdgrSrBSmW8mwGWNm3L7jkX1w7OjN2POMBvLSOp88yeMPUd7UXixrm9G5/vDs7S3eIHWtfupa/WwpO/qWTKtBS16qlfxUCwOPfE6zkGKK7J/i/e8u++DY0B9i1+thiNnIkMwkLjxieTAU5kC9mz3VLeyudLKrqoXdVU7KGjyRoRScPj4uioxTZtZrmTgwmSkFKUzIteMP9Y/Ye0JX98HH0qWCmMFgYOLEiSxfvpwrrrgCiCT28uXLmTdv3lGvHz58ODt27Oiw7Pe//z0tLS089NBD5Ob2kXEihPgKdpMee5aeEVnHHyS8vMlDZbOHQ+0zFLUNwlrp9OLyhzrtIguR3mX5qZET6YJ0KwWpbc9p1m6dRU9yWIiOFEUhxWogxWo4avYhODw77sF6NyV1LkrrI0Xv0noXB+rdNHsC1LRNAPLpgaPHdMqwGblywgBu//rwU26r5K/oDgadhsL0BArTjx4XJRxWqXP5ogP+t49fVtU2oU37xBfRMTprg4CGz9cc7PA+FoOWwnQrg9ITGJSewOCMyHN+mgWjrm/OuHc6SA6LrjIbtAzOsDE4o/OCWbM7EDnWbHRzsN5NaUNkltuD9W4qmj24/CF2VTrZVXl0cduo05Bi0PJ+yzaGZtoZkmFjiCOB/FQrhtM8rmZ/IPkreopOq2FwRmRfedGYrOjyFm+APdUtbC1rZmNJPRtLGmh0B1hdXBcdyF+raHmxYgOT81OYlJ/MxIEppNu6f0KYWNbl+zzmz5/P3LlzmTRpElOmTOHBBx/E5XJFZ9u47rrryMnJYcGCBZhMJkaPHt1h/aSkJICjlgvRnxl0GnJTLOSmdH5vvzcQorwpclXvQH3kYKX9uazBjS8YPubA4DaTjrfmnU1+2vFnqDxRksNCnLgjZ8ftbPbAJre/Qz4fqHNRUh+ZsrvRHSmW+YKhbmuP5K/oSRrN4c/72ONMRtXqC0YmuKhv5d1PNmLNLOBgg4eSOhdljR7c/hCflzv5vLzjSbhGgZy2wcKjA4inRAYOz02xkJ4Q+z3LJIdFd0q06BljSWTMgKMv6PiCkd7NB4/YP7X3fC5r9OALhqkMKlR+Xs27nx/u9aTVKAxMsZCfZo32fm5/zkk2R2/XikeSv+J0spn0TByYwsSBKdxwdgHhsEpxbSsb9tezoaSBjSUN1LT42HaomW2HmnlqdQkAA1MtTC9MZcbQdM4aktZts0/Hqi4XxK6++mpqa2u56667qKqqYvz48bz33nvRAQZLS0vRaOL3H6UQnTHptdEr5V8WDIUpb4qcSBz52F/roqLZQ4s3SGaiqdvaIjksRPdJshhIshgYl5t01M+a3QFK6l3YTd03XKfkr+gLEow6BmckMDDZiHOPykUXDY/eruEPhiltcLO/tpV9tZGxUYprWtlX00qLLxi59avBA9Qf9b52U+R923uqDMqIzL6Vndj12bf6KslhcboYdcc+9gyEwhysbeHV91aSNHA4++s8FLfNyt7qC7K/zsX+OtdR62k1CgVpVoZl2hjmsDEs08bwTBu5yZaYydHjkfwVvUmjURjqsDHUYePa6fn4/X5efGMptsLxbDnkZNOBRvbUtER7ib7yaRlajcLEvGRmDEtnxtB0RmbZ4yJXu+KkjtLnzZvXaddQgBUrVhx33UWLFp3MJoWIWTqthoGpVgamWjl3WMefeQMhDjW6Mem79xYTyWEhel6iRc94S1K3v6/kr+jLDLrDt34cSVVValt8HGjrGd0+HlJZQ+S5stmD0xtkc2kTm0ubOqxrMWij7zkkw8aQtqnqByRb0PbDA3vJYdHb9FoNA1MtjEpWuejsgmhBW1VVqpxe9tW4ONhwuGfZwXo3BxtceAPhaOHsHSqj72cxaBmWaWN0diKjsu2MzklkiCMhJm+RlvwVfYWiKKSa4KLx2Xx78kAAmj0BNh9sZNXeOlbsqWF/rYuNBxrYeKCB+98vIi3BwPRBaZw1KJWzBqcd8+6meNKjs0wKIU6NSa895rgRQgghRH+hKAoZdhMZdhNTCo6+/dgbCHGg3sXe6lb2tvUo21vTQkldZGKL7Yea2X6o46DhJr2GoY7DPVXaH/Fw66UQPUFRFLISzWQlmjmbjjMjthfLiqpaIo/qyPPemlbc/hBbSpvYckQxW69VGJJhY1S2neFZdoa35WdagoxvJERPSTTrOW94BucNz+AuRlLW4GblnlpW7qllbXEdda1+3tpWwVvbKgDITTFzZmEaZw9JY9YIB2ZD7BWxv4oUxIQQQgghRK8y6bUMz7QzPLPj5DXBUGQG573Vreytjpx8761pZV9tK95AuNNCWarVwPAsGyOz7IxoewxKT5CBwoU4BUcWy84dlhFd3j5D3s5KJ1+UN/NFhZPPK5ppcgfYWelk55cG9E9LMDK87VbL9kLZ4IyEbr8bQggBuSkWvj9tIN+fNhB/MMzWsibWFNexdl8dW0qbKGvwsLihjMWflWE36fjmxAF8b2peXHXIkIKYEEIIIYTok3RaTXQcpAtHZ0aXh8IqB+pd7Gmbvbm9x8qBehf1Lj9riutZU3x4nLL23ipjciIDkI8bkMSwTJsUyYQ4RUfOkHfZuGwg0pusvMnD5+WRGS53VzkpqmrhYIObulYfq4t90VnyIDI2WWGaNVogG52TyPgBSSRaZDBwIbqLQadhSkEKUwpS+MXsobh8QTYeaGBtcR3vfVFFWYOHZ9cc4Nk1B5hWmML3pw3kgpGZMb+flIKYEEIIIYToV7QaJVoo+/oR09R7/CH2VLewq9LZ9oh83eILRnurLP6sDACDVsOILBtjBiQyNicpOu5RPM+iJ0R3UBSFAckWBiRbOhSy3f4ge6pbKaqK5ObutudmTyDa+/OtbYffpyDNyrgBiYzPTWJcbhIjs+0xOS6ZEL3BatRx3rAMzhuWwR1fH8Ene2t5aUMpy3dVs35/A+v3N5CWYOSbE3L4xoSco3pwxwopiAkhhBBCiJhgNmgZ13by3E5VVQ41eviiopkd5c3R2yybPYHodPVQCoBRp2FElj3ak2xMTiJDMhLQSZFMiFNmMegYn5vE+C/lZ7XTx64qJ7srW9hZ6WTHoSYO1LujM68v2RoZ70ivVRiZZY+8R14SZ+QmMzDVImMGCnGKNBqFc4dlcO6wDCqaPLyysZSXPy2jtsXH45/s5/FP9jMiy86VZ+Rw2fhsHHZTbze520hBTAghhBBCxCxFUchNsZCbYuHC0ZHeZKqqUtbgYduhJrYfamJHeTNflEd6km0ta2JrWVN0/bfmnc2YAYm91HohYpuiKGQmmshMNHHeEWOTNbr8bDvUxLay5rbnJupd/mgR+7l1BwFItugZl5vE2AFJjBuQyNgBSaTbZOB+IU5WdpKZ+RcM45aZQ1i+q4Y3thzio9017Kp08r+VThYs3cVZg9O4YnwOc0ZnkmDs3yWl/t16IYQQQgghukhRFPJSLeSlWri0bdyjcNu4ZDvKm/m8PNKbbE91K0MzE3q5tULEn2SrIdpjBQ739NxS1sTW0ia2lDXyRYWTRneAFUW1rCiqja6bk2RmbFtxbEpBChMHJvdWGEL0W3qthgtHZ3Lh6Eya3H7e3l7Jki3lfHawkVV761i1t47fLdnB7JGZXDE+m68NTe+XQw5IQUwIIYQQQsQ9jUahMD2BwvQELh+fA0ROwuV2LCF635E9PdsH7/cHw+yqdLK1rKmtt2cz+2pbKW/yUN7kYennVVww0sET103q5dYL0b8lWQzR2SpL6928saWcN7eWs7/OxVvbKnhrWwXJFj0Xj83iG2cMYEJeUr/Zd0pBTAghhBBCiE70lwN6IeKRQac5aszAFm/giLECmzhrcFrvNVCIGJSXauHWWUP4n5mD2X6omSVby3lrWyV1rT5eXF/Ki+tLGTsgkRvOLuCiMVl9vteYFMSEEEIIIYQQQvR7NpOeMwelceYgKYQJ0ZMURYkWpH930QjW7qtnydZy3tleyfZDzdz6ylbuXbqb688q4OopudhN+t5ucqf6drlOCCGEEEIIIYQQQvRJOq2Grw1N54GrxrP29vOZP3soaQkGKpq9/O+7uzhzwUf86e2dbCltJBRWe7u5HUgPMSGEEEIIIYQQQghxSlITjPzPzCH8+GuFvLm1nKdWlbC3ppWnV5fw9OoS7CYdZw1O4+whaXxtSDq5KZZeba8UxIQQQgghhBBCCCFEtzDptVw9OY+rJuWyck8tiz8tY01xHU5vkKWfV7H08yoABqZaOGtwGtMLU5lWmEq6zXha2ykFMSGEEEIIIYQQQgjRrRRF4dxhGZw7LINgKMz28mZW761j1d5atpQ2cbDezcH6Uv61oRSAoY4EphemMn1QGtMKU0iyGHq0fVIQE0IIIYQQQgghhBA9RqfVMCEvmQl5yfzPzCG0eAOs39/Aun31rN1Xx+6qFvZUt7KnupXn1h1EUeDlG6cxrTC159rUY+8shBBCCCGEEEIIIcSX2Ex6Zo90MHukA4AGl58N++tZu6+edfvrKalzMSrb3qNtkIKYEEIIIYQQQgghhOg1KVYDXx+TxdfHZAHQ6PJjM+l7dJuaHn13IYQQQgghhBBCCCG6INnas+OHgRTEhBBCCCGEEEIIIUSckYKYEEIIIYQQQgghhIgrUhATQgghhBBCCCGEEHFFCmJCCCGEEEIIIYQQIq5IQUwIIYQQQgghhBBCxJWTKogtXLiQ/Px8TCYTU6dOZePGjcd87ZNPPsk555xDcnIyycnJzJo167ivF0L0PMlhIfovyV8h+jfJYSH6L8lfIWJLlwtiixcvZv78+dx9991s3ryZcePGMWfOHGpqajp9/YoVK7jmmmv4+OOPWbduHbm5uVxwwQWUl5efcuOFEF0nOSxE/yX5K0T/JjksRP8l+StE7OlyQeyBBx7gxhtv5Prrr2fkyJE89thjWCwWnnnmmU5f/9JLL/Gzn/2M8ePHM3z4cJ566inC4TDLly8/5cYLIbpOcliI/kvyV4j+TXJYiP5L8leI2NOlgpjf72fTpk3MmjXr8BtoNMyaNYt169ad0Hu43W4CgQApKSlda6kQ4pRJDgvRf0n+CtG/SQ4L0X9J/goRm3RdeXFdXR2hUAiHw9FhucPhYPfu3Sf0HrfddhvZ2dkd/pl8mc/nw+fzRb93Op0ABAIBAoFAp+u0Lz/Wz2NZvMYer3FDx9i7Ev/pyGHJ366R2CX2E41f9sF9k8Qef7HLPjh2SOwSu+yD+zeJPf5iP9l98LF0qSB2qv7617/yyiuvsGLFCkwm0zFft2DBAu65556jln/wwQdYLJbjbmPZsmWn3M7+Kl5jj9e4IRK72+0+bds7kRyW/D05Ent8Op05LPvgniWxxx/ZB8cOiT0+yT44dkjs8ae78rdLBbG0tDS0Wi3V1dUdlldXV5OZmXncdf/2t7/x17/+lQ8//JCxY8ce97V33HEH8+fPj37vdDqjgxDa7fZO1wkEAixbtozZs2ej1+tPMKLYEK+xx2vc0DF2j8dzwuudjhyW/O0aiV1iP9Ecln1w3ySxx1/ssg+OHRK7xC774P5NYo+/2E92H3wsXSqIGQwGJk6cyPLly7niiisAogMDzps375jr3Xffffzv//4v77//PpMmTfrK7RiNRoxG41HL9Xr9V/6xT+Q1sSpeY4/XuCESezAYPOHXn44clvw9ORJ7/MZ+ojks++C+TWKPv9hlHxw7JPb4jV32wbFBYo+/2Lu6Dz6WLt8yOX/+fObOncukSZOYMmUKDz74IC6Xi+uvvx6A6667jpycHBYsWADAvffey1133cW//vUv8vPzqaqqAiAhIYGEhIRTDkAI0TWSw0L0X5K/QvRvksNC9F+Sv0LEni4XxK6++mpqa2u56667qKqqYvz48bz33nvRAQZLS0vRaA5PXvnoo4/i9/v51re+1eF97r77bv7whz+cWuuFEF0mOSxE/yX5K0T/JjksRP8l+StE7DmpQfXnzZt3zK6hK1as6PD9gQMHTmYTQogeJDksRP8l+StE/yY5LET/JfkrRGzRfPVLhBBCCCGEEEIIIYSIHVIQE0IIIYQQQgghhBBxRQpiQgghhBBCCCGEECKuSEFMCCGEEEIIIYQQQsQVKYgJIYQQQgghhBBCiLgiBTEhhBBCCCGEEEIIEVekICaEEEIIIYQQQggh4ooUxIQQQgghhBBCCCFEXJGCmBBCCCGEEEIIIYSIK1IQE0IIIYQQQgghhBBxRQpiQgghhBBCCCGEECKuSEFMCCGEEEIIIYQQQsQVKYgJIYQQQgghhBBCiLgiBTEhhBBCCCGEEEIIEVekICaEEEIIIYQQQggh4ooUxIQQQgghhBBCCCFEXJGCmBBCCCGEEEIIIYSIK1IQE0IIIYQQQgghhBBxRQpiQgghhBBCCCGEECKuSEFMCCGEEEIIIYQQQsQVKYgJIYQQQgghhBBCiLgiBTEhhBBCCCGEEEIIEVekICaEEEIIIYQQQggh4ooUxIQQQgghhBBCCCFEXDmpgtjChQvJz8/HZDIxdepUNm7ceNzXv/baawwfPhyTycSYMWN49913T6qxQojuITksRP8l+StE/yY5LET/JfkrRGzpckFs8eLFzJ8/n7vvvpvNmzczbtw45syZQ01NTaevX7t2Lddccw033HADW7Zs4YorruCKK67g888/P+XGCyG6TnJYiP5L8leI/k1yWIj+S/JXiNjT5YLYAw88wI033sj111/PyJEjeeyxx7BYLDzzzDOdvv6hhx7iwgsv5Ne//jUjRozgT3/6ExMmTOCRRx455cYLIbpOcliI/kvyV4j+TXJYiP5L8leI2KPryov9fj+bNm3ijjvuiC7TaDTMmjWLdevWdbrOunXrmD9/fodlc+bMYcmSJcfcjs/nw+fzRb9vbm4GoKGhgUAg0Ok6gUAAt9tNfX09er3+REOKCfEae7zGDR1j93q9AKiq+pXrnY4clvztGoldYj/RHJZ9cN8kscdf7LIPjh0Su8Qu++D+TWKPv9hPdh98LF0qiNXV1REKhXA4HB2WOxwOdu/e3ek6VVVVnb6+qqrqmNtZsGAB99xzz1HLCwoKutJcIeJKS0sLiYmJx33N6chhyV8hTs5X5bDsg4Xou2QfLET/JvtgIfqvE9kHH0uXCmKnyx133NGhmh4Oh2loaCA1NRVFUTpdx+l0kpubS1lZGXa7/XQ1tU+I19jjNW7oGLvNZqOlpYXs7OzebhYg+dtVErvELjncv0ns8Re75G/skNgldsnh/k1ij7/Yuzt/u1QQS0tLQ6vVUl1d3WF5dXU1mZmZna6TmZnZpdcDGI1GjEZjh2VJSUkn1Ea73R5XH4gjxWvs8Ro3HI79RCvipyOHJX9PjsQe37GfSA7LPrhvk9jjL3bZB8cOiT2+Y5d9cP8nscdf7F3dBx9LlwbVNxgMTJw4keXLl0eXhcNhli9fzvTp0ztdZ/r06R1eD7Bs2bJjvl4I0XMkh4XovyR/hejfJIeF6L8kf4WITV2+ZXL+/PnMnTuXSZMmMWXKFB588EFcLhfXX389ANdddx05OTksWLAAgFtvvZUZM2bw97//nYsvvphXXnmFzz77jCeeeKJ7IxFCnBDJYSH6L8lfIfo3yWEh+i/JXyFikHoSHn74YTUvL081GAzqlClT1PXr10d/NmPGDHXu3LkdXv/qq6+qQ4cOVQ0Ggzpq1Cj1nXfeOZnNHpfX61Xvvvtu1ev1dvt793XxGnu8xq2qpx57X8th+VtK7PHmVGLva/mrqvK3lNjjK3bZB8cOiV1i76q+lr+qKn9LiT2+Yu/uuBVVPYU5KoUQQgghhBBCCCGE6Ge6NIaYEEIIIYQQQgghhBD9nRTEhBBCCCGEEEIIIURckYKYEEIIIYQQQgghhIgrUhATQgghhBBCCCGEEHElJgpiCxcuJD8/H5PJxNSpU9m4cWNvN6nbffLJJ1x66aVkZ2ejKApLlizp8HNVVbnrrrvIysrCbDYza9Ys9u7d2zuN7WYLFixg8uTJ2Gw2MjIyuOKKKygqKurwGq/Xy80330xqaioJCQl885vfpLq6upda3H0effRRxo4di91ux263M336dJYuXRr9eazELTkcuzks+Sv5GwviNX9BclhyODbEaw5L/kr+xoJ4zV+QHD4dOdzvC2KLFy9m/vz53H333WzevJlx48YxZ84campqertp3crlcjFu3DgWLlzY6c/vu+8+/vGPf/DYY4+xYcMGrFYrc+bMwev1nuaWdr+VK1dy8803s379epYtW0YgEOCCCy7A5XJFX/OLX/yCt956i9dee42VK1dSUVHBlVde2Yut7h4DBgzgr3/9K5s2beKzzz7j/PPP5/LLL+eLL74AYiNuyeGIWM1hyV/J31gQr/kLksOSw7EhXnNY8lfyNxbEa/6C5PBpyWG1n5syZYp68803R78PhUJqdna2umDBgl5sVc8C1DfeeCP6fTgcVjMzM9X7778/uqypqUk1Go3qyy+/3Ast7Fk1NTUqoK5cuVJV1Uiser1efe2116Kv2bVrlwqo69at661m9pjk5GT1qaeeipm4JYfjK4clfyV/+7t4zl9VlRyWHO7/4jmHJX8lf/u7eM5fVZUc7okc7tc9xPx+P5s2bWLWrFnRZRqNhlmzZrFu3bpebNnpVVJSQlVVVYffQ2JiIlOnTo3J30NzczMAKSkpAGzatIlAINAh/uHDh5OXlxdT8YdCIV555RVcLhfTp0+PibglhyPiKYclfyV/Y0085S9IDksOx554ymHJX8nfWBNP+QuSwz2Rw7rubuzpVFdXRygUwuFwdFjucDjYvXt3L7Xq9KuqqgLo9PfQ/rNYEQ6H+fnPf85ZZ53F6NGjgUj8BoOBpKSkDq+Nlfh37NjB9OnT8Xq9JCQk8MYbbzBy5Ei2bt3a7+OWHI6IlxyW/JX8jUXxkr8gOSw5HJviJYclfyV/Y1G85C9IDvdUDvfrgpiIPzfffDOff/45q1ev7u2mnDbDhg1j69atNDc38+9//5u5c+eycuXK3m6WEF0m+Sv5K/o3yWHJYdF/Sf5K/or+TXK4Z3K4X98ymZaWhlarPWo2gerqajIzM3upVadfe6yx/nuYN28eb7/9Nh9//DEDBgyILs/MzMTv99PU1NTh9bESv8FgYPDgwUycOJEFCxYwbtw4HnrooZiIW3I4Ih5yWPJX8jdWxUP+guSw5HDsiocclvyV/I1V8ZC/IDnckzncrwtiBoOBiRMnsnz58uiycDjM8uXLmT59ei+27PQqKCggMzOzw+/B6XSyYcOGmPg9qKrKvHnzeOONN/joo48oKCjo8POJEyei1+s7xF9UVERpaWlMxP9l4XAYn88XE3FLDkfEcg5L/nYk+Rt7Yjl/QXL4yySHY08s57Dkb0eSv7EnlvMXJIe/rEdyuBsH/e8Vr7zyimo0GtVFixapO3fuVH/84x+rSUlJalVVVW83rVu1tLSoW7ZsUbds2aIC6gMPPKBu2bJFPXjwoKqqqvrXv/5VTUpKUt988011+/bt6uWXX64WFBSoHo+nl1t+6m666SY1MTFRXbFihVpZWRl9uN3u6Gt++tOfqnl5eepHH32kfvbZZ+r06dPV6dOn92Kru8ftt9+urly5Ui0pKVG3b9+u3n777aqiKOoHH3ygqmpsxC05HNs5LPkr+RsL4jV/VVVyWHI4NsRrDkv+Sv7GgnjNX1WVHD4dOdzvC2KqqqoPP/ywmpeXpxoMBnXKlCnq+vXre7tJ3e7jjz9WgaMec+fOVVU1MuXsnXfeqTocDtVoNKozZ85Ui4qKerfR3aSzuAH12Wefjb7G4/GoP/vZz9Tk5GTVYrGo3/jGN9TKysrea3Q3+eEPf6gOHDhQNRgManp6ujpz5szoPwFVjZ24JYdjN4clfyV/Y0G85q+qSg5LDseGeM1hyV/J31gQr/mrqpLDpyOHFVVV1a71KRNCCCGEEEIIIYQQov/q12OICSGEEEIIIYQQQgjRVVIQE0IIIYQQQgghhBBxRQpiQgghhBBCCCGEECKuSEFMCCGEEEIIIYQQQsQVKYgJIYQQQgghhBBCiLgiBTEhhBBCCCGEEEIIEVekICaEEEIIIYQQQggh4ooUxIQQQgghhBBCCCFEXJGCmBBCCCGEEEIIIYSIK1IQE0IIIYQQQgghhBBxRQpiQgghhBBCCCGEECKuSEFMCCGEEEIIIYQQQsSV/wfIa+72H5P58wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1500x900 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the history of the models\n",
    "histories = [history1, history2, history3, history4, history5, history6, history7, history8, history9, history10,\n",
    "            history11, history12, history13, history14, history15]\n",
    "\n",
    "n_rows = 3\n",
    "n_cols = 5\n",
    "plt.figure(figsize=(n_cols * 3, n_rows * 3))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index+1)\n",
    "        plt.plot(pd.DataFrame(histories[index].history))\n",
    "        plt.grid(True)\n",
    "        plt.title(f\"model{index+1}\", fontsize=12)\n",
    "        plt.gca().set_ylim(0, 1)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment with epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "457/457 [==============================] - 9s 19ms/step - loss: 0.6879 - accuracy: 0.5550 - val_loss: 0.6859 - val_accuracy: 0.5575\n",
      "Epoch 2/50\n",
      "457/457 [==============================] - 9s 19ms/step - loss: 0.6836 - accuracy: 0.5550 - val_loss: 0.6814 - val_accuracy: 0.5575\n",
      "Epoch 3/50\n",
      "457/457 [==============================] - 9s 19ms/step - loss: 0.6801 - accuracy: 0.5555 - val_loss: 0.6778 - val_accuracy: 0.5575\n",
      "Epoch 4/50\n",
      "457/457 [==============================] - 9s 19ms/step - loss: 0.6759 - accuracy: 0.5551 - val_loss: 0.6730 - val_accuracy: 0.5575\n",
      "Epoch 5/50\n",
      "457/457 [==============================] - 9s 21ms/step - loss: 0.6693 - accuracy: 0.5664 - val_loss: 0.6652 - val_accuracy: 0.5575\n",
      "Epoch 6/50\n",
      "457/457 [==============================] - 9s 20ms/step - loss: 0.6590 - accuracy: 0.6140 - val_loss: 0.6537 - val_accuracy: 0.6603\n",
      "Epoch 7/50\n",
      "457/457 [==============================] - 9s 20ms/step - loss: 0.6442 - accuracy: 0.6670 - val_loss: 0.6369 - val_accuracy: 0.6695\n",
      "Epoch 8/50\n",
      "457/457 [==============================] - 10s 22ms/step - loss: 0.6242 - accuracy: 0.6787 - val_loss: 0.6177 - val_accuracy: 0.6757\n",
      "Epoch 9/50\n",
      "457/457 [==============================] - 10s 22ms/step - loss: 0.6038 - accuracy: 0.6863 - val_loss: 0.5991 - val_accuracy: 0.6825\n",
      "Epoch 10/50\n",
      "457/457 [==============================] - 10s 22ms/step - loss: 0.5840 - accuracy: 0.6943 - val_loss: 0.5796 - val_accuracy: 0.6997\n",
      "Epoch 11/50\n",
      "457/457 [==============================] - 11s 23ms/step - loss: 0.5611 - accuracy: 0.7133 - val_loss: 0.5547 - val_accuracy: 0.7182\n",
      "Epoch 12/50\n",
      "457/457 [==============================] - 10s 21ms/step - loss: 0.5339 - accuracy: 0.7350 - val_loss: 0.5251 - val_accuracy: 0.7415\n",
      "Epoch 13/50\n",
      "457/457 [==============================] - 9s 19ms/step - loss: 0.5062 - accuracy: 0.7559 - val_loss: 0.4990 - val_accuracy: 0.7588\n",
      "Epoch 14/50\n",
      "457/457 [==============================] - 9s 19ms/step - loss: 0.4840 - accuracy: 0.7723 - val_loss: 0.4799 - val_accuracy: 0.7711\n",
      "Epoch 15/50\n",
      "457/457 [==============================] - 8s 19ms/step - loss: 0.4687 - accuracy: 0.7835 - val_loss: 0.4656 - val_accuracy: 0.7748\n",
      "Epoch 16/50\n",
      "457/457 [==============================] - 9s 20ms/step - loss: 0.4583 - accuracy: 0.7913 - val_loss: 0.4571 - val_accuracy: 0.7809\n",
      "Epoch 17/50\n",
      "457/457 [==============================] - 9s 19ms/step - loss: 0.4505 - accuracy: 0.7956 - val_loss: 0.4504 - val_accuracy: 0.7883\n",
      "Epoch 18/50\n",
      "457/457 [==============================] - 9s 20ms/step - loss: 0.4444 - accuracy: 0.8018 - val_loss: 0.4449 - val_accuracy: 0.7963\n",
      "Epoch 19/50\n",
      "457/457 [==============================] - 9s 20ms/step - loss: 0.4392 - accuracy: 0.8038 - val_loss: 0.4405 - val_accuracy: 0.8031\n",
      "Epoch 20/50\n",
      "457/457 [==============================] - 9s 20ms/step - loss: 0.4348 - accuracy: 0.8083 - val_loss: 0.4384 - val_accuracy: 0.8037\n",
      "Epoch 21/50\n",
      "457/457 [==============================] - 9s 19ms/step - loss: 0.4309 - accuracy: 0.8113 - val_loss: 0.4398 - val_accuracy: 0.7957\n",
      "Epoch 22/50\n",
      "457/457 [==============================] - 9s 20ms/step - loss: 0.4268 - accuracy: 0.8116 - val_loss: 0.4342 - val_accuracy: 0.8025\n",
      "Epoch 23/50\n",
      "457/457 [==============================] - 9s 21ms/step - loss: 0.4233 - accuracy: 0.8148 - val_loss: 0.4316 - val_accuracy: 0.8105\n",
      "Epoch 24/50\n",
      "457/457 [==============================] - 10s 22ms/step - loss: 0.4201 - accuracy: 0.8178 - val_loss: 0.4323 - val_accuracy: 0.8074\n",
      "Epoch 25/50\n",
      "457/457 [==============================] - 11s 24ms/step - loss: 0.4177 - accuracy: 0.8185 - val_loss: 0.4294 - val_accuracy: 0.8055\n",
      "Epoch 26/50\n",
      "457/457 [==============================] - 11s 24ms/step - loss: 0.4147 - accuracy: 0.8198 - val_loss: 0.4289 - val_accuracy: 0.8062\n",
      "Epoch 27/50\n",
      "457/457 [==============================] - 10s 21ms/step - loss: 0.4114 - accuracy: 0.8226 - val_loss: 0.4303 - val_accuracy: 0.8068\n",
      "Epoch 28/50\n",
      "457/457 [==============================] - 9s 20ms/step - loss: 0.4089 - accuracy: 0.8259 - val_loss: 0.4253 - val_accuracy: 0.8092\n",
      "Epoch 29/50\n",
      "457/457 [==============================] - 9s 19ms/step - loss: 0.4061 - accuracy: 0.8288 - val_loss: 0.4253 - val_accuracy: 0.8086\n",
      "Epoch 30/50\n",
      "457/457 [==============================] - 9s 19ms/step - loss: 0.4032 - accuracy: 0.8292 - val_loss: 0.4242 - val_accuracy: 0.8086\n",
      "Epoch 31/50\n",
      "457/457 [==============================] - 10s 22ms/step - loss: 0.4003 - accuracy: 0.8324 - val_loss: 0.4224 - val_accuracy: 0.8080\n",
      "Epoch 32/50\n",
      "457/457 [==============================] - 10s 21ms/step - loss: 0.3967 - accuracy: 0.8339 - val_loss: 0.4246 - val_accuracy: 0.8080\n",
      "Epoch 33/50\n",
      "457/457 [==============================] - 10s 21ms/step - loss: 0.3932 - accuracy: 0.8361 - val_loss: 0.4248 - val_accuracy: 0.8098\n",
      "Epoch 34/50\n",
      "457/457 [==============================] - 9s 20ms/step - loss: 0.3896 - accuracy: 0.8355 - val_loss: 0.4243 - val_accuracy: 0.8129\n",
      "Epoch 35/50\n",
      "457/457 [==============================] - 9s 19ms/step - loss: 0.3864 - accuracy: 0.8364 - val_loss: 0.4218 - val_accuracy: 0.8086\n",
      "Epoch 36/50\n",
      "457/457 [==============================] - 9s 19ms/step - loss: 0.3811 - accuracy: 0.8421 - val_loss: 0.4217 - val_accuracy: 0.8111\n",
      "Epoch 37/50\n",
      "457/457 [==============================] - 9s 21ms/step - loss: 0.3769 - accuracy: 0.8447 - val_loss: 0.4240 - val_accuracy: 0.8074\n",
      "Epoch 38/50\n",
      "457/457 [==============================] - 10s 21ms/step - loss: 0.3714 - accuracy: 0.8474 - val_loss: 0.4265 - val_accuracy: 0.8086\n",
      "Epoch 39/50\n",
      "457/457 [==============================] - 11s 23ms/step - loss: 0.3657 - accuracy: 0.8501 - val_loss: 0.4245 - val_accuracy: 0.8086\n",
      "Epoch 40/50\n",
      "457/457 [==============================] - 11s 24ms/step - loss: 0.3595 - accuracy: 0.8542 - val_loss: 0.4222 - val_accuracy: 0.8111\n",
      "Epoch 41/50\n",
      "457/457 [==============================] - 9s 21ms/step - loss: 0.3536 - accuracy: 0.8557 - val_loss: 0.4279 - val_accuracy: 0.8049\n",
      "Epoch 42/50\n",
      "457/457 [==============================] - 9s 19ms/step - loss: 0.3448 - accuracy: 0.8620 - val_loss: 0.4254 - val_accuracy: 0.8117\n",
      "Epoch 43/50\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.3379 - accuracy: 0.8638 - val_loss: 0.4322 - val_accuracy: 0.8117\n",
      "Epoch 44/50\n",
      "457/457 [==============================] - 8s 18ms/step - loss: 0.3285 - accuracy: 0.8712 - val_loss: 0.4265 - val_accuracy: 0.8098\n",
      "Epoch 45/50\n",
      "457/457 [==============================] - 10s 22ms/step - loss: 0.3192 - accuracy: 0.8751 - val_loss: 0.4299 - val_accuracy: 0.8080\n",
      "Epoch 46/50\n",
      "457/457 [==============================] - 10s 21ms/step - loss: 0.3090 - accuracy: 0.8816 - val_loss: 0.4326 - val_accuracy: 0.8123\n",
      "Epoch 47/50\n",
      "457/457 [==============================] - 9s 19ms/step - loss: 0.2984 - accuracy: 0.8855 - val_loss: 0.4607 - val_accuracy: 0.7932\n",
      "Epoch 48/50\n",
      "457/457 [==============================] - 9s 20ms/step - loss: 0.2868 - accuracy: 0.8930 - val_loss: 0.4393 - val_accuracy: 0.8049\n",
      "Epoch 49/50\n",
      "457/457 [==============================] - 9s 20ms/step - loss: 0.2747 - accuracy: 0.8986 - val_loss: 0.4480 - val_accuracy: 0.8062\n",
      "Epoch 50/50\n",
      "457/457 [==============================] - 9s 20ms/step - loss: 0.2615 - accuracy: 0.9029 - val_loss: 0.4556 - val_accuracy: 0.8037\n",
      "57/57 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Area Under RoC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Layer1 100, Layer2 10, Layer3 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>578.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.888105</td>\n",
       "      <td>0.838897</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.813808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 200, Layer2 20, Layer3 1</th>\n",
       "      <td>0.807309</td>\n",
       "      <td>631.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.833669</td>\n",
       "      <td>0.792714</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.805763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 300, Layer2 30, Layer3 1</th>\n",
       "      <td>0.800664</td>\n",
       "      <td>640.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.774818</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>0.798634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>635.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.819556</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>0.799827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 500, Layer2 50, Layer3 1</th>\n",
       "      <td>0.801772</td>\n",
       "      <td>587.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.867944</td>\n",
       "      <td>0.817549</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.804455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 50, Layer2 5, Layer3 1</th>\n",
       "      <td>0.806202</td>\n",
       "      <td>617.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.845766</td>\n",
       "      <td>0.801299</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.805572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 40, Layer3 4, Layer4 1</th>\n",
       "      <td>0.810078</td>\n",
       "      <td>617.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.852823</td>\n",
       "      <td>0.808650</td>\n",
       "      <td>0.757985</td>\n",
       "      <td>0.809886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 879, Layer2 586, Layer3 390, Layer4 260, Layer5 30, Layer6 1</th>\n",
       "      <td>0.808970</td>\n",
       "      <td>633.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.777641</td>\n",
       "      <td>0.834677</td>\n",
       "      <td>0.794228</td>\n",
       "      <td>0.777641</td>\n",
       "      <td>0.807421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 1000, Layer2 700, Layer3 400, Layer4 260, Layer5 30, Layer6 1</th>\n",
       "      <td>0.808970</td>\n",
       "      <td>627.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.840726</td>\n",
       "      <td>0.798726</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.807786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 500, Layer2 180, Layer3 60, Layer4 20, Layer5 1</th>\n",
       "      <td>0.808416</td>\n",
       "      <td>638.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.828629</td>\n",
       "      <td>0.789604</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.806626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 400, Layer2 100, Layer3 25, Layer4 6, Layer5 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>602.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.739558</td>\n",
       "      <td>0.863911</td>\n",
       "      <td>0.816825</td>\n",
       "      <td>0.739558</td>\n",
       "      <td>0.809254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 300, Layer2 60, Layer3 12, Layer4 3, Layer5 1</th>\n",
       "      <td>0.807863</td>\n",
       "      <td>630.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>829.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.773956</td>\n",
       "      <td>0.835685</td>\n",
       "      <td>0.794451</td>\n",
       "      <td>0.773956</td>\n",
       "      <td>0.806406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 250, Layer2 40, Layer3 7, Layer4 1</th>\n",
       "      <td>0.803987</td>\n",
       "      <td>612.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>0.846774</td>\n",
       "      <td>0.801047</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>0.803595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 200, Layer2 30, Layer3 4, Layer4 1</th>\n",
       "      <td>0.804540</td>\n",
       "      <td>608.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0.746929</td>\n",
       "      <td>0.851815</td>\n",
       "      <td>0.805298</td>\n",
       "      <td>0.746929</td>\n",
       "      <td>0.804647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 879, Layer2 586, Layer3 390, Layer4 260, Layer5 30, Layer6 1, learning_rate=0.02</th>\n",
       "      <td>0.803433</td>\n",
       "      <td>626.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>825.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.769042</td>\n",
       "      <td>0.831653</td>\n",
       "      <td>0.789407</td>\n",
       "      <td>0.769042</td>\n",
       "      <td>0.801910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer1 1000, Layer2 700, Layer3 400, Layer4 260, Layer5 30, Layer6 1, epochs=50</th>\n",
       "      <td>0.805648</td>\n",
       "      <td>607.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>848.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0.745700</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.808256</td>\n",
       "      <td>0.745700</td>\n",
       "      <td>0.806024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy     TP     FP  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     0.807863  578.0  111.0   \n",
       "Layer1 200, Layer2 20, Layer3 1                     0.807309  631.0  165.0   \n",
       "Layer1 300, Layer2 30, Layer3 1                     0.800664  640.0  186.0   \n",
       "Layer1 400, Layer2 40, Layer3 1                     0.801772  635.0  179.0   \n",
       "Layer1 500, Layer2 50, Layer3 1                     0.801772  587.0  131.0   \n",
       "Layer1 50, Layer2 5, Layer3 1                       0.806202  617.0  153.0   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           0.810078  617.0  146.0   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.808970  633.0  164.0   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  0.808970  627.0  158.0   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  0.808416  638.0  170.0   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...  0.807863  602.0  135.0   \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...  0.807863  630.0  163.0   \n",
       "Layer1 250, Layer2 40, Layer3 7, Layer4 1           0.803987  612.0  152.0   \n",
       "Layer1 200, Layer2 30, Layer3 4, Layer4 1           0.804540  608.0  147.0   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.803433  626.0  167.0   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  0.805648  607.0  144.0   \n",
       "\n",
       "                                                       TN     FN  Sensitivity  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     881.0  236.0     0.710074   \n",
       "Layer1 200, Layer2 20, Layer3 1                     827.0  183.0     0.775184   \n",
       "Layer1 300, Layer2 30, Layer3 1                     806.0  174.0     0.786241   \n",
       "Layer1 400, Layer2 40, Layer3 1                     813.0  179.0     0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                     861.0  227.0     0.721130   \n",
       "Layer1 50, Layer2 5, Layer3 1                       839.0  197.0     0.757985   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           846.0  197.0     0.757985   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  828.0  181.0     0.777641   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  834.0  187.0     0.770270   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  822.0  176.0     0.783784   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...  857.0  212.0     0.739558   \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...  829.0  184.0     0.773956   \n",
       "Layer1 250, Layer2 40, Layer3 7, Layer4 1           840.0  202.0     0.751843   \n",
       "Layer1 200, Layer2 30, Layer3 4, Layer4 1           845.0  206.0     0.746929   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  825.0  188.0     0.769042   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  848.0  207.0     0.745700   \n",
       "\n",
       "                                                    Specificity  Precision  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                        0.888105   0.838897   \n",
       "Layer1 200, Layer2 20, Layer3 1                        0.833669   0.792714   \n",
       "Layer1 300, Layer2 30, Layer3 1                        0.812500   0.774818   \n",
       "Layer1 400, Layer2 40, Layer3 1                        0.819556   0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                        0.867944   0.817549   \n",
       "Layer1 50, Layer2 5, Layer3 1                          0.845766   0.801299   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1              0.852823   0.808650   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...     0.834677   0.794228   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...     0.840726   0.798726   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...     0.828629   0.789604   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...     0.863911   0.816825   \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...     0.835685   0.794451   \n",
       "Layer1 250, Layer2 40, Layer3 7, Layer4 1              0.846774   0.801047   \n",
       "Layer1 200, Layer2 30, Layer3 4, Layer4 1              0.851815   0.805298   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...     0.831653   0.789407   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...     0.854839   0.808256   \n",
       "\n",
       "                                                      Recall  \\\n",
       "Layer1 100, Layer2 10, Layer3 1                     0.710074   \n",
       "Layer1 200, Layer2 20, Layer3 1                     0.775184   \n",
       "Layer1 300, Layer2 30, Layer3 1                     0.786241   \n",
       "Layer1 400, Layer2 40, Layer3 1                     0.780098   \n",
       "Layer1 500, Layer2 50, Layer3 1                     0.721130   \n",
       "Layer1 50, Layer2 5, Layer3 1                       0.757985   \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1           0.757985   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.777641   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  0.770270   \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...  0.783784   \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...  0.739558   \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...  0.773956   \n",
       "Layer1 250, Layer2 40, Layer3 7, Layer4 1           0.751843   \n",
       "Layer1 200, Layer2 30, Layer3 4, Layer4 1           0.746929   \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...  0.769042   \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...  0.745700   \n",
       "\n",
       "                                                    Area Under RoC Curve  \n",
       "Layer1 100, Layer2 10, Layer3 1                                 0.813808  \n",
       "Layer1 200, Layer2 20, Layer3 1                                 0.805763  \n",
       "Layer1 300, Layer2 30, Layer3 1                                 0.798634  \n",
       "Layer1 400, Layer2 40, Layer3 1                                 0.799827  \n",
       "Layer1 500, Layer2 50, Layer3 1                                 0.804455  \n",
       "Layer1 50, Layer2 5, Layer3 1                                   0.805572  \n",
       "Layer1 400, Layer2 40, Layer3 4, Layer4 1                       0.809886  \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...              0.807421  \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...              0.807786  \n",
       "Layer1 500, Layer2 180, Layer3 60, Layer4 20, L...              0.806626  \n",
       "Layer1 400, Layer2 100, Layer3 25, Layer4 6, La...              0.809254  \n",
       "Layer1 300, Layer2 60, Layer3 12, Layer4 3, Lay...              0.806406  \n",
       "Layer1 250, Layer2 40, Layer3 7, Layer4 1                       0.803595  \n",
       "Layer1 200, Layer2 30, Layer3 4, Layer4 1                       0.804647  \n",
       "Layer1 879, Layer2 586, Layer3 390, Layer4 260,...              0.801910  \n",
       "Layer1 1000, Layer2 700, Layer3 400, Layer4 260...              0.806024  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try longer epochs (with model9)\n",
    "model16 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "    keras.layers.Dense(1000, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(700, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(400, name=\"layer3\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(260, name=\"layer4\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(30, name=\"layer5\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer6\", activation=\"sigmoid\") \n",
    "])\n",
    "# complie\n",
    "model16.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "# fit\n",
    "history16 = model16.fit(X_train_temp, y_train_temp, epochs=50, validation_split=0.1)\n",
    "\n",
    "# evaluate\n",
    "description = \"Layer1 1000, Layer2 700, Layer3 400, Layer4 260, Layer5 30, Layer6 1, epochs=50\"\n",
    "evaluate_model(model16, description)\n",
    "architecture_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the history\n",
    "pd.DataFrame(history16.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of epochs with highest accuracy on validation set\n",
    "best = np.argmax(history16.history['val_accuracy']) + 1\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Experiement with three different train-test set split\n",
    "\n",
    "1. number of train set - 18051, number of test set -  4513\n",
    "2. number of train set - 12651, number of test set -  9913\n",
    "3. number of train set -  7200, number of test set - 15364"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/34\n",
      "565/565 [==============================] - 9s 15ms/step - loss: 0.6863 - accuracy: 0.5547\n",
      "Epoch 2/34\n",
      "565/565 [==============================] - 9s 16ms/step - loss: 0.6821 - accuracy: 0.5547\n",
      "Epoch 3/34\n",
      "565/565 [==============================] - 11s 19ms/step - loss: 0.6769 - accuracy: 0.5558\n",
      "Epoch 4/34\n",
      "565/565 [==============================] - 10s 17ms/step - loss: 0.6683 - accuracy: 0.5740\n",
      "Epoch 5/34\n",
      "565/565 [==============================] - 10s 17ms/step - loss: 0.6539 - accuracy: 0.6400\n",
      "Epoch 6/34\n",
      "565/565 [==============================] - 10s 17ms/step - loss: 0.6319 - accuracy: 0.6773\n",
      "Epoch 7/34\n",
      "565/565 [==============================] - 10s 18ms/step - loss: 0.6056 - accuracy: 0.6867\n",
      "Epoch 8/34\n",
      "565/565 [==============================] - 10s 17ms/step - loss: 0.5795 - accuracy: 0.7014\n",
      "Epoch 9/34\n",
      "565/565 [==============================] - 10s 18ms/step - loss: 0.5478 - accuracy: 0.7248\n",
      "Epoch 10/34\n",
      "565/565 [==============================] - 11s 19ms/step - loss: 0.5121 - accuracy: 0.7526\n",
      "Epoch 11/34\n",
      "565/565 [==============================] - 12s 20ms/step - loss: 0.4843 - accuracy: 0.7717\n",
      "Epoch 12/34\n",
      "565/565 [==============================] - 10s 19ms/step - loss: 0.4665 - accuracy: 0.7874\n",
      "Epoch 13/34\n",
      "565/565 [==============================] - 10s 17ms/step - loss: 0.4554 - accuracy: 0.7935\n",
      "Epoch 14/34\n",
      "565/565 [==============================] - 9s 17ms/step - loss: 0.4477 - accuracy: 0.7981\n",
      "Epoch 15/34\n",
      "565/565 [==============================] - 10s 17ms/step - loss: 0.4416 - accuracy: 0.8031\n",
      "Epoch 16/34\n",
      "565/565 [==============================] - 9s 17ms/step - loss: 0.4363 - accuracy: 0.8065\n",
      "Epoch 17/34\n",
      "565/565 [==============================] - 10s 18ms/step - loss: 0.4322 - accuracy: 0.8095\n",
      "Epoch 18/34\n",
      "565/565 [==============================] - 11s 19ms/step - loss: 0.4283 - accuracy: 0.8130\n",
      "Epoch 19/34\n",
      "565/565 [==============================] - 10s 18ms/step - loss: 0.4248 - accuracy: 0.8161\n",
      "Epoch 20/34\n",
      "565/565 [==============================] - 10s 18ms/step - loss: 0.4214 - accuracy: 0.8168\n",
      "Epoch 21/34\n",
      "565/565 [==============================] - 11s 19ms/step - loss: 0.4181 - accuracy: 0.8194\n",
      "Epoch 22/34\n",
      "565/565 [==============================] - 12s 22ms/step - loss: 0.4153 - accuracy: 0.8206\n",
      "Epoch 23/34\n",
      "565/565 [==============================] - 11s 20ms/step - loss: 0.4125 - accuracy: 0.8228\n",
      "Epoch 24/34\n",
      "565/565 [==============================] - 13s 22ms/step - loss: 0.4094 - accuracy: 0.8243\n",
      "Epoch 25/34\n",
      "565/565 [==============================] - 9s 17ms/step - loss: 0.4067 - accuracy: 0.8246\n",
      "Epoch 26/34\n",
      "565/565 [==============================] - 9s 16ms/step - loss: 0.4033 - accuracy: 0.8289\n",
      "Epoch 27/34\n",
      "565/565 [==============================] - 9s 15ms/step - loss: 0.3999 - accuracy: 0.8298\n",
      "Epoch 28/34\n",
      "565/565 [==============================] - 9s 16ms/step - loss: 0.3964 - accuracy: 0.8318\n",
      "Epoch 29/34\n",
      "565/565 [==============================] - 9s 16ms/step - loss: 0.3926 - accuracy: 0.8362\n",
      "Epoch 30/34\n",
      "565/565 [==============================] - 9s 16ms/step - loss: 0.3888 - accuracy: 0.8374\n",
      "Epoch 31/34\n",
      "565/565 [==============================] - 11s 19ms/step - loss: 0.3845 - accuracy: 0.8403\n",
      "Epoch 32/34\n",
      "565/565 [==============================] - 10s 18ms/step - loss: 0.3802 - accuracy: 0.8418\n",
      "Epoch 33/34\n",
      "565/565 [==============================] - 10s 18ms/step - loss: 0.3744 - accuracy: 0.8443\n",
      "Epoch 34/34\n",
      "565/565 [==============================] - 10s 18ms/step - loss: 0.3691 - accuracy: 0.8489\n"
     ]
    }
   ],
   "source": [
    "# build final_model\n",
    "model_f1 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "    keras.layers.Dense(1000, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(700, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(400, name=\"layer3\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(260, name=\"layer4\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(30, name=\"layer5\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer6\", activation=\"sigmoid\") \n",
    "])\n",
    "# complie\n",
    "model_f1.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# fit (with the epochs=41)\n",
    "history_f1 = model_f1.fit(X_train_pca, y_train, epochs=best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12651, 1317)\n",
      "(9913, 1317)\n"
     ]
    }
   ],
   "source": [
    "# merge into the whole dataset\n",
    "X_whole = np.concatenate((X_train_pca, X_cv_pca))\n",
    "y_whole = np.concatenate((y_train, y_cv))\n",
    "\n",
    "# split for the second spolit\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_whole, y_whole, test_size=9913, random_state=42)\n",
    "print(X_train_2.shape)\n",
    "print(X_test_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/34\n",
      "396/396 [==============================] - 8s 20ms/step - loss: 0.6861 - accuracy: 0.5567\n",
      "Epoch 2/34\n",
      "396/396 [==============================] - 8s 19ms/step - loss: 0.6840 - accuracy: 0.5567\n",
      "Epoch 3/34\n",
      "396/396 [==============================] - 10s 25ms/step - loss: 0.6818 - accuracy: 0.5567\n",
      "Epoch 4/34\n",
      "396/396 [==============================] - 10s 25ms/step - loss: 0.6793 - accuracy: 0.5567\n",
      "Epoch 5/34\n",
      "396/396 [==============================] - 8s 21ms/step - loss: 0.6758 - accuracy: 0.5567\n",
      "Epoch 6/34\n",
      "396/396 [==============================] - 8s 20ms/step - loss: 0.6711 - accuracy: 0.5581\n",
      "Epoch 7/34\n",
      "396/396 [==============================] - 8s 20ms/step - loss: 0.6640 - accuracy: 0.5789\n",
      "Epoch 8/34\n",
      "396/396 [==============================] - 8s 19ms/step - loss: 0.6540 - accuracy: 0.6386\n",
      "Epoch 9/34\n",
      "396/396 [==============================] - 7s 18ms/step - loss: 0.6406 - accuracy: 0.6758\n",
      "Epoch 10/34\n",
      "396/396 [==============================] - 7s 18ms/step - loss: 0.6241 - accuracy: 0.6788\n",
      "Epoch 11/34\n",
      "396/396 [==============================] - 7s 18ms/step - loss: 0.6070 - accuracy: 0.6842\n",
      "Epoch 12/34\n",
      "396/396 [==============================] - 7s 18ms/step - loss: 0.5908 - accuracy: 0.6912\n",
      "Epoch 13/34\n",
      "396/396 [==============================] - 7s 18ms/step - loss: 0.5732 - accuracy: 0.7045\n",
      "Epoch 14/34\n",
      "396/396 [==============================] - 7s 18ms/step - loss: 0.5517 - accuracy: 0.7223\n",
      "Epoch 15/34\n",
      "396/396 [==============================] - 7s 18ms/step - loss: 0.5274 - accuracy: 0.7404\n",
      "Epoch 16/34\n",
      "396/396 [==============================] - 7s 18ms/step - loss: 0.5041 - accuracy: 0.7588\n",
      "Epoch 17/34\n",
      "396/396 [==============================] - 8s 20ms/step - loss: 0.4857 - accuracy: 0.7716\n",
      "Epoch 18/34\n",
      "396/396 [==============================] - 8s 21ms/step - loss: 0.4721 - accuracy: 0.7794\n",
      "Epoch 19/34\n",
      "396/396 [==============================] - 9s 23ms/step - loss: 0.4623 - accuracy: 0.7848\n",
      "Epoch 20/34\n",
      "396/396 [==============================] - 10s 24ms/step - loss: 0.4552 - accuracy: 0.7927\n",
      "Epoch 21/34\n",
      "396/396 [==============================] - 8s 21ms/step - loss: 0.4491 - accuracy: 0.7971\n",
      "Epoch 22/34\n",
      "396/396 [==============================] - 7s 19ms/step - loss: 0.4442 - accuracy: 0.8001\n",
      "Epoch 23/34\n",
      "396/396 [==============================] - 7s 18ms/step - loss: 0.4391 - accuracy: 0.8036\n",
      "Epoch 24/34\n",
      "396/396 [==============================] - 7s 18ms/step - loss: 0.4355 - accuracy: 0.8067\n",
      "Epoch 25/34\n",
      "396/396 [==============================] - 7s 18ms/step - loss: 0.4316 - accuracy: 0.8095\n",
      "Epoch 26/34\n",
      "396/396 [==============================] - 8s 19ms/step - loss: 0.4279 - accuracy: 0.8111\n",
      "Epoch 27/34\n",
      "396/396 [==============================] - 8s 19ms/step - loss: 0.4251 - accuracy: 0.8154\n",
      "Epoch 28/34\n",
      "396/396 [==============================] - 7s 18ms/step - loss: 0.4218 - accuracy: 0.8149\n",
      "Epoch 29/34\n",
      "396/396 [==============================] - 8s 21ms/step - loss: 0.4189 - accuracy: 0.8170\n",
      "Epoch 30/34\n",
      "396/396 [==============================] - 8s 19ms/step - loss: 0.4163 - accuracy: 0.8187\n",
      "Epoch 31/34\n",
      "396/396 [==============================] - 9s 23ms/step - loss: 0.4133 - accuracy: 0.8199\n",
      "Epoch 32/34\n",
      "396/396 [==============================] - 9s 22ms/step - loss: 0.4102 - accuracy: 0.8243\n",
      "Epoch 33/34\n",
      "396/396 [==============================] - 8s 20ms/step - loss: 0.4076 - accuracy: 0.8225\n",
      "Epoch 34/34\n",
      "396/396 [==============================] - 9s 22ms/step - loss: 0.4048 - accuracy: 0.8278\n"
     ]
    }
   ],
   "source": [
    "# build final_model\n",
    "model_f2 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "    keras.layers.Dense(1000, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(700, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(400, name=\"layer3\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(260, name=\"layer4\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(30, name=\"layer5\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer6\", activation=\"sigmoid\") \n",
    "])\n",
    "# complie\n",
    "model_f2.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# fit (with the epochs=41)\n",
    "history_f2 = model_f2.fit(X_train_2, y_train_2, epochs=best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7200, 1317)\n",
      "(15364, 1317)\n"
     ]
    }
   ],
   "source": [
    "# split for the third spolit\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_whole, y_whole, test_size=15364, random_state=42)\n",
    "print(X_train_3.shape)\n",
    "print(X_test_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/34\n",
      "225/225 [==============================] - 5s 20ms/step - loss: 0.6851 - accuracy: 0.5621\n",
      "Epoch 2/34\n",
      "225/225 [==============================] - 5s 22ms/step - loss: 0.6832 - accuracy: 0.5636\n",
      "Epoch 3/34\n",
      "225/225 [==============================] - 5s 22ms/step - loss: 0.6819 - accuracy: 0.5636\n",
      "Epoch 4/34\n",
      "225/225 [==============================] - 5s 22ms/step - loss: 0.6805 - accuracy: 0.5636\n",
      "Epoch 5/34\n",
      "225/225 [==============================] - 4s 20ms/step - loss: 0.6792 - accuracy: 0.5636\n",
      "Epoch 6/34\n",
      "225/225 [==============================] - 4s 19ms/step - loss: 0.6770 - accuracy: 0.5636\n",
      "Epoch 7/34\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.6752 - accuracy: 0.5636\n",
      "Epoch 8/34\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.6726 - accuracy: 0.5636\n",
      "Epoch 9/34\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.6696 - accuracy: 0.5639\n",
      "Epoch 10/34\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.6656 - accuracy: 0.5650\n",
      "Epoch 11/34\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.6612 - accuracy: 0.5769\n",
      "Epoch 12/34\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 0.6554 - accuracy: 0.6019\n",
      "Epoch 13/34\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.6491 - accuracy: 0.6618\n",
      "Epoch 14/34\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.6409 - accuracy: 0.6686\n",
      "Epoch 15/34\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.6322 - accuracy: 0.6767\n",
      "Epoch 16/34\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.6228 - accuracy: 0.6785\n",
      "Epoch 17/34\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.6130 - accuracy: 0.6815\n",
      "Epoch 18/34\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.6045 - accuracy: 0.6840\n",
      "Epoch 19/34\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.5953 - accuracy: 0.6874\n",
      "Epoch 20/34\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.5862 - accuracy: 0.6922\n",
      "Epoch 21/34\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.5764 - accuracy: 0.6985\n",
      "Epoch 22/34\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.5648 - accuracy: 0.7083\n",
      "Epoch 23/34\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.5519 - accuracy: 0.7193\n",
      "Epoch 24/34\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.5375 - accuracy: 0.7321\n",
      "Epoch 25/34\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.5230 - accuracy: 0.7424\n",
      "Epoch 26/34\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.5089 - accuracy: 0.7543\n",
      "Epoch 27/34\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.4962 - accuracy: 0.7625\n",
      "Epoch 28/34\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.4853 - accuracy: 0.7692\n",
      "Epoch 29/34\n",
      "225/225 [==============================] - 4s 17ms/step - loss: 0.4758 - accuracy: 0.7747\n",
      "Epoch 30/34\n",
      "225/225 [==============================] - 4s 18ms/step - loss: 0.4679 - accuracy: 0.7811\n",
      "Epoch 31/34\n",
      "225/225 [==============================] - 4s 20ms/step - loss: 0.4614 - accuracy: 0.7887\n",
      "Epoch 32/34\n",
      "225/225 [==============================] - 4s 20ms/step - loss: 0.4556 - accuracy: 0.7932\n",
      "Epoch 33/34\n",
      "225/225 [==============================] - 5s 21ms/step - loss: 0.4512 - accuracy: 0.7939\n",
      "Epoch 34/34\n",
      "225/225 [==============================] - 5s 23ms/step - loss: 0.4463 - accuracy: 0.7968\n"
     ]
    }
   ],
   "source": [
    "# build final_model\n",
    "model_f3 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train_pca.shape[1], name=\"input\"),\n",
    "    keras.layers.Dense(1000, name=\"layer1\", activation=\"relu\"),\n",
    "    keras.layers.Dense(700, name=\"layer2\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(400, name=\"layer3\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(260, name=\"layer4\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(30, name=\"layer5\", activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, name=\"layer6\", activation=\"sigmoid\") \n",
    "])\n",
    "# complie\n",
    "model_f3.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# fit (with the epochs=41)\n",
    "history_f3 = model_f3.fit(X_train_3, y_train_3, epochs=best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 1s 9ms/step - loss: 0.4191 - accuracy: 0.8185\n",
      "310/310 [==============================] - 3s 9ms/step - loss: 0.4246 - accuracy: 0.8129\n",
      "481/481 [==============================] - 5s 10ms/step - loss: 0.4501 - accuracy: 0.8014\n"
     ]
    }
   ],
   "source": [
    "e1 = model_f1.evaluate(X_cv_pca, y_cv) \n",
    "e2 = model_f2.evaluate(X_test_2, y_test_2) \n",
    "e3 = model_f3.evaluate(X_test_3, y_test_3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier1 - Accuracy on train set:  0.8489280343055725 , Accuracy on test set:  0.8185242414474487\n",
      "Classifier2 - Accuracy on train set:  0.827760636806488 , Accuracy on test set:  0.8128719925880432\n",
      "Classifier3 - Accuracy on train set:  0.7968055605888367 , Accuracy on test set:  0.8013538122177124\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier1 - Accuracy on train set: \", history_f1.history['accuracy'][-1], \", Accuracy on test set: \", e1[-1])\n",
    "print(\"Classifier2 - Accuracy on train set: \", history_f2.history['accuracy'][-1], \", Accuracy on test set: \", e2[-1])\n",
    "print(\"Classifier3 - Accuracy on train set: \", history_f3.history['accuracy'][-1], \", Accuracy on test set: \", e3[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "8a0afbc8995d256a937eea3117bc2ac830040ae6c61269b467d379bc0c6f6b4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
